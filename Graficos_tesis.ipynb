{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuseifer/TFM_2024/blob/main/Graficos_tesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdfKbUxx1Jbv",
        "outputId": "5f4762c0-8a6e-47dc-8433-3fef6e9b7c12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.13.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.17.3) (1.26.4)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0 (from gym==0.17.3)\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting cloudpickle<1.7.0,>=1.2.0 (from gym==0.17.3)\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
            "Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654616 sha256=df138cce4871e5752fc46c7140eede8d54173301e6a90bd2694484c2ef821da9\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/4b/74/fcfc8238472c34d7f96508a63c962ff3ac9485a9a4137afd4e\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.0\n",
            "    Uninstalling cloudpickle-3.1.0:\n",
            "      Successfully uninstalled cloudpickle-3.1.0\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 1.27.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "dask 2024.10.0 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-1.6.0 gym-0.17.3 pyglet-1.5.0\n",
            "Collecting pybullet==3.2.6\n",
            "  Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Downloading pybullet-3.2.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (103.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.2/103.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pybullet\n",
            "Successfully installed pybullet-3.2.6\n",
            "Collecting stable_baselines3[extra]\n",
            "  Downloading stable_baselines3-2.4.0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting gymnasium<1.1.0,>=0.29.1 (from stable_baselines3[extra])\n",
            "  Downloading gymnasium-1.0.0-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: numpy<2.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.5.1+cu121)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (1.6.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (3.8.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (4.10.0.84)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (2.17.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (4.66.6)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (13.9.4)\n",
            "Collecting ale-py>=0.9.0 (from stable_baselines3[extra])\n",
            "  Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable_baselines3[extra]) (11.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from ale-py>=0.9.0->stable_baselines3[extra]) (4.12.2)\n",
            "Collecting farama-notifications>=0.0.1 (from gymnasium<1.1.0,>=0.29.1->stable_baselines3[extra])\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl.metadata (558 bytes)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.68.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (4.25.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable_baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3[extra]) (3.16.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3[extra]) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3[extra]) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3[extra]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable_baselines3[extra]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.13->stable_baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable_baselines3[extra]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->stable_baselines3[extra]) (2024.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable_baselines3[extra]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->stable_baselines3[extra]) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->stable_baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable_baselines3[extra]) (3.0.2)\n",
            "Downloading ale_py-0.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gymnasium-1.0.0-py3-none-any.whl (958 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m958.1/958.1 kB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading stable_baselines3-2.4.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Installing collected packages: farama-notifications, gymnasium, ale-py, stable_baselines3\n",
            "Successfully installed ale-py-0.10.1 farama-notifications-0.0.4 gymnasium-1.0.0 stable_baselines3-2.4.0\n",
            "Collecting shimmy==1.2.1\n",
            "  Downloading Shimmy-1.2.1-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from shimmy==1.2.1) (1.26.4)\n",
            "Requirement already satisfied: gymnasium>=0.27.0 in /usr/local/lib/python3.10/dist-packages (from shimmy==1.2.1) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==1.2.1) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==1.2.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium>=0.27.0->shimmy==1.2.1) (0.0.4)\n",
            "Downloading Shimmy-1.2.1-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: shimmy\n",
            "Successfully installed shimmy-1.2.1\n",
            "Collecting gymnasium==0.28.1\n",
            "  Downloading gymnasium-0.28.1-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (1.26.4)\n",
            "Collecting jax-jumpy>=1.0.0 (from gymnasium==0.28.1)\n",
            "  Downloading jax_jumpy-1.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (1.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (4.12.2)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from gymnasium==0.28.1) (0.0.4)\n",
            "Downloading gymnasium-0.28.1-py3-none-any.whl (925 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m925.5/925.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jax_jumpy-1.0.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: jax-jumpy, gymnasium\n",
            "  Attempting uninstall: gymnasium\n",
            "    Found existing installation: gymnasium 1.0.0\n",
            "    Uninstalling gymnasium-1.0.0:\n",
            "      Successfully uninstalled gymnasium-1.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "stable-baselines3 2.4.0 requires gymnasium<1.1.0,>=0.29.1, but you have gymnasium 0.28.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gymnasium-0.28.1 jax-jumpy-1.0.0\n",
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install gym==0.17.3\n",
        "!pip install pybullet==3.2.6\n",
        "!pip install stable_baselines3[extra]\n",
        "!pip install shimmy==1.2.1\n",
        "!pip install gymnasium==0.28.1\n",
        "!pip install tensorboardX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qdZ3AlKk2YfO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9391e882-f0dd-4219-f391-9fd25813c9ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py:604: UserWarning: \u001b[33mWARN: plugin: shimmy.registration:register_gymnasium_envs raised Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/gymnasium/envs/registration.py\", line 602, in load_plugin_envs\n",
            "    fn()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/shimmy/registration.py\", line 304, in register_gymnasium_envs\n",
            "    _register_atari_envs()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/shimmy/registration.py\", line 205, in _register_atari_envs\n",
            "    import ale_py\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ale_py/__init__.py\", line 68, in <module>\n",
            "    register_v0_v4_envs()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ale_py/registration.py\", line 178, in register_v0_v4_envs\n",
            "    _register_rom_configs(legacy_games, obs_types, versions)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ale_py/registration.py\", line 63, in _register_rom_configs\n",
            "    gymnasium.register(\n",
            "AttributeError: partially initialized module 'gymnasium' has no attribute 'register' (most likely due to a circular import)\n",
            "\u001b[0m\n",
            "  logger.warn(f\"plugin: {plugin.value} raised {traceback.format_exc()}\")\n"
          ]
        }
      ],
      "source": [
        "import gym\n",
        "import pybullet, pybullet_envs\n",
        "import torch as th\n",
        "\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "from stable_baselines3 import TD3\n",
        "from stable_baselines3 import SAC\n",
        "from stable_baselines3.common.evaluation import evaluate_policy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4MCi5iKV202Q"
      },
      "outputs": [],
      "source": [
        "import pybullet_envs\n",
        "env = gym.make(\"AntBulletEnv-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xQOA-Ryf2yU7",
        "outputId": "c70fa785-8513-4051-883f-8ad164eff7a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/base_vec_env.py:77: UserWarning: The `render_mode` attribute is not defined in your environment. It will be set to None.\n",
            "  warnings.warn(\"The `render_mode` attribute is not defined in your environment. It will be set to None.\")\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# Crear el callback de evaluación, evaluando cada 10,000 steps y guardando el mejor modelo\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/best_model/',\n",
        "                             log_path='./logs/eval/', eval_freq=10000,\n",
        "                             deterministic=True, render=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ush5eSZO2rRT"
      },
      "outputs": [],
      "source": [
        "MAX_AVERAGE_SCORE = 100000\n",
        "#Definimos la arquitectura de la red\n",
        "policy_kwargs = dict(activation_fn=th.nn.LeakyReLU, net_arch=[512, 512])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XoagckzF3Kkb"
      },
      "source": [
        "#TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6zbwJsE3KU7",
        "outputId": "3cfd786f-06e6-4102-81bc-4df6975b3bd1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = TD3('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uP5y6_H-3VZI",
        "outputId": "83eb12ca-f047-423d-e813-5b27a2bfdc99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 829      |\n",
            "|    ep_rew_mean     | 307      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 138      |\n",
            "|    time_elapsed    | 60       |\n",
            "|    total_timesteps | 8294     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -8.68    |\n",
            "|    critic_loss     | 0.0873   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 8193     |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=317.99 +/- 20.97\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 318      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -10.1    |\n",
            "|    critic_loss     | 0.0853   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  349.355723\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 412      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 29       |\n",
            "|    total_timesteps | 4120     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -14.9    |\n",
            "|    critic_loss     | 0.187    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 13919    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 216      |\n",
            "|    ep_rew_mean     | 89.6     |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 4320     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -15.1    |\n",
            "|    critic_loss     | 0.141    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14119    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 225      |\n",
            "|    ep_rew_mean     | 89.1     |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 48       |\n",
            "|    total_timesteps | 6764     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -16.5    |\n",
            "|    critic_loss     | 0.334    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16563    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=504.26 +/- 57.15\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 504      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -20.2    |\n",
            "|    critic_loss     | 1.92     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19799    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  463.6922214\n",
            "Eval num_timesteps=10000, episode_reward=543.05 +/- 141.51\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 543      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -29.1    |\n",
            "|    critic_loss     | 0.272    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29699    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 525      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 124      |\n",
            "|    time_elapsed    | 80       |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "mean_reward  476.8633646\n",
            "Eval num_timesteps=10000, episode_reward=467.32 +/- 103.77\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 467      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 0.46     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39599    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 468      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 125      |\n",
            "|    time_elapsed    | 79       |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "mean_reward  419.1456158\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 426      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 4256     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.5    |\n",
            "|    critic_loss     | 0.613    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 43755    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=359.24 +/- 112.32\n",
            "Episode length: 921.40 +/- 157.20\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 921      |\n",
            "|    mean_reward     | 359      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -45.1    |\n",
            "|    critic_loss     | 0.916    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49499    |\n",
            "---------------------------------\n",
            "mean_reward  469.3006332\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 770      |\n",
            "|    ep_rew_mean     | 387      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 141      |\n",
            "|    time_elapsed    | 54       |\n",
            "|    total_timesteps | 7702     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -50.5    |\n",
            "|    critic_loss     | 0.664    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 57101    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=437.30 +/- 167.56\n",
            "Episode length: 810.80 +/- 292.80\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 811      |\n",
            "|    mean_reward     | 437      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -52.7    |\n",
            "|    critic_loss     | 1.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 59399    |\n",
            "---------------------------------\n",
            "mean_reward  378.9188564\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 640      |\n",
            "|    ep_rew_mean     | 253      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 143      |\n",
            "|    time_elapsed    | 44       |\n",
            "|    total_timesteps | 6405     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -57.6    |\n",
            "|    critic_loss     | 1.34     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 65704    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=203.44 +/- 132.82\n",
            "Episode length: 703.40 +/- 367.26\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 703      |\n",
            "|    mean_reward     | 203      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -60.3    |\n",
            "|    critic_loss     | 1.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 69299    |\n",
            "---------------------------------\n",
            "mean_reward  253.9543662\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 957      |\n",
            "|    ep_rew_mean     | 388      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 121      |\n",
            "|    time_elapsed    | 78       |\n",
            "|    total_timesteps | 9574     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.7    |\n",
            "|    critic_loss     | 1.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 78773    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=426.04 +/- 140.57\n",
            "Episode length: 797.20 +/- 261.24\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 797      |\n",
            "|    mean_reward     | 426      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.4    |\n",
            "|    critic_loss     | 1.05     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 79199    |\n",
            "---------------------------------\n",
            "mean_reward  458.0543764\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 937      |\n",
            "|    ep_rew_mean     | 376      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 129      |\n",
            "|    time_elapsed    | 72       |\n",
            "|    total_timesteps | 9374     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -65      |\n",
            "|    critic_loss     | 0.923    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 88473    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=94.40 +/- 9.74\n",
            "Episode length: 196.00 +/- 22.04\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 196      |\n",
            "|    mean_reward     | 94.4     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -64.7    |\n",
            "|    critic_loss     | 0.814    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 89099    |\n",
            "---------------------------------\n",
            "mean_reward  120.82094260000001\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 867      |\n",
            "|    ep_rew_mean     | 457      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 61       |\n",
            "|    total_timesteps | 8668     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66.4    |\n",
            "|    critic_loss     | 1.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 97667    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=566.59 +/- 77.68\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 567      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -66      |\n",
            "|    critic_loss     | 1.02     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 98999    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  494.0685815999999\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=10000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"TD3_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "kSPAs7SnQGT0",
        "outputId": "11873756-c0b8-44bb-a494-8dd308c39adf"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vAy3AO9x47Lk"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mpa1B9JZ47Ln",
        "outputId": "c716bf20-c609-47c7-b810-643b3e228b46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = PPO('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fcMiMfS47Lp",
        "outputId": "864ed7c2-d458-40b8-d47c-859d01df6907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=10000, episode_reward=8.22 +/- 0.04\n",
            "Episode length: 20.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 20          |\n",
            "|    mean_reward          | 8.22        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008164197 |\n",
            "|    clip_fraction        | 0.11        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.915       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.41        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.00816    |\n",
            "|    std                  | 0.989       |\n",
            "|    value_loss           | 1.61        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mean_reward  8.14665\n",
            "Eval num_timesteps=9760, episode_reward=7.83 +/- 0.10\n",
            "Episode length: 20.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 20         |\n",
            "|    mean_reward          | 7.83       |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 9760       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01266641 |\n",
            "|    clip_fraction        | 0.127      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -11.2      |\n",
            "|    explained_variance   | 0.301      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.726      |\n",
            "|    n_updates            | 90         |\n",
            "|    policy_gradient_loss | -0.0151    |\n",
            "|    std                  | 0.978      |\n",
            "|    value_loss           | 2.87       |\n",
            "----------------------------------------\n",
            "mean_reward  8.8667032\n",
            "Eval num_timesteps=9520, episode_reward=652.69 +/- 52.75\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 653         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9520        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.021977762 |\n",
            "|    clip_fraction        | 0.221       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.1       |\n",
            "|    explained_variance   | 0.508       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.253       |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.0318     |\n",
            "|    std                  | 0.964       |\n",
            "|    value_loss           | 0.909       |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  743.2687764\n",
            "Eval num_timesteps=9280, episode_reward=509.96 +/- 1.38\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 510        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 9280       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01209924 |\n",
            "|    clip_fraction        | 0.222      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -10.9      |\n",
            "|    explained_variance   | 0.831      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.436      |\n",
            "|    n_updates            | 190        |\n",
            "|    policy_gradient_loss | -0.00913   |\n",
            "|    std                  | 0.946      |\n",
            "|    value_loss           | 1.12       |\n",
            "----------------------------------------\n",
            "mean_reward  478.9973516\n",
            "Eval num_timesteps=9040, episode_reward=648.22 +/- 46.74\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 648         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 9040        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.026401874 |\n",
            "|    clip_fraction        | 0.269       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.8       |\n",
            "|    explained_variance   | 0.719       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.255       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0327     |\n",
            "|    std                  | 0.929       |\n",
            "|    value_loss           | 0.934       |\n",
            "-----------------------------------------\n",
            "mean_reward  696.5820100000001\n",
            "Eval num_timesteps=8800, episode_reward=639.72 +/- 39.26\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 640         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 8800        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.028931888 |\n",
            "|    clip_fraction        | 0.3         |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.6       |\n",
            "|    explained_variance   | 0.65        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.371       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.041      |\n",
            "|    std                  | 0.906       |\n",
            "|    value_loss           | 1.35        |\n",
            "-----------------------------------------\n",
            "mean_reward  645.8144162\n",
            "Eval num_timesteps=8560, episode_reward=669.74 +/- 230.87\n",
            "Episode length: 861.20 +/- 277.60\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 861        |\n",
            "|    mean_reward          | 670        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 8560       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03100846 |\n",
            "|    clip_fraction        | 0.316      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -10.3      |\n",
            "|    explained_variance   | 0.871      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.354      |\n",
            "|    n_updates            | 340        |\n",
            "|    policy_gradient_loss | -0.0458    |\n",
            "|    std                  | 0.879      |\n",
            "|    value_loss           | 1.22       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  735.1529519999999\n",
            "Eval num_timesteps=8320, episode_reward=789.61 +/- 50.33\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 790        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 8320       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03521368 |\n",
            "|    clip_fraction        | 0.357      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -10.1      |\n",
            "|    explained_variance   | 0.745      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.242      |\n",
            "|    n_updates            | 390        |\n",
            "|    policy_gradient_loss | -0.0426    |\n",
            "|    std                  | 0.858      |\n",
            "|    value_loss           | 1.8        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  783.2560916\n",
            "Eval num_timesteps=8080, episode_reward=730.66 +/- 60.27\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 731         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 8080        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.044989496 |\n",
            "|    clip_fraction        | 0.333       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -9.93       |\n",
            "|    explained_variance   | 0.711       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.409       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0573     |\n",
            "|    std                  | 0.839       |\n",
            "|    value_loss           | 2.53        |\n",
            "-----------------------------------------\n",
            "mean_reward  736.3468606\n",
            "Eval num_timesteps=7840, episode_reward=786.68 +/- 74.13\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 787         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 7840        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.043340527 |\n",
            "|    clip_fraction        | 0.385       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -9.78       |\n",
            "|    explained_variance   | 0.607       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06        |\n",
            "|    n_updates            | 480         |\n",
            "|    policy_gradient_loss | -0.0428     |\n",
            "|    std                  | 0.822       |\n",
            "|    value_loss           | 1.68        |\n",
            "-----------------------------------------\n",
            "mean_reward  875.6893661999999\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=10000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"PPO_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nPY4OGgWXqec",
        "outputId": "dd81b516-5e5f-448a-fdb4-2dafce3058f5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAABiu0lEQVR4nO3dd3gUVd/G8e+m91DTA6F3KQlgQIrSREBAVFBERB/1EVARK76K2OABFamKWMAGKgIWRCCC0gWkSQ29BZIAgVRSd98/QlZCkSTsZjeb+3NdXJLZ2Znf7Anmzpkz5xhMJpMJEREREQflZOsCRERERKxJYUdEREQcmsKOiIiIODSFHREREXFoCjsiIiLi0BR2RERExKEp7IiIiIhDU9gRERERh6awIyIiIg5NYUdEyr0xY8ZgMBhsXUapK6/XLeWPwo6IFcyePRuDwYDBYGDNmjVXvG4ymQgPD8dgMNCzZ08bVFh0ERER5msxGAx4e3vTqlUrvvjiC1uXJldxeXtd68/s2bNtXapIqXGxdQEijszDw4M5c+Zwyy23FNq+cuVKTpw4gbu7u40qK55mzZrx7LPPAnDq1Ck++eQTBg8eTFZWFo8++qiNq5NLTZo0ibS0NPPXixcvZu7cubz//vtUqVLFvL1NmzY88MADvPTSS7YoU6RUKeyIWNEdd9zBvHnzmDJlCi4u//xzmzNnDpGRkZw5c8aG1RVdaGgoDzzwgPnrhx56iJo1a/L++++XibCTm5uL0WjEzc3N1qVYTHp6Ot7e3lds79OnT6Gv4+PjmTt3Ln369CEiIuKK/S/9vhRxVLqNJWJF9913H2fPniUmJsa8LTs7m++//57777//qu8xGo1MmjSJRo0a4eHhQWBgII8//jjnzp0rtN+PP/5Ijx49CAkJwd3dnVq1avHmm2+Sl5dXaL+OHTvSuHFjdu/eza233oqXlxehoaFMmDChxNdVtWpV6tevz8GDB4td+8iRI6lcuTImk8m87cknn8RgMDBlyhTztoSEBAwGAx9++CGQ/7mNHj2ayMhI/P398fb2pl27dvz++++Fajhy5AgGg4F3332XSZMmUatWLdzd3dm9ezcAa9asoWXLlnh4eFCrVi0++uijYl37vHnziIyMxNPTkypVqvDAAw8QFxdnfv3dd9/FYDBw9OjRK947atQo3NzcCn0eGzZs4Pbbb8ff3x8vLy86dOjA2rVrC72vYGzN7t27uf/++6lYseIVvYUlcbUxOwaDgeHDhzNv3jwaNmyIp6cn0dHR7NixA4CPPvqI2rVr4+HhQceOHTly5MgVxy3KNYmUJoUdESuKiIggOjqauXPnmrf9+uuvJCcnM2DAgKu+5/HHH+f555+nbdu2TJ48mSFDhvD111/TrVs3cnJyzPvNnj0bHx8fRo4cyeTJk4mMjGT06NFXvS1x7tw5br/9dpo2bcp7771H/fr1efHFF/n1119LdF25ubmcOHGCihUrFrv2du3akZSUxK5du8zvW716NU5OTqxevbrQNoD27dsDkJKSwieffELHjh0ZP348Y8aM4fTp03Tr1o1t27ZdUeOsWbOYOnUqjz32GO+99x6VKlVix44ddO3alcTERMaMGcOQIUN47bXXWLhwYZGue/bs2dx77704Ozszbtw4Hn30URYsWMAtt9zC+fPnAbj33nsxGAx89913V7z/u+++o2vXrubPbcWKFbRv356UlBRee+01xo4dy/nz57ntttvYuHHjFe+/5557yMjIYOzYsVbtUVu9ejXPPvssgwcPZsyYMezZs4eePXsyffp0pkyZwtChQ3n++edZv349Dz/8cKH3FveaREqFSUQsbtasWSbAtGnTJtO0adNMvr6+poyMDJPJZDLdc889pltvvdVkMplM1atXN/Xo0cP8vtWrV5sA09dff13oeEuWLLlie8HxLvX444+bvLy8TJmZmeZtHTp0MAGmL774wrwtKyvLFBQUZOrXr991r6V69eqmrl27mk6fPm06ffq0aceOHaZBgwaZANOwYcOKXXtiYqIJMH3wwQcmk8lkOn/+vMnJycl0zz33mAIDA83ve+qpp0yVKlUyGY1Gk8lkMuXm5pqysrIKHfvcuXOmwMBA08MPP2zedvjwYRNg8vPzMyUmJhbav0+fPiYPDw/T0aNHzdt2795tcnZ2Nl3vf4fZ2dmmgIAAU+PGjU0XLlwwb1+0aJEJMI0ePdq8LTo62hQZGVno/Rs3bizUDkaj0VSnTh1Tt27dzNdoMuW3a40aNUxdunQxb3vttddMgOm+++771xqv5p133jEBpsOHD1/xWsFxLwWY3N3dC+3/0UcfmQBTUFCQKSUlxbx91KhRhY5dnGsSKU3q2RGxsnvvvZcLFy6waNEiUlNTWbRo0TVvYc2bNw9/f3+6dOnCmTNnzH8iIyPx8fEpdMvG09PT/PfU1FTOnDlDu3btyMjIYO/evYWO6+PjU2jMjZubG61ateLQoUNFuoZly5ZRtWpVqlatSpMmTfjyyy8ZMmQI77zzTrFrL7gFtmrVKgDWrl2Ls7Mzzz//PAkJCezfvx/I71245ZZbzLdZnJ2dzWNujEYjSUlJ5ObmEhUVxZYtW66ouV+/flStWtX8dV5eHkuXLqVPnz5Uq1bNvL1BgwZ069btup/BX3/9RWJiIkOHDsXDw8O8vUePHtSvX59ffvnFvK1///5s3ry50G2+b7/9Fnd3d3r37g3Atm3b2L9/P/fffz9nz541f17p6el06tSJVatWYTQaC9Xw3//+97p1WkKnTp0Kje9p3bo1kP+Z+vr6XrG94PuoJNckUho0Mk3EyqpWrUrnzp2ZM2cOGRkZ5OXlcffdd1913/3795OcnExAQMBVX09MTDT/fdeuXbzyyiusWLGClJSUQvslJycX+josLOyKsRkVK1bk77//LtI1tG7dmrfeeou8vDx27tzJW2+9xblz5woN+C1O7e3atWPx4sVAfqiJiooiKiqKSpUqsXr1agIDA9m+ffsVofDzzz/nvffeY+/evYVu6dWoUeOK812+7fTp01y4cIE6depcsW+9evXM9VxLwRicevXqXfFa/fr1C00xcM899zBy5Ei+/fZbXn75ZUwmE/PmzaN79+74+fkBmEPd4MGDr3nO5OTkQrcKr3ad1nBpGATw9/cHIDw8/KrbC8YgleSaREqDwo5IKbj//vt59NFHiY+Pp3v37lSoUOGq+xmNRgICAvj666+v+npBT8X58+fp0KEDfn5+vPHGG9SqVQsPDw+2bNnCiy++eMVvz87Ozlc9numSQcL/pkqVKnTu3BmAbt26Ub9+fXr27MnkyZMZOXJksWoHuOWWW/j44485dOgQq1evpl27dhgMBm655RZWr15NSEgIRqORdu3amd/z1Vdf8dBDD9GnTx+ef/55AgICzGNnLh8oDYV7vkpbSEgI7dq147vvvuPll1/mzz//5NixY4wfP968T0EbvfPOOzRr1uyqx/Hx8Sn0dWld07W+X673fVSSaxIpDQo7IqWgb9++PP744/z55598++2319yvVq1a/Pbbb7Rt2/Zff7D98ccfnD17lgULFpgH8AIcPnzYonVfS48ePejQoQNjx47l8ccfx9vbu8i1A+YQExMTw6ZNm8yDqtu3b8+HH35ISEgI3t7eREZGmt/z/fffU7NmTRYsWFCol+q1114rUs1Vq1bF09PT3PtwqdjY2Ou+v3r16uZ9b7vttiveX/B6gf79+zN06FBiY2P59ttv8fLyolevXubXa9WqBYCfn585SJZ1jnhN4hg0ZkekFPj4+PDhhx8yZsyYQj/wLnfvvfeSl5fHm2++ecVrubm55id+Cn7DvrRnJjs7mw8++MCyhf+LF198kbNnz/Lxxx8DRa8d8m/HhIaG8v7775OTk0Pbtm2B/BB08OBBvv/+e26++eZCc8Bc7Zo3bNjA+vXri1Svs7Mz3bp144cffuDYsWPm7Xv27GHp0qXXfX9UVBQBAQHMmDGDrKws8/Zff/2VPXv20KNHj0L79+vXD2dnZ+bOncu8efPo2bNnoXlxIiMjqVWrFu+++26hSQALnD59ukjXZU8c8ZrEMahnR6SU/Ns4hgIdOnTg8ccfZ9y4cWzbto2uXbvi6urK/v37mTdvHpMnT+buu++mTZs2VKxYkcGDB/PUU09hMBj48ssvi3xbyhK6d+9O48aNmThxIsOGDSty7QXatWvHN998Q5MmTcxjOFq0aIG3tzf79u27YrxOz549WbBgAX379qVHjx4cPnyYGTNm0LBhw6v+YL2a119/nSVLltCuXTuGDh1Kbm4uU6dOpVGjRtcdv+Tq6sr48eMZMmQIHTp04L777iMhIYHJkycTERHBM888U2j/gIAAbr31ViZOnEhqair9+/cv9LqTkxOffPIJ3bt3p1GjRgwZMoTQ0FDi4uL4/fff8fPz4+effy7SddkLR7wmcQzq2RGxMzNmzGDmzJkkJiby8ssvM2rUKFasWMEDDzxg7gGpXLkyixYtIjg4mFdeeYV3332XLl263NBEgSXx3HPPcfz4cfM4naLUXqDgVtalk+O5uLgQHR1d6PUCDz30EGPHjmX79u089dRTLF26lK+++oqoqKgi13vTTTexdOlSqlatyujRo/nss894/fXX6du3b5He/9BDD/Htt9+SnZ3Niy++yEcffUTfvn1Zs2bNVcdh9e/fn9TUVHx9fbnjjjuueL1jx46sX7+eqKgopk2bxpNPPsns2bMJCgq6IjyVFY54TVL2GUyl+augiIiISClTz46IiIg4NIUdERERcWgKOyIiIuLQFHZERETEoSnsiIiIiENT2BERERGHpkkFyV/P5eTJk/j6+l6xWKKIiIjYJ5PJRGpqKiEhITg5Xbv/RmEHOHny5BWr+YqIiEjZcPz4ccLCwq75usIO4OvrC+R/WH5+fhY7bk5ODsuWLTNPmy+2pfawP2oT+6L2sC9qj+tLSUkhPDzc/HP8WhR2wHzrys/Pz+Jhx8vLCz8/P32j2gG1h/1Rm9gXtYd9UXsU3fWGoGiAsoiIiDg0hR0RERFxaAo7IiIi4tAUdkRERMShKeyIiIiIQ1PYEREREYemsCMiIiIOTWFHREREHJrCjoiIiDg0hR0RERFxaAo7IiIi4tAUdkRERMShKeyIiIiI1cSdv8DOuGSb1qCwIyIiIlZxJi2LQZ9s4L6Zf7L5aJLN6lDYEREREYtLycxh8GcbOXQmHT9PV4L9PW1Wi8KOiIiIWFRmTh7/+fwvdp1MobK3G18+0oqQCgo7IiIi4gBy8owMn7OFjYeT8HV34fOHW1Gzqo9Na1LYEREREYswGk288P3f/LYnEXcXJz4ZHEXjUH9bl6WwIyIiIjfOZDLxxqLdLNwah7OTgQ8GtqB1zcq2LgtQ2BERERELmLx8P7PXHQHgvXua0qlBoG0LuoTCjoiIiNyQWWsPM+m3/QC8fmcj+jQPtXFFhSnsiIiISIkt2HKC13/eDcAznesyuE2EbQu6CoUdERERKZHfdifw/Pd/AzCkbQRPdapt44quTmFHREREim39wbMMnbOFPKOJu1qE8mqPhhgMBluXdVUKOyIiIlIsO04k8+gXf5Gda6Rzg0Am9LsJJyf7DDqgsCMiIiLFcCAxjcGzNpKWlcvNNSsx7f7muDjbd5yw7+pERETEbsSdv8CDn24gKT2bJqH+fPxgFB6uzrYu67oUdkREROS6zqZlMejTDZxMzqRmVW9mD2mJr4errcsqEoUdERER+VepmTkMnrWRQ6fTCfH34KtHWlPZx93WZRWZwo6IiIhcU8EK5jvjLq5g/p/WNl3BvCQUdkREROSqClYw33A4CZ+LK5jXsvEK5iWhsCMiIiJXMBpNvGiHK5iXhMKOiIiIFFKwgvmCS1Ywv9lOVjAvCYUdERERKWTK8gN2u4J5SSjsiIiIiNnstYd5/7d9AIzp1dDuVjAvCYUdERERAWDh1hOMubiC+YjOdXiobQ0bV2QZCjsiIiLCb7sTeG5e/grmD7WJ4OlOdWxckeUo7IiIiJRzfx46y7CCFcybhzK6p/2uYF4SCjsiIiLl2M64ZP7z+V9k5Rrp3CCA8Xfb9wrmJWHTsJOXl8err75KjRo18PT0pFatWrz55puYTCbzPiaTidGjRxMcHIynpyedO3dm//79hY6TlJTEwIED8fPzo0KFCjzyyCOkpaWV9uWIiIiUKQdPpzH4s/wVzFvXqMS0+1vgaucrmJeETa9o/PjxfPjhh0ybNo09e/Ywfvx4JkyYwNSpU837TJgwgSlTpjBjxgw2bNiAt7c33bp1IzMz07zPwIED2bVrFzExMSxatIhVq1bx2GOP2eKSREREyoST5y8w6JMNnE3PpnGoH58MLhsrmJeEiy1Pvm7dOnr37k2PHj0AiIiIYO7cuWzcuBHI79WZNGkSr7zyCr179wbgiy++IDAwkB9++IEBAwawZ88elixZwqZNm4iKigJg6tSp3HHHHbz77ruEhITY5uJERETs1Nm0LB64ZAXzz4e0KjMrmJeETcNOmzZtmDlzJvv27aNu3bps376dNWvWMHHiRAAOHz5MfHw8nTt3Nr/H39+f1q1bs379egYMGMD69eupUKGCOegAdO7cGScnJzZs2EDfvn2vOG9WVhZZWVnmr1NSUgDIyckhJyfHYtdXcCxLHlNKTu1hf9Qm9kXtYV+s1R6pmbkMnvUXh06nE+zvwawHW+Dn7lQm272oNds07Lz00kukpKRQv359nJ2dycvL4+2332bgwIEAxMfHAxAYWHjmxsDAQPNr8fHxBAQEFHrdxcWFSpUqmfe53Lhx43j99dev2L5s2TK8vLxu+LouFxMTY/FjSsmpPeyP2sS+qD3siyXbIzsPPtrrzIEUA94uJobUSGPbut/ZZrEzlK6MjIwi7WfTsPPdd9/x9ddfM2fOHBo1asS2bdsYMWIEISEhDB482GrnHTVqFCNHjjR/nZKSQnh4OF27dsXPz89i58nJySEmJoYuXbrg6uq43YNlhdrD/qhN7Ivaw75Yuj1y84wM/2Y7B1JO4+3uzNcPt6RRiOV+5tlCwZ2Z67Fp2Hn++ed56aWXGDBgAABNmjTh6NGjjBs3jsGDBxMUFARAQkICwcHB5vclJCTQrFkzAIKCgkhMTCx03NzcXJKSkszvv5y7uzvu7u5XbHd1dbXKP3BrHVdKRu1hf9Qm9kXtYV8s0R5Go4kXF25n+d7TuLk48engljSrXnYX9ixQ1M/Fpk9jZWRk4ORUuARnZ2eMRiMANWrUICgoiOXLl5tfT0lJYcOGDURHRwMQHR3N+fPn2bx5s3mfFStWYDQaad26dSlchYiIiP0yr2C+5eIK5veX7RXMS8KmPTu9evXi7bffplq1ajRq1IitW7cyceJEHn74YQAMBgMjRozgrbfeok6dOtSoUYNXX32VkJAQ+vTpA0CDBg24/fbbefTRR5kxYwY5OTkMHz6cAQMG6EksEREp9y5dwfzde26ic8OyvYJ5Sdg07EydOpVXX32VoUOHkpiYSEhICI8//jijR4827/PCCy+Qnp7OY489xvnz57nllltYsmQJHh4e5n2+/vprhg8fTqdOnXBycqJfv35MmTLFFpckIiI2ZDKZ2BGXjJebM7UDfG1djs19vu6IeQXz13o1pG/zMBtXZBs2DTu+vr5MmjSJSZMmXXMfg8HAG2+8wRtvvHHNfSpVqsScOXOsUKGIiJQFx85mMH/LCRZsPcHxpAsANAj2467mofRuFkKAn8d1juB4ftgax2s/7QLyVzAf4iArmJeETcOOiIhISaVl5bL471N8v+UEGw8nmbd7uzmTnWdkz6kU3j6Vwrhf99C2dhXuahFKt0ZBeLk5/o++5XsSeHbedsDxVjAvCcdvcRERcRh5RhPrDp5h/uYTLNkVT2ZO/gMtBgPcUrsK/VqE0a1REJk5eSzacYqFW06w5dh5Vu8/w+r9Z/By20m3RkH0bR5K29pVcHawBS8BNhw6y9Cv81cw7+uAK5iXhMKOiIjYvYOn05i/+QQLt8ZxKvmftRFrVvXm7sgw+jYPJdjf07zd082ZQTdXZ9DN1Tl6Np2FW+NYuDWOo2czzH8P8HWnd7MQ+jYPo2EZn2+mwOUrmE9wwBXMS0JhR0RE7FJyRg4//X2S+ZtPsO34efN2f09XejUNpl+LMJqFV7hur0X1yt6M6FyXpzvVYcux8yzceoJFf58iMTWLj1cf5uPVh6kf5Euf5qH0aRZKkH/ZHN9z6OIK5qlZubRy4BXMS0JhR0RE7EZunpFV+08zf3McMbsTyM7Lv03l7GSgQ92q3B0ZRqcGAbi7FH91boPBQGT1ikRWr8jono34IzaRhVvjWL4nkb3xqfzv172MX7KXNrUq07d5GLc3DsLHvWz8mDx5/gKDPt1YLlYwL4my0YoiIuLQ9pxKYf7mE/yw7SRn0v5ZqLl+kC93R4ZxZ7MQAnwt1+Pi5uJE10ZBdG0URHJGDr/sOMXCrSfYdOQcaw+cZe2Bs7zyww66Ngyib4tQ2tWugoud9pIkpWcz6NMNxJ2/YF7B3M+BVzAvCYUdERGxibNpWfy47STzt5xg18l/1jiq7O3Gnc1CuDsyjEYh/lavw9/LlftbV+P+1tU4npTBDxfH9Bw6k85P20/y0/aTVPFx586mIdzVIpRGIX52M+A3NTOHh2Zt5ODFFcy/fKQ1lX2uXA6pvFPYERGRUpOda2TF3gS+3xzHH7GJ5BpNALg6G+hUP5B+kWF0rFfVZmNNwit58WSnOgy/rTbbTyTzw9Y4ftqe39v02drDfLb2MHUCfOjbIn98T0gFz+sf1Eoyc/J49Iu/+PtEMpW83fjykdaE2rAee6awIyIiVlUwq/H8zSf4aftJzmXkmF+7KcyfuyPD6HVTCBW93WxYZWEGg4Fm4RVoFl6B/+vRgFX7TrNga/44ov2JaUxYEss7S2NpXaMSdzUPo3uTIHxL8dZRbp6R4XO28uehJHzcXfh8SCtqB/iU2vnLGoUdERGxioSUTBZujWP+5hPsT0wzbw/0c6dP81DubhFGnUD7X9LB1dmJTg0C6dQgkJTMHH7dcYqFW+P481CS+c+rP+6kS8NA7moRSrs61u2ZMhpNvDh/B7/tScDNxYlPBkfRJMz6t/vKMoUdERGxmMycPJbtTmD+5hOs3n+ai3epcHdxolujIPpFhnFLGZ7Mz8/Dlf4tq9G/ZTXizl8wj+85kJjGor9PsejvU1T2dqNX0xD6Ng/lpjB/i47vMZlMvPnLbuZvOYGzk4Hp5XAF85JQ2BERkRtiMpnYfPQc87fkz1+Tmplrfi2qekX6RYbR46Zgh3tCKLSCJ8Nurc3QjrXYGZfCgq0n+Hn7Sc6kZTN73RFmrztCzareF9fnCiW8ktcNn3PqigPMWnsEgHfuvoku5XAF85JQ2BERkRI5cS6DhVviWLA1jsNn0s3bQyt40q9FKHe1CCOiircNKywdBoOBJmH+NAnz5//uaMDqA2dYuCWOZbvjOXQ6nXeX7ePdZftoVaMSfZuHckeTYPw9ix/8vlh/hIkx/6xgfleL8rmCeUko7IiISJGlZ+Xy68545m8+wfpDZ83bvdyc6d44mH6Rodxco3K5XaLAxdmJW+sFcGu9AFIzc1iyM54ftsWx7uBZNh5OYuPhJF77aRedGwTQt3kYHepWxc3l+uN7ftgax+gf81cwf7pT+V7BvCQUdqTcWHfwLB/udqJBq3TqBlewdTkiZYbRaOLPw2eZvzmOX3eeIiM7z/xam1qV6dcif7Zh7zIy23Bp8fVw5Z6ocO6JCudU8gV+3HaShVviiE1IZfGOeBbviKeilyu9mobQp3koza+x9MXvsafNK5gPjq7OiM7lewXzktB3ppQbn609yt5kJ8b+Gsvsh1vbuhwRu3fkTDrzt5xgwZY44s5fMG+PqOxFvxZh9G0RSljFGx+HUh4E+3vy3w61eLx9TXafSmHhljh+3H6S06lZfLH+KF+sP0qNKt70aRZK3+ahVKuc/7keTIGPvtlOntFEn2YhvNarkd1MaFiWKOxIuRGbkArAH/vOsDMumcahelRT5HIXcuHbv07ww7ZT/HX0nHm7r7sLPZuGcHdkKC2qVdQP3BIyGAw0CvGnUYg/o+5owNoDZ1i4NY4lO+M5fCad93/bx/u/7SOqekU61q3CzL3OZOUZ6VQ/gHfuaVpubw/eKIUdKReSM3KIT/lnvZ2pK/bz0aAoG1YkYl8SUzMZu2g3v/ztTI5pNwBOBmhXpyr9IsPo2jBQC0tamLOTgfZ1q9K+blXe6pPL0l3xLNwax9oDZ/jr6LmLYdNAy4iKTB+oFcxvhMKOlAt74/PX3fFwNpFlNLB0VwJ7TqXQINjPxpWJ2N7iHaf4v4U7Ls5sbKBOgDd3R4bTp3kogX6WW3xTrs3b3YW7WoRxV4swElIy+WnbSX7aHkdO2nk+GthMQfMGKexIuVBwC6umr4mIsCAW70xg2u8HmH5/CxtXJmI7yRdyGPPTLhZujQOgYbAv3Sqf44l72+DmZj9LN5Q3gX4ePNq+Jg9Fh7N48eJSXYbCUalPTMqFvfH5YSfEC4Z2qAnk/zZ7IDHVlmWJ2MzaA2e4fdIqFm6Nw8kAw2+tzbzHWhPhi8bjiMNR2JFyIbYg7HibqBfkS9eGgZhMMG3FARtXJlK6MnPyeP3nXQz8ZAOnkjOJqOzFvP+24blu9Yo034tIWaTvbHF4JpOJfRfDTrBX/kI9T3XKn6fip+0nC838KuLI/j5xnh5TVpuXG3jg5mosfrodkdUr2rYwEStT2BGHF3f+AqlZubg6Gwi8ONaycag/t9UPwGiCD35X7444ttw8I5N/289dH6zj4Ol0AnzdmT2kJW/1aYKXm4ZuiuNT2BGHV3ALq2YVby59cvPJ22oDsGBrHMeTMmxRmojVHTydRr8Z63n/t33kGk30uCmYpSPa07FegK1LEyk1Cjvi8AoGJ9cN9Cm0vXm1irSrU4U8o4kP/jhoi9JErMZoNPH5uiP0mLKa7cfP4+fhwuQBzZh2X3MqeutJKylfFHbE4RX07NQL9L3itYKxO99vPs7JS6bDFynL4pMzGTxrI6/9tIvMHCPt6lRh6TPt6d0sVE9aSbmksCMOL/YaPTsALSMqcXPNSuTkmZixUr07Uvb9uC2Oru+vZPX+M3i4OvH6nY34fEgrgv09bV2aiM0o7IhDy841cvB0GgD1rhJ2AJ66Lb9355tNx0lMySy12kQs6XxGNsPnbOHpb7aRkplL0zB/fnmqHYPbRGg9JSn3FHbEoR08nUau0YSvhwvB/lef9j66VmWiqlckO9fIR6sOlXKFIjfuj9hEur6/ikV/n8LZycAznesy/4k21Kp69YAvUt4o7IhDu3S8zrXGKhgMBp68OHbn6w1HOZOWddX9ROxNRnYur/ywg4dmbSIxNYtaVb1ZOLQNT3eug4sWjRQx078GcWgFT2LVC7pycPKl2tepQtMwfzJzjHy8Wr07Yv+2HDvHHZNX89WfxwB4qE0EvzzVjpvCKti2MBE7pLAjDi324mrn9a+zurnBYDA/mfXl+qOcS8+2em3l3fGkDJ76ZjvLThhI0FipIsvONfLu0lju/nAdR85mEOzvwdf/ac2YOxtpZWyRa9DUmeLQCm5j1b9Ozw7AbfUDaBTix66TKXy29jDPdq1n7fLKLZPJxIvz/2bdwbOAM7++u4rb6gcwoGU1Otarqlsw17A/IZUR325j18n8EN+3eShj7myEv6dWxRb5N/o/ijis5As5nEzO7zGoe5U5di5nMBjMsyrPXnuE5As5Vq2vPFu8I551B8/i5uJETV8TRhP8tieR/3zxF23Hr+DdpbEcO6tZrQsYjSY+WX2IHlPXsOtkChW8XPlgYAve799MQUekCNSzIw5rX8LFlc79PfD3dCUn5/rhpWvDIOoF+hKbkMrstUd4unMda5dZ7mRk5/LWL7sBeLxdBLUz91GvZQfmbz3J/C1xJKRkMe33A0z7/QC31K5C/5bhdG0UiLtL+bxFc+JcBs/N286fh5IAuLVeVcb3u4kAv6s/XSgiV1LPjjisog5OvpSTk4HhF3t3Plt7mNRM9e5Y2vTfD3AqOZOwip481q4GALWqevN/PRry56hOfDCwBe3qVMFggDUHzvDk3K3cPHY5by7azf6LAbY8MJlMfL/5BN0nrebPQ0l4uTkztm8TPnuopYKOSDGpZ0ccVsHg5HpB/z44+XJ3NAnm/d/2ceh0Ol+sP8qwW2tbo7xy6fCZdD5edRiA0T0bXjGg1s3FiTuaBHNHk2COJ2Uw76/jfPfXCeJTMvl0zWE+XXOYyOoV6d8ynJ43BTvsit1n07J4eeEOlu5KACCyekXeu6cpEVW8bVyZSNmknh1xWMUZnHwpZycDwy8GnE/XHCYjO9fitZVHJpOJ13/eRXaekQ51q9KlYeC/7h9eyYuRXeux9qXb+OyhKLo2DMTZycDmo+d44fu/afX2cl5euIMdJ5JL6QpKx2+7E+g2aRVLdyXg6mzg+W71+O7xaAUdkRvgmL8WSblnMplKdBurwJ1NQ5i8fD9Hz2bw9Z/HeLR9TUuXWO78tieRP2JP4+ps4LVeDYu8IKWzk4Hb6gdyW/1AElMy+X7LCb7ddJyjZzOYs+EYczYco1GIHwNahnNns9AyO2A3LSuXN3/ezbd/HQfy13J7v38zGoX427gykbJPPTvikE4mZ5KamYuLk6FEU+a7ODsxrGN+785Hqw6RmZNn6RLLlcycPN5YtAuA/7SrSc0SLmMQ4OfB0I61+f3Zjsx5tDW9m4Xg5uLErpMpvPrjLlqP/Y2R321j4+EkTCaTJS/BqjYeTqL75FV8+9dxDAZ4rH1Nfhp+i4KOiIWoZ0ccUsF4nZpVvXFzKVmm79silMnL9xN3/gJzNx5jSNsaliyxXPlo5SGOJ10gyM/DfIvwRjg5GWhTqwptalVhTHo2P2yL45uNx4lNSGXBljgWbImjZlVvBrQMp1+LMCr7uFvgKiwvKzePiTH7mLnqECYThFbw5L17m3Jzzcq2Lk3EoahnRxzSXvN4neINTr6Uq7MTQ2+tBeT/sM7KVe9OSRxPyuCDPw4A8H89GuDtbtnfsSp6uzGkbQ2WjGjHgqFt6B8VjpebM4dOpzN28V5uHrecoV9vZtW+0xiN9tPbs+dUCr2nreWjlflB557IMJaMaKegI2IF6tkRhxR7A+N1LnV3ZBjTVuQ/Kj3vrxM8cHN1S5RXrry5aDdZuUaia1am503BVjuPwWCgRbWKtKhWkVd7NeTn7Sf5ZtNxth8/z+Id8SzeEU9oBU/6twznnqgwgv09rVbLv8kzmpi56hATY2LJyTNR2duNcXc1oWujIJvUI1IeqGdHHFJJn8S6nLuLM49fHJz84R8Hyc413nBt5ckfsYks252As5OB13s3KvKg5Bvl4+7Cfa2q8eOwtvz6dDseahOBn4cLcecvMDFmH23/t4KHZ29i6a54cvJKr02Pnc2g/0frGb9kLzl5Jro0DGTpM+0VdESsTD074nBy8owcPJ0G3HjPDsCAVtWY/sdB4s5fYOHWE/RvWe2Gj1keZOXm8frP+TMlP9QmokhLdlhDg2A/xtzZiJe612fJznjmbjzGhsNJrNibyIq9iVT1defuyDD6R4Vb7fFuk8nEN5uO8+ai3WRk5+Hj7sLoXg25JzKs1AKgSHmmsCMO59DpdHLyTPi6uxBa4cZvVXi45vfuvPXLHqb/fpB+LcK0UGURfLbmCIfPpFPFx90ult3wcHWmT/NQ+jQP5dDpNL796zjzN5/gdGoWH/5xkA//OEh0zcoMaBVOt0ZBFltBPDE1k1Hzd7B8byIArWpU4r17mhJeycsixxeR61PYEYez9+KTWHWDfC32W/P9ravxwR8HOZaUwY/bTtIvMswix3VUp5IvMHXFfgBGda+Pn4d9zX1Ts6oPo7o34Lmu9Vi+J4FvNh1n5b7TrD90lvWHzlLBy5W+zUMZ0LLaDfUOLtl5ilELdnAuIwc3Zyee71aPR26pgZOTenNESpPCjjgcSw1OvpSXmwuPtqvJ+CV7mf77Afo0D8VZP7CuaezivWRk5xFVvSJ3tQi1dTnX5OrsxO2Ng7m9cTBx5y/kL0+x6TgnkzOZtfYIs9YeoXm1CgxoGU7Pm0KK/CRZSmYOY37cxYKtcUD+rbRJ/ZtZ9HtSRIpOffHicCw1OPlyg6KrU8HLlUNn0vllxymLHtuRrDt4hp+3n8TJQKkOSr5RoRU8GdG5LqtfvI3ZQ1pye6MgXJwMbD12nhfn76DV278xasHfbDt+/l8nLFx34Ay3v7+KBVvjcDLA0I61+HFYWwUdERtSz444HPMyERYeEOvj7sLDbWswMWYf01bsp2eTYN2OuExOnpExP+XPlDywdfUyOQOws5OBjvUC6FgvgNOpWSy4uDzFoTPpzN14nLkbj1M/yJcBLcPp2zwMf6/8W3SZOXlMWBLLZ2vzFzqtVsmL9/s3JbJ6JVtejoigsCMOJiUzh7jzF4Abm1DwWga3ieDj1YfYl5DG0l3xdG9ivXljyqIv1h9lX0IaFb1cebZrXVuXc8Oq+rrzeIdaPNa+JhsPJ/HNpuMs3nGKvfGpjPl5N2N/3csdjYO4tX4AU1cc4EBi/lOA97euxv/dYfkJFEWkZPQvURzKvou9OkF+HubfuC3J39OVIW0imLLiAFNXHOD2xkFl5jaNtSWmZjIpZh8AL9xenwpebjauyHIMBgOta1amdc3KjOnViB+2xTF34zH2xqfyw7aT/LDtJJAfjib0u4lb6wfYuGIRuZTG7IhDMS8TEWy98REP31IDbzdndp9KYfmeRKudp6wZ/2ssqVm5NA3zp39UuK3LsRp/L1cGt4ng16fb8eOwttzXqhoVvFzpeVMwS0e0V9ARsUPq2RGHYo0nsS5XwcuNQdERzFh5kCkr9tOpQUC5793ZfDSJ+VtOAPB678blYiyTwWCgaXgFmoZXYNxdTWxdjoj8C/XsiEOx1pNYl/tPuxp4ujrz94lkVu47bdVz2bs8o4lXf8gflNw/Kpxm4RVsW5CIyGUUdsRhmEwm84SC9QItPzj5UlV83BnYOn/ZiCnL9//ro8iObs7GY+w+lYKfhwsv3F7P1uWIiFxBYUccRnxKJimZuTg7GagVYJ01ji71WPuauLk4seXYedYdPGv189mjpPRs3l0aC8CzXetR2cfdxhWJiFxJYUccRsHg5JpVvHF3scy6Rv8mwM+D+1v907tTHr2zNJbkCzk0CPYz93SJiNgbhR1xGKUxOPlyj3eoiZuzExsOJ7HhUPnq3fn7xHm+2XQMgDd6N9LiqCJit/R/J3EYpTU4+VLB/p7cHZW/KOjUFQdK7by2ZjSaePXHXZhM0Ld5KC0jNEuwiNgvhR1xGOZlIqwwc/K/eaJDLVycDKw5cIYtx86V6rlt5fvNJ9h+/Dzebs6M6l7f1uWIiPwrhR1xCDl5Rg4kln7PDkB4JS/zyt5Ty8HYneSMHMYv2QvAiM51CfDzsHFFIiL/TmFHHMLhM+nk5JnwdnMmtIJnqZ9/aMfaOBng99jT/H3ifKmfvzS9/9s+zqZnUzvAh4faRti6HBGR61LYEYew95LBybaYvTeiijd9ml3s3XHgsTu7T6bwxfojALx+ZyNcNShZRMoA/Z9KHEJswWSCpTxe51JDb62NwQAxuxPYcyrFZnVYi8lk4rWfdmI0QY8mwbStXcXWJYmIFInNw05cXBwPPPAAlStXxtPTkyZNmvDXX3+ZXzeZTIwePZrg4GA8PT3p3Lkz+/cXHheRlJTEwIED8fPzo0KFCjzyyCOkpaWV9qWIDdniSazL1Q7woUeTYACmOWDvzo/bTrLpyDk8XZ15uUcDW5cjIlJkNg07586do23btri6uvLrr7+ye/du3nvvPSpWrGjeZ8KECUyZMoUZM2awYcMGvL296datG5mZmeZ9Bg4cyK5du4iJiWHRokWsWrWKxx57zBaXJDay1wZz7FzNk7fVAWDxzlPsT0i1aS2WlJqZw9uL9wAw/LbaNhkXJSJSUjYNO+PHjyc8PJxZs2bRqlUratSoQdeuXalVqxaQ36szadIkXnnlFXr37s1NN93EF198wcmTJ/nhhx8A2LNnD0uWLOGTTz6hdevW3HLLLUydOpVvvvmGkydP2vDqpLSkZeVy4twFwLY9O5Aftm5vFITJBNN+d5zenakrDnA6NYuIyl78p10NW5cjIlIsNg07P/30E1FRUdxzzz0EBATQvHlzPv74Y/Prhw8fJj4+ns6dO5u3+fv707p1a9avXw/A+vXrqVChAlFRUeZ9OnfujJOTExs2bCi9ixGbKbiFFejnTgUvNxtXk9/zAfDz9pMcOl32b6fuT0jlszWHAXjtzkalshSHiIgludjy5IcOHeLDDz9k5MiRvPzyy2zatImnnnoKNzc3Bg8eTHx8PACBgYGF3hcYGGh+LT4+noCAgEKvu7i4UKlSJfM+l8vKyiIrK8v8dUpK/mDSnJwccnJyLHZ9Bcey5DHlSrvjzgNQN8DnXz/r0mqPegFe3FqvCr/HnmHqiv1MuKuxVc9nTSaTidd+3Emu0USn+lW5pWZF/RtxYGoP+6L2uL6ifjY2DTtGo5GoqCjGjh0LQPPmzdm5cyczZsxg8ODBVjvvuHHjeP3116/YvmzZMry8vCx+vpiYGIsfU/6x7LAT4IRr+mkWL1583f1Loz2au8LvuPDj1jgac4wqZXTevW1nDaw75IyLwUQbz1MsXnzKKufRvxH7ovawL2qPa8vIyCjSfjYNO8HBwTRs2LDQtgYNGjB//nwAgoKCAEhISCA4ONi8T0JCAs2aNTPvk5iYWOgYubm5JCUlmd9/uVGjRjFy5Ejz1ykpKYSHh9O1a1f8/Cz36HJOTg4xMTF06dIFV1dXix1XCvv6003AOW6Pvok7modcc7/Sbo9NmZtZfeAs+5yr8+Adjax+PkvLyM7lf1PWAZn8t0MtHuxU2+Ln0L8R+6L2sC9qj+sruDNzPTYNO23btiU2NrbQtn379lG9enUAatSoQVBQEMuXLzeHm5SUFDZs2MATTzwBQHR0NOfPn2fz5s1ERkYCsGLFCoxGI61bt77qed3d3XF3d79iu6urq1W+oax1XMm/zRKbkD8upmFohSJ9zqXVHk93rsvqA+tZsPUkT3WuV+aeYPp4xSFOJWcSWsGTYbfVxdXVemN19G/Evqg97Iva49qK+rnYdIDyM888w59//snYsWM5cOAAc+bMYebMmQwbNgwAg8HAiBEjeOutt/jpp5/YsWMHDz74ICEhIfTp0wfI7wm6/fbbefTRR9m4cSNr165l+PDhDBgwgJCQa/+WL44hISWL5As5ODsZqB3gY+tyComKqESbWpXJyTMx44+Dti6nWA6fSWfmqkMAjO7VEE83DUoWkbLLpmGnZcuWLFy4kLlz59K4cWPefPNNJk2axMCBA837vPDCCzz55JM89thjtGzZkrS0NJYsWYKHxz+DIL7++mvq169Pp06duOOOO7jllluYOXOmLS5JStneizMn16jijYcVex5KqmDenW83HSc+OfM6e9sHk8nE6z/vIjvPSPu6VenaMPD6bxIRsWM2vY0F0LNnT3r27HnN1w0GA2+88QZvvPHGNfepVKkSc+bMsUZ5Yudi7WQywWu5uWYlWkZUZNORc3y06iCv9bL/sTvL9yTyR+xpXJ0NvNarIQZD6a81JiJiSTZfLkLkRpiXiQi0z7BjMBh4qlN+786cDcc4nZp1nXfYVmZOHq8v2gXAI7fUpFZV+7o1KCJSEgo7UqbZyzIR/+aW2lVoFl6BrFwjn6w+ZOty/tXMVYc4nnSBID8PnrzN8k9fiYjYgsKOlFm5eUYOXJyhuL4NVzu/nvzenfzg8OWfR0lKz7ZxRVd3PCmD6ReXuPi/Hg3wdrf5XW4REYtQ2JEy68jZdLJzjXi5ORNW0b4f6761XgCNQ/3IyM7j0zX22bvz1i+7yco1cnPNSvS8Kfj6bxARKSMUdqTMKriFVTfQFycn+x5EazAYzE9mfb7uKMkZ9jX9+8p9p1m6KwFnJwOv39lYg5JFxKEo7EiZZR6cbMfjdS7VpUEg9YN8ScvKZda6w7Yuxyw718jrP+UPSh4cHWHX459EREpCYUfKrLIwOPlSTk4G84ron605TGqmffTufLb2MIfOpFPFx50RXerYuhwREYtT2JEyq2BCwbISdgC6Nw6mdoAPKZm5fLH+qK3L4VTyBaYs3w/AqO718fPQlPQi4ngUdqRMSsvK5XjSBcC+n8S6nLOTgeG35vfufLL6EOlZuTatZ+zivWRk5xFZvSJ9m4fatBYREWtR2JEyaV9C/i2sAF93Knm72bia4ul5UzARlb04l5HDV3/arndn/cGz/Lz9JAYDvH5nI7sf5C0iUlJFmkijefPmRX46Y8uWLTdUkEhR2PsyEf/GxdmJYbfW5vnv/+bj1Yd4MDqi1BfazMkzMubioOSBravRONS/VM8vIlKaitSz06dPH3r37k3v3r3p1q0bBw8exN3dnY4dO9KxY0c8PDw4ePAg3bp1s3a9IkDZexLrcn2ahxJW0ZMzadnM3Xis1M//5fqjxCakUtHLlee61iv184uIlKYi9ey89tpr5r//5z//4amnnuLNN9+8Yp/jx49btjqRa/hncHLZGa9zKVdnJ4Z2rM3LC3cwY+VB7m9drdRWbU9MzeT9mH0AvHB7fSp4la3bgCIixVXsMTvz5s3jwQcfvGL7Aw88wPz58y1SlMi/MZlMZb5nB6BfZCgh/h4kpmYx76/S+0Vh/K+xpGblclOYP/dGhZfaeUVEbKXYYcfT05O1a9desX3t2rV4eHhYpCiRf3M6NYtzGTk4GaB2QNldldvdxZn/dqwFwId/HCQ712j1c24+msT8LSeA/EHJzhqULCLlQLFX+hsxYgRPPPEEW7ZsoVWrVgBs2LCBzz77jFdffdXiBYpcrmAywYgq3qV268da7o0KZ9qKA5xMzmTBlhMMaFXNaufKM5oY/eOui+cNo3m1ilY7l4iIPSl22HnppZeoWbMmkydP5quvvgKgQYMGzJo1i3vvvdfiBYpczhFuYRXwcHXm8Q61eHPRbqb/cYB+kWG4OltnRoi5G4+x62QKfh4uvHB7faucQ0TEHhUr7OTm5jJ27FgefvhhBRuxmT0Fg5MDy+bg5Mvd36oaH/5xgONJF/hx20nujgyz+DmS0rN5Z2ksAM92rUcVH3eLn0NExF4V61dIFxcXJkyYQG6ubWd9lfKtLM+xczWebs78p11NAKb/foA8o8ni53hnaSzJF3KoH+TLwNbWu1UmImKPit1f3qlTJ1auXGmNWkSuKzfPyP7ENAAaBDtG2AEYdHN1Knq5cvhMOov+PmnRY/994jzfbMqfy+eN3o1xsdJtMhERe1XsMTvdu3fnpZdeYseOHURGRuLt7V3o9TvvvNNixYlc7sjZDLJzjXi5ORNe0cvW5ViMt7sLj9xSg3eX7WPaigP0uinEIss3GC8OSjaZoE+zEFrVqGSBakVEypZih52hQ4cCMHHixCteMxgM5OXl3XhVItdQcAurTqCvw63l9GCbCGauOsT+xDSW7IrnjibBN3zM77ecYNvx83i7OTPqjgYWqFJEpOwpdn+20Wi85h8FHbG22IuDk+sHOs4trAJ+Hq481LYGAFOW78d4g2N3ki/kMP7XvQCM6FyXQD/NgyUi5ZNu3kuZstfBBidf7uG2Efi4u7A3PpXf9iTc0LHej9nH2fRsagf48FDbCMsUKCJSBhX7NhZAeno6K1eu5NixY2RnZxd67amnnrJIYSJXE5vgOHPsXE0FLzcejK7OB38cZOqKA3RpGIjBUPzbdXtOpfDF+iMAjOnVyGpz94iIlAXFDjtbt27ljjvuICMjg/T0dCpVqsSZM2fw8vIiICBAYUesJiM7l2NJGYDj9uwAPHJLDWatPcKOuGT+iD3NrfUDivV+k8nEaz/uwmiCO5oEcUudKlaqVESkbCj2r3vPPPMMvXr14ty5c3h6evLnn39y9OhRIiMjeffdd61RowgA+xLSMJmgio87lR14UrzKPu4Miq4OwJQV+zGZijd256ftJ9l4JAlPV2f+r0dDa5QoIlKmFDvsbNu2jWeffRYnJyecnZ3JysoiPDycCRMm8PLLL1ujRhHgksHJDtyrU+A/7Wrg7uLE1mPnWXvgbJHfl5aVy9u/7AFg+G21Ca3gaa0SRUTKjGKHHVdXV5yc8t8WEBDAsWP5k5X5+/tz/Phxy1Yncok9pxx7cPKlAnw9uO/ioqBTVuwv8vumLN9PYmoWEZW9+E+7GtYqT0SkTCl22GnevDmbNm0CoEOHDowePZqvv/6aESNG0LhxY4sXKFLA0ZaJuJ7/dqiFm7MTGw8n8eeh6/fuHEhM5bM1hwF4rVcj3F3K9orwIiKWUuywM3bsWIKD8yc7e/vtt6lYsSJPPPEEp0+fZubMmRYvUATyB90WPInVIMgxFgC9niB/D+5tmb8o6NTr9O6YTCbG/LSbXKOJzg0Cij2oWUTEkRX7aayoqCjz3wMCAliyZIlFCxK5mtNpWSSlZ+NkgDqBPrYup9T8t0Mtvtl4nLUHzrL5aBKR1a++3MOSnfGsOXAGNxcnXu2pQckiIpcqds/OZ599xuHDh61Ri8g1FdzCiqjsjYdr+bk9E1bRi7sj83t3piw/cNV9LmTn8eai3QD8t31Nqlf2vup+IiLlVbHDzrhx46hduzbVqlVj0KBBfPLJJxw4cPX/CYtYSnkbr3OpoR1r4+xkYOW+02w/fv6K16f/foCTyZmEVvDkiY61S79AERE7V+yws3//fo4dO8a4cePw8vLi3XffpV69eoSFhfHAAw9Yo0YRh18m4t9Uq+xF72YhAExdUfgXiyNn0pm56hAAr/ZsiKdb+en1EhEpqhLNIR8aGsrAgQN5//33mTx5MoMGDSIhIYFvvvnG0vWJAP/07JSHOXauZtittTEY4Lc9Cew6mWze/sai3WTnGWlXpwrdGgXasEIREftV7LCzbNkyXn75Zdq0aUPlypUZNWoUFStW5Pvvv+f06dPWqFHKuTyjiX0JBT075eNJrMvVqupDr5vye3emXezdWb4ngRV7E3F1NjDmzkYlWkNLRKQ8KPbTWLfffjtVq1bl2WefZfHixVSoUMEKZYn84+jZdLJyjXi4OlGtkpety7GZ4bfV5qftJ/l1Zzw7TiTz+s/5g5IfvqUGtaqWnyfURESKq9g9OxMnTqRt27ZMmDCBRo0acf/99zNz5kz27dtnjfpEzLew6gb64uxUfnsv6gb60r1xEACDPtvAsaQMAv3ceeq2OjauTETEvhU77IwYMYIFCxZw5swZlixZQps2bViyZAmNGzcmLCzMGjVKObenYHByYPkcr3Op4bflP211PiMHgP/r0RBv92J30IqIlCslGqBsMpnYsmULMTExLF26lN9//x2j0UjVqlUtXZ+IeQHQ8vgk1uUahfjTuUH+QOTWNSrR66ZgG1ckImL/iv0rYa9evVi7di0pKSk0bdqUjh078uijj9K+fXuN3xGrKLiN1SC4fA5OvtzYvo2pG+jDg9ERGpQsIlIExQ479evX5/HHH6ddu3b4+/tboyYRs4zsXI4mZQDq2SkQ4OfBC7fXt3UZIiJlRrHDzjvvvGP+e2ZmJh4eHhYtSORS+xPSMJmgio8bVXzcbV2OiIiUQcUes2M0GnnzzTcJDQ3Fx8eHQ4cuzt766qt8+umnFi9QyrfyvEyEiIhYRrHDzltvvcXs2bOZMGECbm5u5u2NGzfmk08+sWhxIuZlIgI1XkdEREqm2GHniy++YObMmQwcOBBn53/W4WnatCl79+61aHEisQn5T2KV12UiRETkxhU77MTFxVG79pUrKxuNRnJycixSlEgB3cYSEZEbVeyw07BhQ1avXn3F9u+//57mzZtbpCgRgDNpWZxJy8ZgyJ89WEREpCSK/TTW6NGjGTx4MHFxcRiNRhYsWEBsbCxffPEFixYtskaNUk4V9OpUr+SFp5vzdfYWERG5umL37PTu3Zuff/6Z3377DW9vb0aPHs2ePXv4+eef6dKlizVqlHJqzynNnCwiIjeuRIvqtGvXjpiYmCu2//XXX0RFRd1wUSLwT89O/SA9iSUiIiVX7J6dtLQ0Lly4UGjbtm3b6NWrF61bt7ZYYSKxCQVhRz07IiJSckUOO8ePHyc6Ohp/f3/8/f0ZOXIkGRkZPPjgg7Ru3Rpvb2/WrVtnzVqlHMkzmtiXoCexRETkxhX5Ntbzzz9PZmYmkydPZsGCBUyePJnVq1fTunVrDh48SFhYmDXrlHLmWFIGmTlGPFydqF7Z29bliIhIGVbksLNq1SoWLFjAzTffzL333ktQUBADBw5kxIgRVixPyqvY+PzByXUCfHF20sreIiJSckW+jZWQkECNGjUACAgIwMvLi+7du1utMCnf9moyQRERsZBiDVB2cnIq9PdL18YSsaR/nsRS2BERkRtT5NtYJpOJunXrYjDk31JIS0ujefPmhQIQQFJSkmUrlHJJy0SIiIilFDnszJo1y5p1iJhl5uRx5Gw6oLAjIiI3rshhZ/DgwdasQ8Rsf0IaRhNU8najqo+7rcsREZEyrtiTCopY256LT2LVC/Q13zYVEREpKYUdsTvmwcnBuoUlIiI3TmFH7I6exBIREUtS2BG7888cO1oAVEREbpzCjtiVs2lZnEnLwmCAuoE+ti5HREQcQJGfxiqQl5fH7NmzWb58OYmJiRiNxkKvr1ixwmLFSflTcAurWiUvvNyK/e0pIiJyhWL37Dz99NM8/fTT5OXl0bhxY5o2bVroT0n973//w2AwFFprKzMzk2HDhlG5cmV8fHzo168fCQkJhd537NgxevTogZeXFwEBATz//PPk5uaWuA6xLfMtrECN1xEREcso9q/O33zzDd999x133HGHxYrYtGkTH330ETfddFOh7c888wy//PIL8+bNw9/fn+HDh3PXXXexdu1aIL+XqUePHgQFBbFu3TpOnTrFgw8+iKurK2PHjrVYfVJ6NDhZREQsrdg9O25ubtSuXdtiBaSlpTFw4EA+/vhjKlasaN6enJzMp59+ysSJE7ntttuIjIxk1qxZrFu3jj///BOAZcuWsXv3br766iuaNWtG9+7defPNN5k+fTrZ2dkWq1FKz94EDU4WERHLKnbPzrPPPsvkyZOZNm2aRSZ8GzZsGD169KBz58689dZb5u2bN28mJyeHzp07m7fVr1+fatWqsX79em6++WbWr19PkyZNCAwMNO/TrVs3nnjiCXbt2kXz5s2ves6srCyysrLMX6ek5E9il5OTQ05Ozg1fU4GCY1nymI7MaDSx/2LYqVXF0+Kfm9rD/qhN7Ivaw76oPa6vqJ9NscPOmjVr+P333/n1119p1KgRrq6uhV5fsGBBkY/1zTffsGXLFjZt2nTFa/Hx8bi5uVGhQoVC2wMDA4mPjzfvc2nQKXi94LVrGTduHK+//voV25ctW4aXl1eR6y+qmJgYix/TEZ3JhIxsF1wMJnZvXEmslSZPVnvYH7WJfVF72Be1x7VlZGQUab9ih50KFSrQt2/fYhd0uePHj/P0008TExODh4fHDR+vOEaNGsXIkSPNX6ekpBAeHk7Xrl3x87Pc7ZOcnBxiYmLo0qXLFaFQrrRsdwJs3U7dID969Yi2+PHVHvZHbWJf1B72Re1xfQV3Zq6n2GHHUqufb968mcTERFq0aGHelpeXx6pVq5g2bRpLly4lOzub8+fPF+rdSUhIICgoCICgoCA2btxY6LgFT2sV7HM17u7uuLtfucCkq6urVb6hrHVcR3Pg9AUAGgT7W/XzUnvYH7WJfVF72Be1x7UV9XOx2aSCnTp1YseOHWzbts38JyoqioEDB5r/7urqyvLly83viY2N5dixY0RH5//WHx0dzY4dO0hMTDTvExMTg5+fHw0bNiz1a5IbE5uQn9D1JJaIiFhSiWZt+/777/nuu+84duzYFU89bdmypUjH8PX1pXHjxoW2eXt7U7lyZfP2Rx55hJEjR1KpUiX8/Px48skniY6O5uabbwaga9euNGzYkEGDBjFhwgTi4+N55ZVXGDZs2FV7bsS+/bNMhMKOiIhYTrF7dqZMmcKQIUMIDAxk69attGrVisqVK3Po0CG6d+9u0eLef/99evbsSb9+/Wjfvj1BQUGFBkA7OzuzaNEinJ2diY6O5oEHHuDBBx/kjTfesGgdYn2ZOXkcOZMOqGdHREQsq9g9Ox988AEzZ87kvvvuY/bs2bzwwgvUrFmT0aNHk5SUdEPF/PHHH4W+9vDwYPr06UyfPv2a76levTqLFy++ofOK7R1ITMNogoperlT1Va+ciIhYTrF7do4dO0abNm0A8PT0JDU1/9bDoEGDmDt3rmWrk3Lj0ltYlpi/SUREpECxw05QUJC5B6datWrm2YwPHz6MyWSybHVSbsTGFwxO1szJIiJiWcUOO7fddhs//fQTAEOGDOGZZ56hS5cu9O/f3yLz70j5pMHJIiJiLcUeszNz5kyMRiOAeUXydevWceedd/L4449bvEApH2IVdkRExEqKHXacnJxwcvqnQ2jAgAEMGDDAokVJ+ZKUnk1iav5aZXUDFXZERMSySjSp4OrVq3nggQeIjo4mLi4OgC+//JI1a9ZYtDgpH/ZeHK8TXskTH/cSTf0kIiJyTcUOO/Pnz6dbt254enqydetW8+rhycnJjB071uIFiuMruIWlwckiImINxQ47b731FjNmzODjjz8utCZF27Ztizx7ssil/gk7uoUlIiKWV+ywExsbS/v27a/Y7u/vz/nz5y1Rk5QzehJLRESsqUTz7Bw4cOCK7WvWrKFmzZoWKUrKD6PRxL4E9eyIiIj1FDvsPProozz99NNs2LABg8HAyZMn+frrr3nuued44oknrFGjOLAT5y6QkZ2Hm4sTEZW9bV2OiIg4oGI/+vLSSy9hNBrp1KkTGRkZtG/fHnd3d5577jmefPJJa9QoDqzgSazaVX1wcS7Rw4EiIiL/qthhx2Aw8H//9388//zzHDhwgLS0NBo2bIiPj4816hMHp8HJIiJibSWe1MTNzY2GDRtashYph/YmaHCyiIhYV5HDzsMPP1yk/T777LMSFyPlj5aJEBERayty2Jk9ezbVq1enefPmWt1cLCIzJ4/DZ9IBTSgoIiLWU+Sw88QTTzB37lwOHz7MkCFDeOCBB6hUqZI1axMHdyAxjTyjiQpergT6udu6HBERcVBFfvxl+vTpnDp1ihdeeIGff/6Z8PBw7r33XpYuXaqeHikR8y2sQF8MBoONqxEREUdVrGd93d3due+++4iJiWH37t00atSIoUOHEhERQVpamrVqFAcVq8kERUSkFJR4YhMnJycMBgMmk4m8vDxL1iTlxD/LRGi8joiIWE+xwk5WVhZz586lS5cu1K1blx07djBt2jSOHTumeXak2GIvTiioJ7FERMSaijxAeejQoXzzzTeEh4fz8MMPM3fuXKpUqWLN2sSBnc/IJiElC1DYERER6ypy2JkxYwbVqlWjZs2arFy5kpUrV151vwULFlisOHFcBbewwip64uNe4rktRURErqvIP2UefPBBPTEjFqNlIkREpLQUa1JBEUvZq5mTRUSklGiZabGJfwYn60ksERGxLoUdKXVGo4l9CfnzMuk2loiIWJvCjpS6uPMXSMvKxc3ZiRpVvG1djoiIODiFHSl1BeN1agX44Oqsb0EREbEu/aSRUlcwXke3sEREpDQo7Eip05NYIiJSmhR2pNTFKuyIiEgpUtiRUpWVm8ehM+mAbmOJiEjpUNiRUnUwMZ08owk/DxeC/DxsXY6IiJQDCjtSqmITCgYn+2n5ERERKRUKO1KqNDhZRERKm8KOlCoNThYRkdKmsCOlSqudi4hIaVPYkVKTnJHDqeRMAOoq7IiISClR2JFSs/fizMmhFTzx83C1cTUiIlJeKOxIqYlN0C0sEREpfQo7Umr0JJaIiNiCwo6UGj2JJSIitqCwI6XCZDKxz/wklp+NqxERkfJEYUdKRdz5C6Rm5eLqbKBmVW9blyMiIuWIwo6UioJbWLWq+uDqrG87EREpPfqpI6VCg5NFRMRWFHakVGhwsoiI2IrCjpQKLRMhIiK2orAjVpeda+Tg6TRAT2KJiEjpU9gRqzt4Oo1cowlfDxeC/T1sXY6IiJQzCjtidZfewjIYDDauRkREyhuFHbE6PYklIiK2pLAjVhd7cbXzehqvIyIiNqCwI1anJ7FERMSWFHbEqpIv5HAyOROAuoEKOyIiUvoUdsSq9iXk9+qE+Hvg7+lq42pERKQ8UtgRq9LgZBERsTWFHbEqDU4WERFbU9gRq9p7Kr9np0GwenZERMQ2FHbEakwmE7EJuo0lIiK2pbAjVnMyOZPUzFxcnAzUrOJj63JERKScUtgRqykYr1Orqg9uLvpWExER29BPILEaPYklIiL2QGFHrCZWYUdEROyAwo5YjZaJEBERe2DTsDNu3DhatmyJr68vAQEB9OnTh9jY2EL7ZGZmMmzYMCpXroyPjw/9+vUjISGh0D7Hjh2jR48eeHl5ERAQwPPPP09ubm5pXopcJifPyMHTaYB6dkRExLZsGnZWrlzJsGHD+PPPP4mJiSEnJ4euXbuSnp5u3ueZZ57h559/Zt68eaxcuZKTJ09y1113mV/Py8ujR48eZGdns27dOj7//HNmz57N6NGjbXFJctGh0+nk5JnwdXchtIKnrcsREZFyzMWWJ1+yZEmhr2fPnk1AQACbN2+mffv2JCcn8+mnnzJnzhxuu+02AGbNmkWDBg34888/ufnmm1m2bBm7d+/mt99+IzAwkGbNmvHmm2/y4osvMmbMGNzc3GxxaeXe3otPYtUN8sVgMNi4GhERKc/sasxOcnIyAJUqVQJg8+bN5OTk0LlzZ/M+9evXp1q1aqxfvx6A9evX06RJEwIDA837dOvWjZSUFHbt2lWK1culNDhZRETshU17di5lNBoZMWIEbdu2pXHjxgDEx8fj5uZGhQoVCu0bGBhIfHy8eZ9Lg07B6wWvXU1WVhZZWVnmr1NS8nshcnJyyMnJscj1FBzv0v+WJ7tP5gfXulW97Ob6y3N72Cu1iX1Re9gXtcf1FfWzsZuwM2zYMHbu3MmaNWusfq5x48bx+uuvX7F92bJleHl5Wfx8MTExFj+mvdt+xBkwkHR4J4vP7rR1OYWUx/awd2oT+6L2sC9qj2vLyMgo0n52EXaGDx/OokWLWLVqFWFhYebtQUFBZGdnc/78+UK9OwkJCQQFBZn32bhxY6HjFTytVbDP5UaNGsXIkSPNX6ekpBAeHk7Xrl3x87Pc6tw5OTnExMTQpUsXXF1dLXZce5eamcO59b8D8GDvLvh72se1l9f2sGdqE/ui9rAvao/rK7gzcz02DTsmk4knn3yShQsX8scff1CjRo1Cr0dGRuLq6sry5cvp168fALGxsRw7dozo6GgAoqOjefvtt0lMTCQgIADIT8F+fn40bNjwqud1d3fH3d39iu2urq5W+Yay1nHt1aG4/PE6wf4eVPGzfE/ZjSpv7VEWqE3si9rDvqg9rq2on4tNw86wYcOYM2cOP/74I76+vuYxNv7+/nh6euLv788jjzzCyJEjqVSpEn5+fjz55JNER0dz8803A9C1a1caNmzIoEGDmDBhAvHx8bzyyisMGzbsqoFGrE/LRIiIiD2xadj58MMPAejYsWOh7bNmzeKhhx4C4P3338fJyYl+/fqRlZVFt27d+OCDD8z7Ojs7s2jRIp544gmio6Px9vZm8ODBvPHGG6V1GXIZPYklIiL2xOa3sa7Hw8OD6dOnM3369GvuU716dRYvXmzJ0uQGaJkIERGxJ3Y1z46UfSaTyTyhYL1Ayw32FhERKSmFHbGo+JRMUjJzcXYyUCvA29bliIiIKOyIZRUMTq5ZxRt3F2cbVyMiIqKwIxamwckiImJvFHbEovaeyh+v0yBY43VERMQ+KOyIRZnn2AlUz46IiNgHhR2xmJw8IwdPpwG6jSUiIvZDYUcs5vCZdHLyTPi4uxBW0dPW5YiIiAAKO2JBBbew6gb6YDAYbFyNiIhIPoUdsZjYgskEgzQ4WURE7IfCjliMlokQERF7pLAjFqPVzkVExB4p7IhFpGXlcuLcBUA9OyIiYl8UdsQiCm5hBfq5U8HLzcbViIiI/ENhRyzin2UiNDhZRETsi8KOWMTei09iNdAtLBERsTMKO2IRGpwsIiL2SmFHbpjJZNJq5yIiYrcUduSGJaRkkXwhB2cnA7UDfGxdjoiISCEKO3LDCsbr1KjijbuLs42rERERKUxhR26YbmGJiIg9U9iRG2ZeJiJQYUdEROyPwo7cMD2JJSIi9kxhR25Ibp6RA6fTAKivCQVFRMQOKezIDTlyNp3sXCNebs6EVfS0dTkiIiJXUNiRG3LpLSwnJ4ONqxEREbmSwo7ckL2nLg5O1ngdERGxUwo7ckPMPTt6EktEROyUwo7ckNiE/AkFtdq5iIjYK4UdKbG0rFyOJ10AdBtLRETsl8KOlNi+hPxbWAG+7lT0drNxNSIiIlensCMlpmUiRESkLFDYkRIzLxOhsCMiInZMYUdKrGC1cw1OFhERe6awIyViMpnUsyMiImWCwo6UyOnULM5l5OBkgNoBPrYuR0RE5JoUdqRECiYTrFHFGw9XZxtXIyIicm0KO1IiBeN1tNK5iIjYO4UdKZG9euxcRETKCIUdKRHNsSMiImWFwo4UW26ekf2JaYCexBIREfunsCPFduRsBtm5RrzcnAmv6GXrckRERP6Vwo4UW8EtrDqBvjg5GWxcjYiIyL9T2JFiiy14EitQt7BERMT+KexIselJLBERKUsUdqTYYhO0TISIiJQdCjtSLBnZuRxLygDUsyMiImWDwo4Uy76ENEwmqOrrTmUfd1uXIyIicl0KO1Ise08VLBOhXh0RESkbFHakWMyDk/UkloiIlBEKO1IsWiZCRETKGoUdKTKTyXTJk1ha7VxERMoGhR0pstNpWSSlZ+NkgDqBPrYuR0REpEgUdqTICm5hRVT2xsPV2cbViIiIFI3CjhSZxuuIiEhZpLAjRaZlIkREpCxS2JEiK+jZ0Rw7IiJSlijsSJHkGU3sSyjo2dGTWCIiUnYo7EiRHD2bTlauEU9XZ6pV8rJ1OSIiIkWmsCNFUjBep26gD85OBhtXIyIiUnQKO1IkGpwsIiJllcKOFElsfP4CoBqvIyIiZY3CjhSJnsQSEZGySmFHrisjO5ejSRmAbmOJiEjZo7Aj17U/IQ2TCar4uFHFx93W5YiIiBSLwo5cl5aJEBGRsszF1gU4soSUTM5mwvFzGTg7u2AygQkwmkz5fzeZLvs6/+9css14cZ9C+xv/eR8mMJrAxOX7F3z9z/sKbcNkfq3w+f7Zr+CYS3bFA1AvUIOTRUSk7HGYsDN9+nTeeecd4uPjadq0KVOnTqVVq1Y2rWnQZ39x+KwLb2xdY9M6LKVBsHp2RESk7HGIsPPtt98ycuRIZsyYQevWrZk0aRLdunUjNjaWgIAAm9Xl7uqMq5MJVxcXDIDBYMBgAAPg5GTI/+/FbWDAyQAGw8Vtl+5/yTaniwf4Z5+L2y45ltMl5zFcuu2S9xuutv9lx7z0/VV83LmjSXDpf4giIiI3yCHCzsSJE3n00UcZMmQIADNmzOCXX37hs88+46WXXrJZXT8Pi2bx4sXccUc3XF1dbVaHiIhIeVbmw052djabN29m1KhR5m1OTk507tyZ9evXX/U9WVlZZGVlmb9OScmfMC8nJ4ecnByL1VZwLEseU0pO7WF/1Cb2Re1hX9Qe11fUz6bMh50zZ86Ql5dHYGBgoe2BgYHs3bv3qu8ZN24cr7/++hXbly1bhpeX5Re5jImJsfgxpeTUHvZHbWJf1B72Re1xbRkZGUXar8yHnZIYNWoUI0eONH+dkpJCeHg4Xbt2xc/Pck8c5eTkEBMTQ5cuXXQbyw6oPeyP2sS+qD3si9rj+gruzFxPmQ87VapUwdnZmYSEhELbExISCAoKuup73N3dcXe/cnI8V1dXq3xDWeu4UjJqD/ujNrEvag/7ova4tqJ+LmV+UkE3NzciIyNZvny5eZvRaGT58uVER0fbsDIRERGxB2W+Zwdg5MiRDB48mKioKFq1asWkSZNIT083P50lIiIi5ZdDhJ3+/ftz+vRpRo8eTXx8PM2aNWPJkiVXDFoWERGR8schwg7A8OHDGT58uK3LEBERETtT5sfsiIiIiPwbhR0RERFxaAo7IiIi4tAUdkRERMShKeyIiIiIQ1PYEREREYfmMI+e3wiTyQQUfY2NosrJySEjI4OUlBRN9W0H1B72R21iX9Qe9kXtcX0FP7cLfo5fi8IOkJqaCkB4eLiNKxEREZHiSk1Nxd/f/5qvG0zXi0PlgNFo5OTJk/j6+mIwGCx23ILV1I8fP27R1dSlZNQe9kdtYl/UHvZF7XF9JpOJ1NRUQkJCcHK69sgc9ewATk5OhIWFWe34fn5++ka1I2oP+6M2sS9qD/ui9vh3/9ajU0ADlEVERMShKeyIiIiIQ1PYsSJ3d3dee+013N3dbV2KoPawR2oT+6L2sC9qD8vRAGURERFxaOrZEREREYemsCMiIiIOTWFHREREHJrCjoiIiDg0hR0rmj59OhEREXh4eNC6dWs2btxo65LKpXHjxtGyZUt8fX0JCAigT58+xMbG2rosueh///sfBoOBESNG2LqUcisuLo4HHniAypUr4+npSZMmTfjrr79sXVa5lZeXx6uvvkqNGjXw9PSkVq1avPnmm9dd/0muTWHHSr799ltGjhzJa6+9xpYtW2jatCndunUjMTHR1qWVOytXrmTYsGH8+eefxMTEkJOTQ9euXUlPT7d1aeXepk2b+Oijj7jppptsXUq5de7cOdq2bYurqyu//voru3fv5r333qNixYq2Lq3cGj9+PB9++CHTpk1jz549jB8/ngkTJjB16lRbl1Zm6dFzK2ndujUtW7Zk2rRpQP76W+Hh4Tz55JO89NJLNq6ufDt9+jQBAQGsXLmS9u3b27qccistLY0WLVrwwQcf8NZbb9GsWTMmTZpk67LKnZdeeom1a9eyevVqW5ciF/Xs2ZPAwEA+/fRT87Z+/frh6enJV199ZcPKyi717FhBdnY2mzdvpnPnzuZtTk5OdO7cmfXr19uwMgFITk4GoFKlSjaupHwbNmwYPXr0KPTvRErfTz/9RFRUFPfccw8BAQE0b96cjz/+2NZllWtt2rRh+fLl7Nu3D4Dt27ezZs0aunfvbuPKyi4tBGoFZ86cIS8vj8DAwELbAwMD2bt3r42qEsjvYRsxYgRt27alcePGti6n3Prmm2/YsmULmzZtsnUp5d6hQ4f48MMPGTlyJC+//DKbNm3iqaeews3NjcGDB9u6vHLppZdeIiUlhfr16+Ps7ExeXh5vv/02AwcOtHVpZZbCjpQrw4YNY+fOnaxZs8bWpZRbx48f5+mnnyYmJgYPDw9bl1PuGY1GoqKiGDt2LADNmzdn586dzJgxQ2HHRr777ju+/vpr5syZQ6NGjdi2bRsjRowgJCREbVJCCjtWUKVKFZydnUlISCi0PSEhgaCgIBtVJcOHD2fRokWsWrWKsLAwW5dTbm3evJnExERatGhh3paXl8eqVauYNm0aWVlZODs727DC8iU4OJiGDRsW2tagQQPmz59vo4rk+eef56WXXmLAgAEANGnShKNHjzJu3DiFnRLSmB0rcHNzIzIykuXLl5u3GY1Gli9fTnR0tA0rK59MJhPDhw9n4cKFrFixgho1ati6pHKtU6dO7Nixg23btpn/REVFMXDgQLZt26agU8ratm17xVQM+/bto3r16jaqSDIyMnByKvzj2dnZGaPRaKOKyj717FjJyJEjGTx4MFFRUbRq1YpJkyaRnp7OkCFDbF1auTNs2DDmzJnDjz/+iK+vL/Hx8QD4+/vj6elp4+rKH19f3yvGS3l7e1O5cmWNo7KBZ555hjZt2jB27FjuvfdeNm7cyMyZM5k5c6atSyu3evXqxdtvv021atVo1KgRW7duZeLEiTz88MO2Lq3M0qPnVjRt2jTeeecd4uPjadasGVOmTKF169a2LqvcMRgMV90+a9YsHnroodItRq6qY8eOevTchhYtWsSoUaPYv38/NWrUYOTIkTz66KO2LqvcSk1N5dVXX2XhwoUkJiYSEhLCfffdx+jRo3Fzc7N1eWWSwo6IiIg4NI3ZEREREYemsCMiIiIOTWFHREREHJrCjoiIiDg0hR0RERFxaAo7IiIi4tAUdkRERMShKeyIiAARERGa1FDEQSnsiEipe+ihh+jTpw+QP3vyiBEjSu3cs2fPpkKFClds37RpE4899lip1SEipUdrY4mIQ8jOzr6hqfSrVq1qwWpExJ6oZ0dEbOahhx5i5cqVTJ48GYPBgMFg4MiRIwDs3LmT7t274+PjQ2BgIIMGDeLMmTPm93bs2JHhw4czYsQIqlSpQrdu3QCYOHEiTZo0wdvbm/DwcIYOHUpaWhoAf/zxB0OGDCE5Odl8vjFjxgBX3sY6duwYvXv3xsfHBz8/P+69914SEhLMr48ZM4ZmzZrx5ZdfEhERgb+/PwMGDCA1NdW6H5qIFJvCjojYzOTJk4mOjubRRx/l1KlTnDp1ivDwcM6fP89tt91G8+bN+euvv1iyZAkJCQnce++9hd7/+eef4+bmxtq1a5kxYwYATk5OTJkyhV27dvH555+zYsUKXnjhBQDatGnDpEmT8PPzM5/vueeeu6Iuo9FI7969SUpKYuXKlcTExHDo0CH69+9faL+DBw/yww8/sGjRIhYtWsTKlSv53//+Z6VPS0RKSrexRMRm/P39cXNzw8vLi6CgIPP2adOm0bx5c8aOHWve9tlnnxEeHs6+ffuoW7cuAHXq1GHChAmFjnnp+J+IiAjeeust/vvf//LBBx/g5uaGv78/BoOh0Pkut3z5cnbs2MHhw4cJDw8H4IsvvqBRo0Zs2rSJli1bAvmhaPbs2fj6+gIwaNAgli9fzttvv31jH4yIWJR6dkTE7mzfvp3ff/8dHx8f85/69esD+b0pBSIjI69472+//UanTp0IDQ3F19eXQYMGcfbsWTIyMop8/j179hAeHm4OOgANGzakQoUK7Nmzx7wtIiLCHHQAgoODSUxMLNa1ioj1qWdHROxOWloavXr1Yvz48Ve8FhwcbP67t7d3odeOHDlCz549eeKJJ3j77bepVKkSa9as4ZFHHiE7OxsvLy+L1unq6lroa4PBgNFotOg5ROTGKeyIiE25ubmRl5dXaFuLFi2YP38+ERERuLgU/X9Tmzdvxmg08t577+HklN9x/d133133fJdr0KABx48f5/jx4+bend27d3P+/HkaNmxY5HpExD7oNpaI2FRERAQbNmzgyJEjnDlzBqPRyLBhw0hKSuK+++5j06ZNHDx4kKVLlzJkyJB/DSq1a9cmJyeHqVOncujQIb788kvzwOVLz5eWlsby5cs5c+bMVW9vde7cmSZNmjBw4EC2bNnCxo0befDBB+nQoQNRUVEW/wxExLoUdkTEpp577jmcnZ1p2LAhVatW5dixY4SEhLB27Vry8vLo2rUrTZo0YcSIEVSoUMHcY3M1TZs2ZeLEiYwfP57GjRvz9ddfM27cuEL7tGnThv/+97/079+fqlWrXjHAGfJvR/34449UrFiR9u3b07lzZ2rWrMm3335r8esXEeszmEwmk62LEBEREbEW9eyIiIiIQ1PYEREREYemsCMiIiIOTWFHREREHJrCjoiIiDg0hR0RERFxaAo7IiIi4tAUdkRERMShKeyIiIiIQ1PYEREREYemsCMiIiIOTWFHREREHNr/A56SnfmxV2NNAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "w_nK8ook47Lq",
        "outputId": "5670869b-3ca0-4b38-e54f-e9d8b726355e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['timesteps', 'results', 'ep_lengths']\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el archivo .npz\n",
        "eval_data = np.load('./logs/eval/evaluations.npz')\n",
        "\n",
        "# Listar las claves en el archivo .npz\n",
        "print(eval_data.files)\n",
        "\n",
        "# Supongamos que el archivo tiene las claves 'results' y 'timesteps'\n",
        "# Acceder a los datos\n",
        "results = eval_data['results']\n",
        "timesteps = eval_data['timesteps']\n",
        "\n",
        "# Calcular la recompensa promedio si es necesario (depende del formato de results)\n",
        "mean_rewards = results.mean(axis=1)  # Promedio de recompensas por evaluación\n",
        "\n",
        "# Graficar las recompensas promedio\n",
        "plt.plot(timesteps, mean_rewards)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Llrm8JOy5GGg"
      },
      "source": [
        "#SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7HRNuNB5GGh",
        "outputId": "c308c0df-3b1a-4a80-b8f7-cef7bfc9a114"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model = SAC('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HA5JGyEX5GGi",
        "outputId": "00c4fcee-2499-4dd1-8b17-cd5fbd52e9e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 536      |\n",
            "|    ep_rew_mean     | 259      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 74       |\n",
            "|    total_timesteps | 5356     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -67.4    |\n",
            "|    critic_loss     | 0.563    |\n",
            "|    ent_coef        | 0.209    |\n",
            "|    ent_coef_loss   | -19.2    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 5255     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=10000, episode_reward=355.41 +/- 38.76\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 355      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95      |\n",
            "|    critic_loss     | 1.24     |\n",
            "|    ent_coef        | 0.0945   |\n",
            "|    ent_coef_loss   | -1.99    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  332.2489376\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 659      |\n",
            "|    ep_rew_mean     | 264      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 80       |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total_timesteps | 6588     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -133     |\n",
            "|    critic_loss     | 1.83     |\n",
            "|    ent_coef        | 0.0813   |\n",
            "|    ent_coef_loss   | 0.143    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 16387    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=457.80 +/- 59.38\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 458      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -141     |\n",
            "|    critic_loss     | 1.69     |\n",
            "|    ent_coef        | 0.102    |\n",
            "|    ent_coef_loss   | 0.365    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19799    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  428.5022162\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 823      |\n",
            "|    ep_rew_mean     | 355      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 101      |\n",
            "|    total_timesteps | 8226     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -153     |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    ent_coef        | 0.0869   |\n",
            "|    ent_coef_loss   | -0.863   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 27925    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=387.35 +/- 187.52\n",
            "Episode length: 824.80 +/- 217.90\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 825      |\n",
            "|    mean_reward     | 387      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -157     |\n",
            "|    critic_loss     | 2.25     |\n",
            "|    ent_coef        | 0.0878   |\n",
            "|    ent_coef_loss   | 0.521    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29699    |\n",
            "---------------------------------\n",
            "mean_reward  531.3664574\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 857      |\n",
            "|    ep_rew_mean     | 375      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 8568     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -162     |\n",
            "|    critic_loss     | 1.6      |\n",
            "|    ent_coef        | 0.0805   |\n",
            "|    ent_coef_loss   | 1.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 38167    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=340.89 +/- 175.82\n",
            "Episode length: 747.40 +/- 313.53\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 747      |\n",
            "|    mean_reward     | 341      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -159     |\n",
            "|    critic_loss     | 1.38     |\n",
            "|    ent_coef        | 0.0768   |\n",
            "|    ent_coef_loss   | -0.205   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39599    |\n",
            "---------------------------------\n",
            "mean_reward  423.1102754\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 960      |\n",
            "|    ep_rew_mean     | 425      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 118      |\n",
            "|    total_timesteps | 9598     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -155     |\n",
            "|    critic_loss     | 1.69     |\n",
            "|    ent_coef        | 0.0751   |\n",
            "|    ent_coef_loss   | -0.909   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49097    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=392.65 +/- 67.31\n",
            "Episode length: 919.20 +/- 161.60\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 919      |\n",
            "|    mean_reward     | 393      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -157     |\n",
            "|    critic_loss     | 1.43     |\n",
            "|    ent_coef        | 0.0752   |\n",
            "|    ent_coef_loss   | -0.449   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49499    |\n",
            "---------------------------------\n",
            "mean_reward  440.00213160000004\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 854      |\n",
            "|    ep_rew_mean     | 436      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 8539     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -148     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.0619   |\n",
            "|    ent_coef_loss   | -0.114   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 57938    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=560.89 +/- 48.18\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 561      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -145     |\n",
            "|    critic_loss     | 1.01     |\n",
            "|    ent_coef        | 0.0611   |\n",
            "|    ent_coef_loss   | 0.0228   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 59399    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  397.84145060000003\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 839      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 80       |\n",
            "|    time_elapsed    | 104      |\n",
            "|    total_timesteps | 8390     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 0.93     |\n",
            "|    ent_coef        | 0.0515   |\n",
            "|    ent_coef_loss   | 0.952    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 67689    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=379.09 +/- 83.08\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 379      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -135     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    ent_coef        | 0.0493   |\n",
            "|    ent_coef_loss   | 0.217    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 69299    |\n",
            "---------------------------------\n",
            "mean_reward  445.1350122\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 706      |\n",
            "|    ep_rew_mean     | 288      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 86       |\n",
            "|    total_timesteps | 7064     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -131     |\n",
            "|    critic_loss     | 0.615    |\n",
            "|    ent_coef        | 0.046    |\n",
            "|    ent_coef_loss   | 0.79     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 76263    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=480.40 +/- 104.78\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 480      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -128     |\n",
            "|    critic_loss     | 0.76     |\n",
            "|    ent_coef        | 0.0473   |\n",
            "|    ent_coef_loss   | 0.846    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 79199    |\n",
            "---------------------------------\n",
            "mean_reward  470.83217719999993\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 762      |\n",
            "|    ep_rew_mean     | 363      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 80       |\n",
            "|    time_elapsed    | 94       |\n",
            "|    total_timesteps | 7621     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -123     |\n",
            "|    critic_loss     | 0.954    |\n",
            "|    ent_coef        | 0.0457   |\n",
            "|    ent_coef_loss   | 1.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 86720    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=624.96 +/- 95.41\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 625      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -122     |\n",
            "|    critic_loss     | 0.664    |\n",
            "|    ent_coef        | 0.0446   |\n",
            "|    ent_coef_loss   | -1.65    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 89099    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  568.739937\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 797      |\n",
            "|    ep_rew_mean     | 404      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 81       |\n",
            "|    time_elapsed    | 97       |\n",
            "|    total_timesteps | 7968     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -118     |\n",
            "|    critic_loss     | 0.608    |\n",
            "|    ent_coef        | 0.0437   |\n",
            "|    ent_coef_loss   | 0.541    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 96967    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=475.14 +/- 76.67\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 475      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -117     |\n",
            "|    critic_loss     | 0.842    |\n",
            "|    ent_coef        | 0.0407   |\n",
            "|    ent_coef_loss   | 1.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 98999    |\n",
            "---------------------------------\n",
            "mean_reward  505.54319480000004\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=10000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"SAC_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "Q5-94jVdXv3t",
        "outputId": "dd8f2153-1fbc-48c8-dbbe-607db7c66c37"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLgfBRiq5GGj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el archivo .npz\n",
        "eval_data = np.load('./logs/eval/evaluations.npz')\n",
        "\n",
        "# Listar las claves en el archivo .npz\n",
        "print(eval_data.files)\n",
        "\n",
        "# Supongamos que el archivo tiene las claves 'results' y 'timesteps'\n",
        "# Acceder a los datos\n",
        "results = eval_data['results']\n",
        "timesteps = eval_data['timesteps']\n",
        "\n",
        "# Calcular la recompensa promedio si es necesario (depende del formato de results)\n",
        "mean_rewards = results.mean(axis=1)  # Promedio de recompensas por evaluación\n",
        "\n",
        "# Graficar las recompensas promedio\n",
        "plt.plot(timesteps, mean_rewards)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xDLe7q-Yiwa6"
      },
      "source": [
        "#Fase 100000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fbsgfIYEibzv"
      },
      "outputs": [],
      "source": [
        "import pybullet_envs\n",
        "env = gym.make(\"AntBulletEnv-v0\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AAEFzk3Aibzw",
        "outputId": "cc9bebd3-3ddb-4b6c-922f-c7c41c75c5af"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from stable_baselines3.common.callbacks import EvalCallback\n",
        "\n",
        "# Crear el callback de evaluación, evaluando cada 10,000 steps y guardando el mejor modelo\n",
        "eval_callback = EvalCallback(env, best_model_save_path='./logs/best_model/',\n",
        "                             log_path='./logs/eval/', eval_freq=10000,\n",
        "                             deterministic=True, render=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tCIqlBPvibzx"
      },
      "outputs": [],
      "source": [
        "MAX_AVERAGE_SCORE = 100000\n",
        "#Definimos la arquitectura de la red\n",
        "policy_kwargs = dict(activation_fn=th.nn.LeakyReLU, net_arch=[512, 512])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaH5MZloibzx"
      },
      "source": [
        "#TD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hjajd_4ibzx",
        "outputId": "385abfc3-a35e-4d4c-d213-8590e8f0cdbc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/vec_env/patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = TD3('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "thxSVVrqibzy",
        "outputId": "073ab680-4611-43ad-a8db-9c0fa73d6993"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.1    |\n",
            "|    critic_loss     | 1.5      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 625779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 139      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 190      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 196      |\n",
            "|    total_timesteps | 26750    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.3    |\n",
            "|    critic_loss     | 2.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 626049   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 206      |\n",
            "|    total_timesteps | 28054    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 1.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 627353   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 139      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 210      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 215      |\n",
            "|    total_timesteps | 29287    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 2.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 628586   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 138      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 223      |\n",
            "|    total_timesteps | 30509    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 2.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 629808   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 137      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 230      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 232      |\n",
            "|    total_timesteps | 31719    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 631018   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 136      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 241      |\n",
            "|    total_timesteps | 32941    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 1.71     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 632240   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 136      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 250      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 251      |\n",
            "|    total_timesteps | 34218    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 1.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 633517   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 259      |\n",
            "|    total_timesteps | 35434    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.6    |\n",
            "|    critic_loss     | 1.97     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 634733   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36480, episode_reward=185.03 +/- 6.02\n",
            "Episode length: 129.40 +/- 4.72\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 129      |\n",
            "|    mean_reward     | 185      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 2.71     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 635779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 270      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 270      |\n",
            "|    total_timesteps | 36742    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 2.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 636041   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 126      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 279      |\n",
            "|    total_timesteps | 37983    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 2.6      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 637282   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 290      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 287      |\n",
            "|    total_timesteps | 39208    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.1    |\n",
            "|    critic_loss     | 2.31     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 638507   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 124      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 296      |\n",
            "|    total_timesteps | 40463    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.8    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 639762   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 310      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 41779    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 2.43     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 641078   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 315      |\n",
            "|    total_timesteps | 43034    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.3    |\n",
            "|    critic_loss     | 2.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 642333   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 330      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 323      |\n",
            "|    total_timesteps | 44239    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 643538   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 333      |\n",
            "|    total_timesteps | 45473    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 2.31     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 644772   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46480, episode_reward=180.21 +/- 7.11\n",
            "Episode length: 121.60 +/- 6.34\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 122      |\n",
            "|    mean_reward     | 180      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 46480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.6    |\n",
            "|    critic_loss     | 2.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 645779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 350      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 343      |\n",
            "|    total_timesteps | 46734    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 2.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 646033   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 352      |\n",
            "|    total_timesteps | 47977    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.04     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 647276   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 370      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 360      |\n",
            "|    total_timesteps | 49221    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.3    |\n",
            "|    critic_loss     | 2.05     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 648520   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 125      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 369      |\n",
            "|    total_timesteps | 50448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.9    |\n",
            "|    critic_loss     | 2.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 649747   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 390      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 382      |\n",
            "|    total_timesteps | 52144    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 2.09     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 651443   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 391      |\n",
            "|    total_timesteps | 53374    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.5    |\n",
            "|    critic_loss     | 1.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 652673   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 410      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 400      |\n",
            "|    total_timesteps | 54641    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 1.85     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 653940   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 409      |\n",
            "|    total_timesteps | 55916    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.2    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 655215   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56480, episode_reward=180.60 +/- 2.39\n",
            "Episode length: 123.60 +/- 6.92\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 124      |\n",
            "|    mean_reward     | 181      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 56480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.9    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 655779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 185      |\n",
            "| time/              |          |\n",
            "|    episodes        | 430      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 420      |\n",
            "|    total_timesteps | 57242    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 2.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 656541   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 185      |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 429      |\n",
            "|    total_timesteps | 58499    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.5    |\n",
            "|    critic_loss     | 1.96     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 657798   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 185      |\n",
            "| time/              |          |\n",
            "|    episodes        | 450      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 437      |\n",
            "|    total_timesteps | 59703    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 659002   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 446      |\n",
            "|    total_timesteps | 60906    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 3.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 660205   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 470      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 455      |\n",
            "|    total_timesteps | 62140    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.54     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 661439   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 464      |\n",
            "|    total_timesteps | 63362    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.5    |\n",
            "|    critic_loss     | 2.02     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 662661   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 124      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 490      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 472      |\n",
            "|    total_timesteps | 64567    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 2.31     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 663866   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 124      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 481      |\n",
            "|    total_timesteps | 65764    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.9    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 665063   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66480, episode_reward=177.06 +/- 4.09\n",
            "Episode length: 117.80 +/- 3.82\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 118      |\n",
            "|    mean_reward     | 177      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 66480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 2.04     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 665779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 123      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 510      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 491      |\n",
            "|    total_timesteps | 66949    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 666248   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 122      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 520      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 499      |\n",
            "|    total_timesteps | 68130    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.7    |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 667429   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 121      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 530      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 507      |\n",
            "|    total_timesteps | 69312    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 1.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 668611   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 540      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 70508    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.9    |\n",
            "|    critic_loss     | 2.91     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 669807   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 550      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 524      |\n",
            "|    total_timesteps | 71679    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.6    |\n",
            "|    critic_loss     | 2.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 670978   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 533      |\n",
            "|    total_timesteps | 72841    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.1    |\n",
            "|    critic_loss     | 2.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 672140   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 176      |\n",
            "| time/              |          |\n",
            "|    episodes        | 570      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 541      |\n",
            "|    total_timesteps | 73991    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 1.66     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 673290   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 175      |\n",
            "| time/              |          |\n",
            "|    episodes        | 580      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 549      |\n",
            "|    total_timesteps | 75162    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2        |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 674461   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 590      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 558      |\n",
            "|    total_timesteps | 76338    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 675637   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76480, episode_reward=170.11 +/- 6.41\n",
            "Episode length: 112.40 +/- 5.46\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 112      |\n",
            "|    mean_reward     | 170      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 76480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 675779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 600      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 568      |\n",
            "|    total_timesteps | 77574    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.32     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 676873   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 610      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 576      |\n",
            "|    total_timesteps | 78753    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.9    |\n",
            "|    critic_loss     | 1.88     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 678052   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 620      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 584      |\n",
            "|    total_timesteps | 79937    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.4    |\n",
            "|    critic_loss     | 1.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 679236   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 630      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 593      |\n",
            "|    total_timesteps | 81054    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 2.31     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 680353   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 640      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 601      |\n",
            "|    total_timesteps | 82249    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -29.6    |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 681548   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 650      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 610      |\n",
            "|    total_timesteps | 83424    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.6    |\n",
            "|    critic_loss     | 2.02     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 682723   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 174      |\n",
            "| time/              |          |\n",
            "|    episodes        | 660      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 619      |\n",
            "|    total_timesteps | 84633    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.1    |\n",
            "|    critic_loss     | 1.53     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 683932   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 175      |\n",
            "| time/              |          |\n",
            "|    episodes        | 670      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 627      |\n",
            "|    total_timesteps | 85830    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.3    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 685129   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86480, episode_reward=178.79 +/- 2.85\n",
            "Episode length: 118.60 +/- 7.17\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 119      |\n",
            "|    mean_reward     | 179      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 86480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.8    |\n",
            "|    critic_loss     | 2.4      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 685779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 680      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 637      |\n",
            "|    total_timesteps | 87108    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.9    |\n",
            "|    critic_loss     | 2.52     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 686407   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 690      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 646      |\n",
            "|    total_timesteps | 88283    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 1.66     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 687582   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 700      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 654      |\n",
            "|    total_timesteps | 89443    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 688742   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 710      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 663      |\n",
            "|    total_timesteps | 90648    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.57     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 689947   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 177      |\n",
            "| time/              |          |\n",
            "|    episodes        | 720      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 672      |\n",
            "|    total_timesteps | 91881    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 2.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 691180   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 121      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 730      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 681      |\n",
            "|    total_timesteps | 93113    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 1.82     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 692412   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 121      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 740      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 690      |\n",
            "|    total_timesteps | 94331    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.88     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 693630   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 122      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 750      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 699      |\n",
            "|    total_timesteps | 95591    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.9    |\n",
            "|    critic_loss     | 2.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 694890   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96480, episode_reward=180.21 +/- 9.59\n",
            "Episode length: 122.40 +/- 11.24\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 122      |\n",
            "|    mean_reward     | 180      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 96480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 695779   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 123      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 760      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 709      |\n",
            "|    total_timesteps | 96886    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 696185   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 123      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 770      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 719      |\n",
            "|    total_timesteps | 98152    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.58     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 697451   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 122      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 780      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 727      |\n",
            "|    total_timesteps | 99357    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 698656   |\n",
            "---------------------------------\n",
            "mean_reward  192.98489439999997\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 204      |\n",
            "|    ep_rew_mean     | 203      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 147      |\n",
            "|    time_elapsed    | 13       |\n",
            "|    total_timesteps | 2036     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 701235   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 167      |\n",
            "|    ep_rew_mean     | 196      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 142      |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 3333     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 702532   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 151      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 32       |\n",
            "|    total_timesteps | 4544     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 1.56     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 703743   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 144      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 41       |\n",
            "|    total_timesteps | 5768     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.4    |\n",
            "|    critic_loss     | 1.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 704967   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6480, episode_reward=185.36 +/- 4.24\n",
            "Episode length: 121.00 +/- 4.98\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 121      |\n",
            "|    mean_reward     | 185      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6480     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.1    |\n",
            "|    critic_loss     | 2.41     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 705679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 142      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 51       |\n",
            "|    total_timesteps | 7092     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 1.86     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 706291   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 139      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 61       |\n",
            "|    total_timesteps | 8330     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 1.86     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 707529   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 137      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 70       |\n",
            "|    total_timesteps | 9584     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 2.49     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 708783   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 135      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 79       |\n",
            "|    total_timesteps | 10817    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.6    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 710016   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 134      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 12045    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.49     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 711244   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 103      |\n",
            "|    total_timesteps | 14100    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 1.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 713299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 112      |\n",
            "|    total_timesteps | 15320    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 1.82     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 714519   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=16480, episode_reward=181.99 +/- 7.11\n",
            "Episode length: 117.80 +/- 7.63\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 118      |\n",
            "|    mean_reward     | 182      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 16480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.8    |\n",
            "|    critic_loss     | 2.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 715679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 122      |\n",
            "|    total_timesteps | 16604    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.6    |\n",
            "|    critic_loss     | 2.57     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 715803   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 132      |\n",
            "|    total_timesteps | 17869    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.7    |\n",
            "|    critic_loss     | 2.43     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 717068   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 143      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 147      |\n",
            "|    total_timesteps | 20023    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 719222   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 156      |\n",
            "|    total_timesteps | 21232    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.5    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 720431   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 164      |\n",
            "|    total_timesteps | 22423    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.57     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 721622   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 170      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 173      |\n",
            "|    total_timesteps | 23636    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.5    |\n",
            "|    critic_loss     | 2.32     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 722835   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 183      |\n",
            "|    total_timesteps | 24886    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 724085   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 190      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 190      |\n",
            "|    total_timesteps | 26051    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.59     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 725250   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=26480, episode_reward=194.42 +/- 37.49\n",
            "Episode length: 197.20 +/- 166.95\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 197      |\n",
            "|    mean_reward     | 194      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.8    |\n",
            "|    critic_loss     | 2.13     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 725679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 209      |\n",
            "|    total_timesteps | 28235    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 2.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 727434   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 210      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 217      |\n",
            "|    total_timesteps | 29426    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 728625   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 225      |\n",
            "|    total_timesteps | 30597    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.7    |\n",
            "|    critic_loss     | 1.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 729796   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 139      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 230      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 234      |\n",
            "|    total_timesteps | 31791    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.8    |\n",
            "|    critic_loss     | 1.65     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 730990   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 242      |\n",
            "|    total_timesteps | 32946    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.7    |\n",
            "|    critic_loss     | 2.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 732145   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 250      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 251      |\n",
            "|    total_timesteps | 34139    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 733338   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 260      |\n",
            "|    total_timesteps | 35292    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 2.43     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 734491   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36480, episode_reward=183.83 +/- 3.32\n",
            "Episode length: 121.60 +/- 2.42\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 122      |\n",
            "|    mean_reward     | 184      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.8    |\n",
            "|    critic_loss     | 2.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 735679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 270      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 270      |\n",
            "|    total_timesteps | 36608    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 735807   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 279      |\n",
            "|    total_timesteps | 37824    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 2.46     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 737023   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 129      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 290      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 287      |\n",
            "|    total_timesteps | 38957    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.88     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 738156   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 296      |\n",
            "|    total_timesteps | 40145    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.2    |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 739344   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 310      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 304      |\n",
            "|    total_timesteps | 41295    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 2.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 740494   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 313      |\n",
            "|    total_timesteps | 42483    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 741682   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 330      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 321      |\n",
            "|    total_timesteps | 43618    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.49     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 742817   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 330      |\n",
            "|    total_timesteps | 44792    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 743991   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 350      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 338      |\n",
            "|    total_timesteps | 45978    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 2.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 745177   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46480, episode_reward=181.07 +/- 7.43\n",
            "Episode length: 119.40 +/- 3.44\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 119      |\n",
            "|    mean_reward     | 181      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 46480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 2.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 745679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 349      |\n",
            "|    total_timesteps | 47224    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.78     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 746423   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 370      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 358      |\n",
            "|    total_timesteps | 48456    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 1.97     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 747655   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 365      |\n",
            "|    total_timesteps | 49601    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 2.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 748800   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 390      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 374      |\n",
            "|    total_timesteps | 50722    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 2.33     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 749921   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 382      |\n",
            "|    total_timesteps | 51869    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 5.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 751068   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 410      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 390      |\n",
            "|    total_timesteps | 53018    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 1.59     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 752217   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 399      |\n",
            "|    total_timesteps | 54135    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.1    |\n",
            "|    critic_loss     | 3.76     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 753334   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 430      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 407      |\n",
            "|    total_timesteps | 55290    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.4    |\n",
            "|    critic_loss     | 2.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 754489   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 415      |\n",
            "|    total_timesteps | 56442    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.5    |\n",
            "|    critic_loss     | 2.09     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 755641   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56480, episode_reward=181.91 +/- 3.03\n",
            "Episode length: 113.00 +/- 1.79\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 113      |\n",
            "|    mean_reward     | 182      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 56480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.7    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 755679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 450      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 425      |\n",
            "|    total_timesteps | 57605    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 756804   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 433      |\n",
            "|    total_timesteps | 58729    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 3.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 757928   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 470      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 440      |\n",
            "|    total_timesteps | 59813    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.7    |\n",
            "|    critic_loss     | 2        |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 759012   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 448      |\n",
            "|    total_timesteps | 60935    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.5    |\n",
            "|    critic_loss     | 2.46     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 760134   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 490      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 456      |\n",
            "|    total_timesteps | 62065    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.55     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 761264   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 465      |\n",
            "|    total_timesteps | 63228    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 762427   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 510      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 473      |\n",
            "|    total_timesteps | 64366    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 763565   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 520      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 481      |\n",
            "|    total_timesteps | 65525    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 764724   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66480, episode_reward=176.89 +/- 5.78\n",
            "Episode length: 115.00 +/- 4.34\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 115      |\n",
            "|    mean_reward     | 177      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 66480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 1.79     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 765679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 530      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 491      |\n",
            "|    total_timesteps | 66710    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 2.47     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 765909   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 540      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 499      |\n",
            "|    total_timesteps | 67873    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 1.93     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 767072   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 550      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 508      |\n",
            "|    total_timesteps | 69032    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 2.17     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 768231   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 178      |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 70202    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.5    |\n",
            "|    critic_loss     | 2.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 769401   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 570      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 524      |\n",
            "|    total_timesteps | 71348    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 1.36     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 770547   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 179      |\n",
            "| time/              |          |\n",
            "|    episodes        | 580      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 533      |\n",
            "|    total_timesteps | 72504    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 771703   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 590      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 541      |\n",
            "|    total_timesteps | 73668    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.9    |\n",
            "|    critic_loss     | 2.04     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 772867   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 600      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 550      |\n",
            "|    total_timesteps | 74864    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 1.41     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 774063   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 180      |\n",
            "| time/              |          |\n",
            "|    episodes        | 610      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 559      |\n",
            "|    total_timesteps | 76084    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.5    |\n",
            "|    critic_loss     | 2.73     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 775283   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76480, episode_reward=183.26 +/- 1.40\n",
            "Episode length: 123.20 +/- 9.62\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 123      |\n",
            "|    mean_reward     | 183      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 76480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.1    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 775679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 181      |\n",
            "| time/              |          |\n",
            "|    episodes        | 620      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 568      |\n",
            "|    total_timesteps | 77285    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.6    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 776484   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 630      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 577      |\n",
            "|    total_timesteps | 78468    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 1.77     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 777667   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 640      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 592      |\n",
            "|    total_timesteps | 80533    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 2.38     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 779732   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 650      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 600      |\n",
            "|    total_timesteps | 81729    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.8    |\n",
            "|    critic_loss     | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 780928   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 660      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 609      |\n",
            "|    total_timesteps | 82893    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.6    |\n",
            "|    critic_loss     | 1.76     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 782092   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 670      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 617      |\n",
            "|    total_timesteps | 84056    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 783255   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 680      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 626      |\n",
            "|    total_timesteps | 85195    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.49     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 784394   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86480, episode_reward=192.41 +/- 3.84\n",
            "Episode length: 123.80 +/- 2.86\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 124      |\n",
            "|    mean_reward     | 192      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 86480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 3.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 785679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 690      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 639      |\n",
            "|    total_timesteps | 86946    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.1    |\n",
            "|    critic_loss     | 3.89     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 786145   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 700      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 648      |\n",
            "|    total_timesteps | 88143    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.1    |\n",
            "|    critic_loss     | 2.41     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 787342   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 141      |\n",
            "|    ep_rew_mean     | 197      |\n",
            "| time/              |          |\n",
            "|    episodes        | 710      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 663      |\n",
            "|    total_timesteps | 90184    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 2        |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 789383   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | 196      |\n",
            "| time/              |          |\n",
            "|    episodes        | 720      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 671      |\n",
            "|    total_timesteps | 91328    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 2.77     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 790527   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 140      |\n",
            "|    ep_rew_mean     | 196      |\n",
            "| time/              |          |\n",
            "|    episodes        | 730      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 679      |\n",
            "|    total_timesteps | 92511    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 791710   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 132      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 740      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 688      |\n",
            "|    total_timesteps | 93735    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 792934   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 133      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 750      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 698      |\n",
            "|    total_timesteps | 95024    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 794223   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 134      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 760      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 706      |\n",
            "|    total_timesteps | 96264    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.6    |\n",
            "|    critic_loss     | 1.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 795463   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96480, episode_reward=185.58 +/- 3.93\n",
            "Episode length: 116.20 +/- 6.37\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 116      |\n",
            "|    mean_reward     | 186      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 96480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 795679   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 135      |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 770      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 717      |\n",
            "|    total_timesteps | 97567    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 1.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 796766   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 136      |\n",
            "|    ep_rew_mean     | 197      |\n",
            "| time/              |          |\n",
            "|    episodes        | 780      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 726      |\n",
            "|    total_timesteps | 98813    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 798012   |\n",
            "---------------------------------\n",
            "mean_reward  188.48681019999998\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 209      |\n",
            "|    ep_rew_mean     | 236      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 145      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 2093     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 4.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 801192   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 166      |\n",
            "|    ep_rew_mean     | 212      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 141      |\n",
            "|    time_elapsed    | 23       |\n",
            "|    total_timesteps | 3315     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 2.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 802414   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 150      |\n",
            "|    ep_rew_mean     | 204      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 142      |\n",
            "|    time_elapsed    | 31       |\n",
            "|    total_timesteps | 4507     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 2.44     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 803606   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 142      |\n",
            "|    ep_rew_mean     | 199      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 40       |\n",
            "|    total_timesteps | 5663     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.7    |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 804762   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6480, episode_reward=190.60 +/- 7.36\n",
            "Episode length: 119.40 +/- 5.57\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 119      |\n",
            "|    mean_reward     | 191      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6480     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.3    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 805579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 136      |\n",
            "|    ep_rew_mean     | 196      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 6817     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.5    |\n",
            "|    critic_loss     | 2.88     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 805916   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 134      |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 138      |\n",
            "|    time_elapsed    | 58       |\n",
            "|    total_timesteps | 8016     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 2.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 807115   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 132      |\n",
            "|    ep_rew_mean     | 194      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 138      |\n",
            "|    time_elapsed    | 66       |\n",
            "|    total_timesteps | 9216     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 808315   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 10395    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.4    |\n",
            "|    critic_loss     | 2.45     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 809494   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 128      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 83       |\n",
            "|    total_timesteps | 11550    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.3    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 810649   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 127      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 138      |\n",
            "|    time_elapsed    | 91       |\n",
            "|    total_timesteps | 12690    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 1.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 811789   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 100      |\n",
            "|    total_timesteps | 13876    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 812975   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 109      |\n",
            "|    total_timesteps | 15092    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32      |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 814191   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 138      |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 16257    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.8    |\n",
            "|    critic_loss     | 1.66     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 815356   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=16480, episode_reward=187.31 +/- 4.03\n",
            "Episode length: 119.20 +/- 2.48\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 119      |\n",
            "|    mean_reward     | 187      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 16480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 1.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 815579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 128      |\n",
            "|    total_timesteps | 17573    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 816672   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 136      |\n",
            "|    total_timesteps | 18753    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 1.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 817852   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 144      |\n",
            "|    total_timesteps | 19908    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.4    |\n",
            "|    critic_loss     | 2.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 819007   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 170      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 153      |\n",
            "|    total_timesteps | 21039    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 820138   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 162      |\n",
            "|    total_timesteps | 22209    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 821308   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 190      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 170      |\n",
            "|    total_timesteps | 23374    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.7    |\n",
            "|    critic_loss     | 1.85     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 822473   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 178      |\n",
            "|    total_timesteps | 24524    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 1.81     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 823623   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 210      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 186      |\n",
            "|    total_timesteps | 25635    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 1.56     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 824734   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=26480, episode_reward=183.46 +/- 3.60\n",
            "Episode length: 114.80 +/- 6.91\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 115      |\n",
            "|    mean_reward     | 183      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 2.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 825579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 196      |\n",
            "|    total_timesteps | 26831    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -30.5    |\n",
            "|    critic_loss     | 1.97     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 825930   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 230      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 204      |\n",
            "|    total_timesteps | 28014    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.2    |\n",
            "|    critic_loss     | 1.52     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 827113   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 213      |\n",
            "|    total_timesteps | 29183    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.5    |\n",
            "|    critic_loss     | 1.48     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 828282   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 250      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 221      |\n",
            "|    total_timesteps | 30334    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 2.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 829433   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 229      |\n",
            "|    total_timesteps | 31485    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.5    |\n",
            "|    critic_loss     | 1.6      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 830584   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 270      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 238      |\n",
            "|    total_timesteps | 32659    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.1    |\n",
            "|    critic_loss     | 2.16     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 831758   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 246      |\n",
            "|    total_timesteps | 33828    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.8    |\n",
            "|    critic_loss     | 1.86     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 832927   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 290      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 254      |\n",
            "|    total_timesteps | 34979    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.3    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 834078   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 263      |\n",
            "|    total_timesteps | 36130    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.6    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 835229   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36480, episode_reward=193.57 +/- 2.69\n",
            "Episode length: 121.80 +/- 3.19\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 122      |\n",
            "|    mean_reward     | 194      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 835579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 310      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 273      |\n",
            "|    total_timesteps | 37399    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 1.71     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 836498   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 281      |\n",
            "|    total_timesteps | 38535    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 2.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 837634   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 330      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 39682    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.1    |\n",
            "|    critic_loss     | 1.91     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 838781   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 298      |\n",
            "|    total_timesteps | 40853    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 10.1     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 839952   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 350      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 41988    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 841087   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 315      |\n",
            "|    total_timesteps | 43174    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 842273   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 370      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 323      |\n",
            "|    total_timesteps | 44324    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 843423   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 331      |\n",
            "|    total_timesteps | 45472    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 2.21     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 844571   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46480, episode_reward=185.37 +/- 1.96\n",
            "Episode length: 111.80 +/- 2.99\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 112      |\n",
            "|    mean_reward     | 185      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 46480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 1.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 845579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 390      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 341      |\n",
            "|    total_timesteps | 46707    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.24     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 845806   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 350      |\n",
            "|    total_timesteps | 47863    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 1.8      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 846962   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 410      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 358      |\n",
            "|    total_timesteps | 49039    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 1.67     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 848138   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 366      |\n",
            "|    total_timesteps | 50185    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.09     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 849284   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 430      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 375      |\n",
            "|    total_timesteps | 51328    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 2.09     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 850427   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 383      |\n",
            "|    total_timesteps | 52500    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 2.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 851599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 450      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 391      |\n",
            "|    total_timesteps | 53650    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.5    |\n",
            "|    critic_loss     | 1.75     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 852749   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 400      |\n",
            "|    total_timesteps | 54780    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.3    |\n",
            "|    critic_loss     | 2.05     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 853879   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 470      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 407      |\n",
            "|    total_timesteps | 55909    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 855008   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56480, episode_reward=186.54 +/- 3.89\n",
            "Episode length: 113.80 +/- 3.60\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 114      |\n",
            "|    mean_reward     | 187      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 56480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34      |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 855579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 418      |\n",
            "|    total_timesteps | 57164    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.7    |\n",
            "|    critic_loss     | 1.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 856263   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 490      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 426      |\n",
            "|    total_timesteps | 58347    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 857446   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 435      |\n",
            "|    total_timesteps | 59596    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.4    |\n",
            "|    critic_loss     | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 858695   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 510      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 444      |\n",
            "|    total_timesteps | 60813    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36      |\n",
            "|    critic_loss     | 2.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 859912   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 520      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 453      |\n",
            "|    total_timesteps | 62016    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 1.91     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 861115   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 530      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 461      |\n",
            "|    total_timesteps | 63197    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.6    |\n",
            "|    critic_loss     | 1.99     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 862296   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 540      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 469      |\n",
            "|    total_timesteps | 64343    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 2.53     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 863442   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 550      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 478      |\n",
            "|    total_timesteps | 65490    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 2.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 864589   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66480, episode_reward=192.56 +/- 7.51\n",
            "Episode length: 120.00 +/- 5.97\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 120      |\n",
            "|    mean_reward     | 193      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 66480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.8    |\n",
            "|    critic_loss     | 2.13     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 865579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 488      |\n",
            "|    total_timesteps | 66703    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.2    |\n",
            "|    critic_loss     | 2.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 865802   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 120      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 570      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 497      |\n",
            "|    total_timesteps | 67885    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.4    |\n",
            "|    critic_loss     | 14.4     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 866984   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 580      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 505      |\n",
            "|    total_timesteps | 69053    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.3    |\n",
            "|    critic_loss     | 2.61     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 868152   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 119      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 590      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 513      |\n",
            "|    total_timesteps | 70202    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.5    |\n",
            "|    critic_loss     | 2.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 869301   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 600      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 522      |\n",
            "|    total_timesteps | 71378    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36      |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 870477   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 610      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 530      |\n",
            "|    total_timesteps | 72546    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 1.79     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 871645   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 620      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 540      |\n",
            "|    total_timesteps | 73720    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33      |\n",
            "|    critic_loss     | 2.26     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 872819   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 630      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 548      |\n",
            "|    total_timesteps | 74859    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.7    |\n",
            "|    critic_loss     | 2.34     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 873958   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 640      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 557      |\n",
            "|    total_timesteps | 76041    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.2    |\n",
            "|    critic_loss     | 2.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 875140   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76480, episode_reward=190.57 +/- 4.79\n",
            "Episode length: 118.80 +/- 2.04\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 119      |\n",
            "|    mean_reward     | 191      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 76480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.6    |\n",
            "|    critic_loss     | 1.76     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 875579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 650      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 567      |\n",
            "|    total_timesteps | 77267    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 876366   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 660      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 576      |\n",
            "|    total_timesteps | 78449    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 877548   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 670      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 584      |\n",
            "|    total_timesteps | 79594    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.3    |\n",
            "|    critic_loss     | 2.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 878693   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 680      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 593      |\n",
            "|    total_timesteps | 80743    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -31.2    |\n",
            "|    critic_loss     | 1.59     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 879842   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 690      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 601      |\n",
            "|    total_timesteps | 81913    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 1.64     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 881012   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 700      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 610      |\n",
            "|    total_timesteps | 83063    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 882162   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 710      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 618      |\n",
            "|    total_timesteps | 84210    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.9    |\n",
            "|    critic_loss     | 1.73     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 883309   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 720      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 627      |\n",
            "|    total_timesteps | 85357    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 2.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 884456   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86480, episode_reward=186.19 +/- 4.55\n",
            "Episode length: 114.80 +/- 2.40\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 115      |\n",
            "|    mean_reward     | 186      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 86480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.5    |\n",
            "|    critic_loss     | 1.79     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 885579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 730      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 637      |\n",
            "|    total_timesteps | 86591    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 2.05     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 885690   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 740      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 645      |\n",
            "|    total_timesteps | 87764    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.7    |\n",
            "|    critic_loss     | 1.81     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 886863   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 750      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 654      |\n",
            "|    total_timesteps | 88923    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.5    |\n",
            "|    critic_loss     | 1.75     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 888022   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 760      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 662      |\n",
            "|    total_timesteps | 90074    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.4    |\n",
            "|    critic_loss     | 2.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 889173   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 770      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 671      |\n",
            "|    total_timesteps | 91249    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.2    |\n",
            "|    critic_loss     | 2.36     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 890348   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 780      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 679      |\n",
            "|    total_timesteps | 92419    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 1.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 891518   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 790      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 688      |\n",
            "|    total_timesteps | 93586    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.9    |\n",
            "|    critic_loss     | 2.76     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 892685   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 800      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 696      |\n",
            "|    total_timesteps | 94730    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.2    |\n",
            "|    critic_loss     | 2.47     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 893829   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 810      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 705      |\n",
            "|    total_timesteps | 95895    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.6    |\n",
            "|    critic_loss     | 2.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 894994   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96480, episode_reward=194.10 +/- 1.66\n",
            "Episode length: 120.00 +/- 2.10\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 120      |\n",
            "|    mean_reward     | 194      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 96480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 895579   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 820      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 714      |\n",
            "|    total_timesteps | 97071    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.2    |\n",
            "|    critic_loss     | 1.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 896170   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 830      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 722      |\n",
            "|    total_timesteps | 98222    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.9    |\n",
            "|    critic_loss     | 2.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 897321   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 840      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 731      |\n",
            "|    total_timesteps | 99359    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 898458   |\n",
            "---------------------------------\n",
            "mean_reward  179.3430318\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 201      |\n",
            "|    ep_rew_mean     | 209      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 142      |\n",
            "|    time_elapsed    | 14       |\n",
            "|    total_timesteps | 2013     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.6    |\n",
            "|    critic_loss     | 1.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 901012   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 159      |\n",
            "|    ep_rew_mean     | 199      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 142      |\n",
            "|    time_elapsed    | 22       |\n",
            "|    total_timesteps | 3186     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.9    |\n",
            "|    critic_loss     | 5.35     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 902185   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 145      |\n",
            "|    ep_rew_mean     | 196      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 140      |\n",
            "|    time_elapsed    | 30       |\n",
            "|    total_timesteps | 4349     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.2    |\n",
            "|    critic_loss     | 2.05     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 903348   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 138      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 139      |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 5509     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35      |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 904508   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=6480, episode_reward=183.89 +/- 6.28\n",
            "Episode length: 117.40 +/- 3.07\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 117      |\n",
            "|    mean_reward     | 184      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 6480     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 905479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 134      |\n",
            "|    ep_rew_mean     | 194      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 49       |\n",
            "|    total_timesteps | 6709     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.8    |\n",
            "|    critic_loss     | 9.36     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 905708   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 130      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 57       |\n",
            "|    total_timesteps | 7810     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -32.8    |\n",
            "|    critic_loss     | 2.4      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 906809   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 128      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 65       |\n",
            "|    total_timesteps | 8948     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.5    |\n",
            "|    critic_loss     | 2        |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 907947   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 126      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 73       |\n",
            "|    total_timesteps | 10048    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.2    |\n",
            "|    critic_loss     | 2.37     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 909047   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 124      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 81       |\n",
            "|    total_timesteps | 11190    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -33.7    |\n",
            "|    critic_loss     | 2.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 910189   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 123      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 89       |\n",
            "|    total_timesteps | 12289    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.5    |\n",
            "|    critic_loss     | 2.5      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 911288   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 97       |\n",
            "|    total_timesteps | 13404    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.7    |\n",
            "|    critic_loss     | 2.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 912403   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 137      |\n",
            "|    time_elapsed    | 105      |\n",
            "|    total_timesteps | 14529    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.1    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 913528   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 114      |\n",
            "|    total_timesteps | 15706    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.3    |\n",
            "|    critic_loss     | 2.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 914705   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=16480, episode_reward=179.41 +/- 5.00\n",
            "Episode length: 109.60 +/- 1.74\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 110      |\n",
            "|    mean_reward     | 179      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 16480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -34.4    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 915479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 124      |\n",
            "|    total_timesteps | 16939    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.3    |\n",
            "|    critic_loss     | 1.76     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 915938   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 132      |\n",
            "|    total_timesteps | 18068    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.4    |\n",
            "|    critic_loss     | 2.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 917067   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 141      |\n",
            "|    total_timesteps | 19235    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 1.41     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 918234   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 170      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 148      |\n",
            "|    total_timesteps | 20345    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 13.3     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 919344   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 157      |\n",
            "|    total_timesteps | 21442    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.2    |\n",
            "|    critic_loss     | 1.82     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 920441   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 190      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 165      |\n",
            "|    total_timesteps | 22535    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.7    |\n",
            "|    critic_loss     | 2.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 921534   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 200      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 172      |\n",
            "|    total_timesteps | 23608    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.2    |\n",
            "|    critic_loss     | 1.92     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 922607   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 210      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 180      |\n",
            "|    total_timesteps | 24714    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.8    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 923713   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 220      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 188      |\n",
            "|    total_timesteps | 25809    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36      |\n",
            "|    critic_loss     | 1.83     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 924808   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=26480, episode_reward=183.53 +/- 2.52\n",
            "Episode length: 114.60 +/- 5.24\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 115      |\n",
            "|    mean_reward     | 184      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 26480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.8    |\n",
            "|    critic_loss     | 1.93     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 925479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 230      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 197      |\n",
            "|    total_timesteps | 26932    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.1    |\n",
            "|    critic_loss     | 2.34     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 925931   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 185      |\n",
            "| time/              |          |\n",
            "|    episodes        | 240      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 205      |\n",
            "|    total_timesteps | 28037    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.5    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 927036   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 185      |\n",
            "| time/              |          |\n",
            "|    episodes        | 250      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 214      |\n",
            "|    total_timesteps | 29153    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.7    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 928152   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 110      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 260      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 222      |\n",
            "|    total_timesteps | 30280    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.2    |\n",
            "|    critic_loss     | 1.5      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 929279   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 270      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 230      |\n",
            "|    total_timesteps | 31416    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.6    |\n",
            "|    critic_loss     | 1.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 930415   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 280      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 239      |\n",
            "|    total_timesteps | 32503    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.2    |\n",
            "|    critic_loss     | 2.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 931502   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 290      |\n",
            "|    fps             | 136      |\n",
            "|    time_elapsed    | 246      |\n",
            "|    total_timesteps | 33624    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.8    |\n",
            "|    critic_loss     | 1.89     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 932623   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 183      |\n",
            "| time/              |          |\n",
            "|    episodes        | 300      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 255      |\n",
            "|    total_timesteps | 34736    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.5    |\n",
            "|    critic_loss     | 2.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 933735   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 111      |\n",
            "|    ep_rew_mean     | 182      |\n",
            "| time/              |          |\n",
            "|    episodes        | 310      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 263      |\n",
            "|    total_timesteps | 35832    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -35.5    |\n",
            "|    critic_loss     | 2.17     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 934831   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=36480, episode_reward=172.73 +/- 4.60\n",
            "Episode length: 103.80 +/- 3.87\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 104      |\n",
            "|    mean_reward     | 173      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 36480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -40      |\n",
            "|    critic_loss     | 2        |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 935479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 320      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 273      |\n",
            "|    total_timesteps | 37018    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.8    |\n",
            "|    critic_loss     | 4.63     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 936017   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 330      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 281      |\n",
            "|    total_timesteps | 38120    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 937119   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 340      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 289      |\n",
            "|    total_timesteps | 39210    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 938209   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 350      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 297      |\n",
            "|    total_timesteps | 40356    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 2.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 939355   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 360      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 306      |\n",
            "|    total_timesteps | 41484    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 1.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 940483   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 184      |\n",
            "| time/              |          |\n",
            "|    episodes        | 370      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 314      |\n",
            "|    total_timesteps | 42597    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.4    |\n",
            "|    critic_loss     | 1.93     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 941596   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 186      |\n",
            "| time/              |          |\n",
            "|    episodes        | 380      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 322      |\n",
            "|    total_timesteps | 43718    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.5    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 942717   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 390      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 330      |\n",
            "|    total_timesteps | 44860    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.3    |\n",
            "|    critic_loss     | 1.9      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 943859   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 400      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 338      |\n",
            "|    total_timesteps | 45992    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.9    |\n",
            "|    critic_loss     | 2.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 944991   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=46480, episode_reward=188.69 +/- 2.45\n",
            "Episode length: 115.80 +/- 4.12\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 116      |\n",
            "|    mean_reward     | 189      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 46480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.3    |\n",
            "|    critic_loss     | 17.6     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 945479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 410      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 348      |\n",
            "|    total_timesteps | 47168    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.1    |\n",
            "|    critic_loss     | 1.99     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 946167   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 187      |\n",
            "| time/              |          |\n",
            "|    episodes        | 420      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 356      |\n",
            "|    total_timesteps | 48248    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.4    |\n",
            "|    critic_loss     | 3.39     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 947247   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 112      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 430      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 364      |\n",
            "|    total_timesteps | 49367    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.9    |\n",
            "|    critic_loss     | 2.1      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 948366   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 113      |\n",
            "|    ep_rew_mean     | 188      |\n",
            "| time/              |          |\n",
            "|    episodes        | 440      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 373      |\n",
            "|    total_timesteps | 50528    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.6    |\n",
            "|    critic_loss     | 1.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 949527   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 189      |\n",
            "| time/              |          |\n",
            "|    episodes        | 450      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 382      |\n",
            "|    total_timesteps | 51730    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.5    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 950729   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 460      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 390      |\n",
            "|    total_timesteps | 52871    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -40.1    |\n",
            "|    critic_loss     | 1.79     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 951870   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 190      |\n",
            "| time/              |          |\n",
            "|    episodes        | 470      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 398      |\n",
            "|    total_timesteps | 54009    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.6    |\n",
            "|    critic_loss     | 2.25     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 953008   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 114      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 480      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 407      |\n",
            "|    total_timesteps | 55168    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.6    |\n",
            "|    critic_loss     | 1.99     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 954167   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 490      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 416      |\n",
            "|    total_timesteps | 56312    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 1.94     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 955311   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=56480, episode_reward=187.13 +/- 4.48\n",
            "Episode length: 112.20 +/- 3.97\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 112      |\n",
            "|    mean_reward     | 187      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 56480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.3    |\n",
            "|    critic_loss     | 2.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 955479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 500      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 425      |\n",
            "|    total_timesteps | 57509    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.9    |\n",
            "|    critic_loss     | 1.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 956508   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 510      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 434      |\n",
            "|    total_timesteps | 58716    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.1    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 957715   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 520      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 443      |\n",
            "|    total_timesteps | 59861    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.7    |\n",
            "|    critic_loss     | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 958860   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 194      |\n",
            "| time/              |          |\n",
            "|    episodes        | 530      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 452      |\n",
            "|    total_timesteps | 61169    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 2.13     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 960168   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 118      |\n",
            "|    ep_rew_mean     | 194      |\n",
            "| time/              |          |\n",
            "|    episodes        | 540      |\n",
            "|    fps             | 135      |\n",
            "|    time_elapsed    | 460      |\n",
            "|    total_timesteps | 62327    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.9    |\n",
            "|    critic_loss     | 2.61     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 961326   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=66480, episode_reward=360.74 +/- 156.80\n",
            "Episode length: 822.60 +/- 354.80\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 823      |\n",
            "|    mean_reward     | 361      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 66480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.7    |\n",
            "|    critic_loss     | 2.56     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 965479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 197      |\n",
            "|    ep_rew_mean     | 223      |\n",
            "| time/              |          |\n",
            "|    episodes        | 550      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 535      |\n",
            "|    total_timesteps | 71448    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 2.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 970447   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 230      |\n",
            "| time/              |          |\n",
            "|    episodes        | 560      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 569      |\n",
            "|    total_timesteps | 76078    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.7    |\n",
            "|    critic_loss     | 11.4     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 975077   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=76480, episode_reward=187.72 +/- 2.39\n",
            "Episode length: 109.00 +/- 1.41\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 109      |\n",
            "|    mean_reward     | 188      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 76480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.2    |\n",
            "|    critic_loss     | 2.22     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 975479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 231      |\n",
            "| time/              |          |\n",
            "|    episodes        | 570      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 578      |\n",
            "|    total_timesteps | 77248    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.6    |\n",
            "|    critic_loss     | 1.58     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 976247   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 230      |\n",
            "| time/              |          |\n",
            "|    episodes        | 580      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 586      |\n",
            "|    total_timesteps | 78373    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.9    |\n",
            "|    critic_loss     | 1.75     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 977372   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 230      |\n",
            "| time/              |          |\n",
            "|    episodes        | 590      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 595      |\n",
            "|    total_timesteps | 79518    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.3    |\n",
            "|    critic_loss     | 2.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 978517   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 230      |\n",
            "| time/              |          |\n",
            "|    episodes        | 600      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 603      |\n",
            "|    total_timesteps | 80663    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.4    |\n",
            "|    critic_loss     | 2.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 979662   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 231      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    episodes        | 610      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 611      |\n",
            "|    total_timesteps | 81833    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.7    |\n",
            "|    critic_loss     | 1.68     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 980832   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 232      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    episodes        | 620      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 620      |\n",
            "|    total_timesteps | 83031    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.3    |\n",
            "|    critic_loss     | 2.7      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 982030   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 231      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    episodes        | 630      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 629      |\n",
            "|    total_timesteps | 84243    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.3    |\n",
            "|    critic_loss     | 1.98     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 983242   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 231      |\n",
            "|    ep_rew_mean     | 229      |\n",
            "| time/              |          |\n",
            "|    episodes        | 640      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 637      |\n",
            "|    total_timesteps | 85395    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 984394   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=86480, episode_reward=190.98 +/- 7.43\n",
            "Episode length: 117.20 +/- 4.58\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 117      |\n",
            "|    mean_reward     | 191      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 86480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.9    |\n",
            "|    critic_loss     | 1.87     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 985479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 152      |\n",
            "|    ep_rew_mean     | 200      |\n",
            "| time/              |          |\n",
            "|    episodes        | 650      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 647      |\n",
            "|    total_timesteps | 86598    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.1    |\n",
            "|    critic_loss     | 1.95     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 985597   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 660      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 655      |\n",
            "|    total_timesteps | 87774    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37      |\n",
            "|    critic_loss     | 2.47     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 986773   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 191      |\n",
            "| time/              |          |\n",
            "|    episodes        | 670      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 663      |\n",
            "|    total_timesteps | 88908    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37      |\n",
            "|    critic_loss     | 2.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 987907   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 680      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 672      |\n",
            "|    total_timesteps | 90042    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.8    |\n",
            "|    critic_loss     | 2.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 989041   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 192      |\n",
            "| time/              |          |\n",
            "|    episodes        | 690      |\n",
            "|    fps             | 133      |\n",
            "|    time_elapsed    | 680      |\n",
            "|    total_timesteps | 91166    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.8    |\n",
            "|    critic_loss     | 1.56     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 990165   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 700      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 688      |\n",
            "|    total_timesteps | 92336    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.5    |\n",
            "|    critic_loss     | 2.27     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 991335   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 710      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 697      |\n",
            "|    total_timesteps | 93496    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -37.4    |\n",
            "|    critic_loss     | 1.88     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 992495   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 720      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 705      |\n",
            "|    total_timesteps | 94621    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -39.6    |\n",
            "|    critic_loss     | 1.82     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 993620   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 115      |\n",
            "|    ep_rew_mean     | 193      |\n",
            "| time/              |          |\n",
            "|    episodes        | 730      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 713      |\n",
            "|    total_timesteps | 95790    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.8    |\n",
            "|    critic_loss     | 2.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 994789   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=96480, episode_reward=196.47 +/- 1.98\n",
            "Episode length: 114.60 +/- 1.36\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 115      |\n",
            "|    mean_reward     | 196      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 96480    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.8    |\n",
            "|    critic_loss     | 2.16     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 995479   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 117      |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 740      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 724      |\n",
            "|    total_timesteps | 97061    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38      |\n",
            "|    critic_loss     | 2.21     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 996060   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 750      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 732      |\n",
            "|    total_timesteps | 98199    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -36.9    |\n",
            "|    critic_loss     | 2.28     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 997198   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 116      |\n",
            "|    ep_rew_mean     | 195      |\n",
            "| time/              |          |\n",
            "|    episodes        | 760      |\n",
            "|    fps             | 134      |\n",
            "|    time_elapsed    | 740      |\n",
            "|    total_timesteps | 99340    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -38.6    |\n",
            "|    critic_loss     | 2.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 998339   |\n",
            "---------------------------------\n",
            "mean_reward  193.3244482\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=100000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"TD3_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Rv6OvqWdibzy",
        "outputId": "5986c45e-76a4-48b0-8545-a6a535093ca5"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PfsQr6vGibzz",
        "outputId": "458eb99a-71b6-4fab-d0a4-63de722f502b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['timesteps', 'results', 'ep_lengths']\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el archivo .npz\n",
        "eval_data = np.load('./logs/eval/evaluations.npz')\n",
        "\n",
        "# Listar las claves en el archivo .npz\n",
        "print(eval_data.files)\n",
        "\n",
        "# Supongamos que el archivo tiene las claves 'results' y 'timesteps'\n",
        "# Acceder a los datos\n",
        "results = eval_data['results']\n",
        "timesteps = eval_data['timesteps']\n",
        "\n",
        "# Calcular la recompensa promedio si es necesario (depende del formato de results)\n",
        "mean_rewards = results.mean(axis=1)  # Promedio de recompensas por evaluación\n",
        "\n",
        "# Graficar las recompensas promedio\n",
        "plt.plot(timesteps, mean_rewards)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yWMcdze5ibzz"
      },
      "source": [
        "#PPO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXTh7S6Kibzz",
        "outputId": "7d14e2ff-2e4c-4263-85ff-d20188c08820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model = PPO('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fdTBvz63ibz0",
        "outputId": "b917900c-0936-4d5c-d256-ed664f9b7406"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Eval num_timesteps=10000, episode_reward=10.13 +/- 0.35\n",
            "Episode length: 20.20 +/- 0.40\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 20.2        |\n",
            "|    mean_reward          | 10.1        |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 10000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016721161 |\n",
            "|    clip_fraction        | 0.188       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.3       |\n",
            "|    explained_variance   | 0.808       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.19        |\n",
            "|    n_updates            | 40          |\n",
            "|    policy_gradient_loss | -0.0229     |\n",
            "|    std                  | 0.992       |\n",
            "|    value_loss           | 1.51        |\n",
            "-----------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best mean reward!\n",
            "Eval num_timesteps=20000, episode_reward=514.16 +/- 10.39\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 514         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 20000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014140195 |\n",
            "|    clip_fraction        | 0.159       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11.1       |\n",
            "|    explained_variance   | 0.902       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.152       |\n",
            "|    n_updates            | 90          |\n",
            "|    policy_gradient_loss | -0.0184     |\n",
            "|    std                  | 0.965       |\n",
            "|    value_loss           | 0.526       |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 952      |\n",
            "|    ep_rew_mean     | 437      |\n",
            "| time/              |          |\n",
            "|    fps             | 284      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 71       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=734.08 +/- 24.39\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 734         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 30000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012018466 |\n",
            "|    clip_fraction        | 0.154       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -11         |\n",
            "|    explained_variance   | 0.514       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.5         |\n",
            "|    n_updates            | 140         |\n",
            "|    policy_gradient_loss | -0.012      |\n",
            "|    std                  | 0.951       |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=40000, episode_reward=672.99 +/- 65.57\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 673         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 40000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.023165185 |\n",
            "|    clip_fraction        | 0.24        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.8       |\n",
            "|    explained_variance   | 0.547       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.256       |\n",
            "|    n_updates            | 190         |\n",
            "|    policy_gradient_loss | -0.0298     |\n",
            "|    std                  | 0.93        |\n",
            "|    value_loss           | 1.43        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 943      |\n",
            "|    ep_rew_mean     | 468      |\n",
            "| time/              |          |\n",
            "|    fps             | 273      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 149      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=614.94 +/- 190.40\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 615         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 50000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.019236896 |\n",
            "|    clip_fraction        | 0.212       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.7       |\n",
            "|    explained_variance   | 0.334       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.325       |\n",
            "|    n_updates            | 240         |\n",
            "|    policy_gradient_loss | -0.0228     |\n",
            "|    std                  | 0.919       |\n",
            "|    value_loss           | 1.55        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=619.97 +/- 96.90\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 620         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 60000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.031101763 |\n",
            "|    clip_fraction        | 0.266       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.4       |\n",
            "|    explained_variance   | 0.963       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.132       |\n",
            "|    n_updates            | 290         |\n",
            "|    policy_gradient_loss | -0.0316     |\n",
            "|    std                  | 0.891       |\n",
            "|    value_loss           | 0.69        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 968      |\n",
            "|    ep_rew_mean     | 490      |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 227      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=699.71 +/- 93.02\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 700         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 70000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.033216305 |\n",
            "|    clip_fraction        | 0.313       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -10.3       |\n",
            "|    explained_variance   | 0.959       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.135       |\n",
            "|    n_updates            | 340         |\n",
            "|    policy_gradient_loss | -0.0426     |\n",
            "|    std                  | 0.876       |\n",
            "|    value_loss           | 0.826       |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=699.16 +/- 64.59\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 699       |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 80000     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0316465 |\n",
            "|    clip_fraction        | 0.25      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -10.1     |\n",
            "|    explained_variance   | 0.496     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.439     |\n",
            "|    n_updates            | 390       |\n",
            "|    policy_gradient_loss | -0.0525   |\n",
            "|    std                  | 0.85      |\n",
            "|    value_loss           | 2.33      |\n",
            "---------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 976      |\n",
            "|    ep_rew_mean     | 518      |\n",
            "| time/              |          |\n",
            "|    fps             | 268      |\n",
            "|    iterations      | 40       |\n",
            "|    time_elapsed    | 304      |\n",
            "|    total_timesteps | 81920    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=673.98 +/- 71.54\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 674         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 90000       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.037945464 |\n",
            "|    clip_fraction        | 0.341       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -9.9        |\n",
            "|    explained_variance   | 0.82        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.328       |\n",
            "|    n_updates            | 430         |\n",
            "|    policy_gradient_loss | -0.0547     |\n",
            "|    std                  | 0.834       |\n",
            "|    value_loss           | 1.06        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=528.18 +/- 73.79\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 528        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 100000     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.03126815 |\n",
            "|    clip_fraction        | 0.305      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -9.76      |\n",
            "|    explained_variance   | 0.892      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.154      |\n",
            "|    n_updates            | 480        |\n",
            "|    policy_gradient_loss | -0.0398    |\n",
            "|    std                  | 0.819      |\n",
            "|    value_loss           | 0.75       |\n",
            "----------------------------------------\n",
            "mean_reward  764.2115335999999\n",
            "Eval num_timesteps=9648, episode_reward=912.17 +/- 55.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 912        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 9648       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06366569 |\n",
            "|    clip_fraction        | 0.408      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -9.52      |\n",
            "|    explained_variance   | 0.881      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.144      |\n",
            "|    n_updates            | 530        |\n",
            "|    policy_gradient_loss | -0.0597    |\n",
            "|    std                  | 0.793      |\n",
            "|    value_loss           | 1.58       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=19648, episode_reward=782.65 +/- 51.37\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 783         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 19648       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.042470638 |\n",
            "|    clip_fraction        | 0.362       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -9.35       |\n",
            "|    explained_variance   | 0.834       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.115       |\n",
            "|    n_updates            | 580         |\n",
            "|    policy_gradient_loss | -0.0552     |\n",
            "|    std                  | 0.777       |\n",
            "|    value_loss           | 1.29        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.03e+03 |\n",
            "|    ep_rew_mean     | 729      |\n",
            "| time/              |          |\n",
            "|    fps             | 272      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=29648, episode_reward=811.86 +/- 35.59\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 812         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 29648       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.049001057 |\n",
            "|    clip_fraction        | 0.371       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -9.09       |\n",
            "|    explained_variance   | 0.795       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.389       |\n",
            "|    n_updates            | 630         |\n",
            "|    policy_gradient_loss | -0.0571     |\n",
            "|    std                  | 0.751       |\n",
            "|    value_loss           | 1.02        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=39648, episode_reward=850.03 +/- 113.56\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 850         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 39648       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.064493835 |\n",
            "|    clip_fraction        | 0.412       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.92       |\n",
            "|    explained_variance   | 0.868       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.212       |\n",
            "|    n_updates            | 680         |\n",
            "|    policy_gradient_loss | -0.053      |\n",
            "|    std                  | 0.738       |\n",
            "|    value_loss           | 1.37        |\n",
            "-----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.02e+03 |\n",
            "|    ep_rew_mean     | 778      |\n",
            "| time/              |          |\n",
            "|    fps             | 268      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 152      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=49648, episode_reward=960.63 +/- 51.50\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 961         |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 49648       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.062972054 |\n",
            "|    clip_fraction        | 0.396       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -8.74       |\n",
            "|    explained_variance   | 0.915       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.194       |\n",
            "|    n_updates            | 730         |\n",
            "|    policy_gradient_loss | -0.0473     |\n",
            "|    std                  | 0.72        |\n",
            "|    value_loss           | 1.22        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=59648, episode_reward=860.02 +/- 41.25\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 860        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 59648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05842471 |\n",
            "|    clip_fraction        | 0.404      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.59      |\n",
            "|    explained_variance   | 0.93       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.166      |\n",
            "|    n_updates            | 780        |\n",
            "|    policy_gradient_loss | -0.0507    |\n",
            "|    std                  | 0.707      |\n",
            "|    value_loss           | 1.54       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | 804      |\n",
            "| time/              |          |\n",
            "|    fps             | 266      |\n",
            "|    iterations      | 30       |\n",
            "|    time_elapsed    | 230      |\n",
            "|    total_timesteps | 61440    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=69648, episode_reward=876.11 +/- 94.62\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 876        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 69648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05530548 |\n",
            "|    clip_fraction        | 0.36       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.39      |\n",
            "|    explained_variance   | 0.906      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.149      |\n",
            "|    n_updates            | 830        |\n",
            "|    policy_gradient_loss | -0.0546    |\n",
            "|    std                  | 0.69       |\n",
            "|    value_loss           | 1.33       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=79648, episode_reward=988.06 +/- 62.50\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 988        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 79648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07652749 |\n",
            "|    clip_fraction        | 0.447      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.22      |\n",
            "|    explained_variance   | 0.941      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.223      |\n",
            "|    n_updates            | 870        |\n",
            "|    policy_gradient_loss | -0.0549    |\n",
            "|    std                  | 0.677      |\n",
            "|    value_loss           | 1.5        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 837        |\n",
            "| time/                   |            |\n",
            "|    fps                  | 265        |\n",
            "|    iterations           | 40         |\n",
            "|    time_elapsed         | 308        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.07242921 |\n",
            "|    clip_fraction        | 0.44       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.2       |\n",
            "|    explained_variance   | 0.939      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.126      |\n",
            "|    n_updates            | 880        |\n",
            "|    policy_gradient_loss | -0.0613    |\n",
            "|    std                  | 0.672      |\n",
            "|    value_loss           | 1.65       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=89648, episode_reward=978.49 +/- 42.32\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 978        |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 89648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08730282 |\n",
            "|    clip_fraction        | 0.456      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -8.03      |\n",
            "|    explained_variance   | 0.871      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.383      |\n",
            "|    n_updates            | 920        |\n",
            "|    policy_gradient_loss | -0.0498    |\n",
            "|    std                  | 0.66       |\n",
            "|    value_loss           | 1.51       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=99648, episode_reward=1010.74 +/- 49.84\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.01e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 99648      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.06614057 |\n",
            "|    clip_fraction        | 0.41       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.83      |\n",
            "|    explained_variance   | 0.888      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.881      |\n",
            "|    n_updates            | 970        |\n",
            "|    policy_gradient_loss | -0.0548    |\n",
            "|    std                  | 0.644      |\n",
            "|    value_loss           | 2.81       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  1018.6236358\n",
            "Eval num_timesteps=9296, episode_reward=1170.42 +/- 153.37\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.17e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 9296       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08892679 |\n",
            "|    clip_fraction        | 0.469      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -7.64      |\n",
            "|    explained_variance   | 0.874      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.982      |\n",
            "|    n_updates            | 1020       |\n",
            "|    policy_gradient_loss | -0.0578    |\n",
            "|    std                  | 0.628      |\n",
            "|    value_loss           | 3.04       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=19296, episode_reward=1476.82 +/- 49.21\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 1.48e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 19296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0985202 |\n",
            "|    clip_fraction        | 0.49      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.45     |\n",
            "|    explained_variance   | 0.862     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.553     |\n",
            "|    n_updates            | 1070      |\n",
            "|    policy_gradient_loss | -0.0442   |\n",
            "|    std                  | 0.614     |\n",
            "|    value_loss           | 2.5       |\n",
            "---------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | 1.19e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 266      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 76       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=29296, episode_reward=1528.87 +/- 59.70\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 1.53e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 29296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1018143 |\n",
            "|    clip_fraction        | 0.49      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.28     |\n",
            "|    explained_variance   | 0.825     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.736     |\n",
            "|    n_updates            | 1120      |\n",
            "|    policy_gradient_loss | -0.0436   |\n",
            "|    std                  | 0.6       |\n",
            "|    value_loss           | 3.65      |\n",
            "---------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=39296, episode_reward=1718.56 +/- 15.01\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 1.72e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 39296     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.0993392 |\n",
            "|    clip_fraction        | 0.546     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -7.14     |\n",
            "|    explained_variance   | 0.841     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.817     |\n",
            "|    n_updates            | 1170      |\n",
            "|    policy_gradient_loss | -0.0408   |\n",
            "|    std                  | 0.591     |\n",
            "|    value_loss           | 2.46      |\n",
            "---------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.01e+03 |\n",
            "|    ep_rew_mean     | 1.29e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 265      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 154      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=49296, episode_reward=1818.71 +/- 12.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 1.82e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 49296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.085943975 |\n",
            "|    clip_fraction        | 0.546       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -6.97       |\n",
            "|    explained_variance   | 0.83        |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 0.683       |\n",
            "|    n_updates            | 1220        |\n",
            "|    policy_gradient_loss | -0.0395     |\n",
            "|    std                  | 0.578       |\n",
            "|    value_loss           | 2.8         |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=59296, episode_reward=1873.20 +/- 9.22\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.87e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 59296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08798064 |\n",
            "|    clip_fraction        | 0.497      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.82      |\n",
            "|    explained_variance   | 0.787      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 0.811      |\n",
            "|    n_updates            | 1260       |\n",
            "|    policy_gradient_loss | -0.0476    |\n",
            "|    std                  | 0.568      |\n",
            "|    value_loss           | 3.12       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 1.39e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 265        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 231        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08289442 |\n",
            "|    clip_fraction        | 0.496      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.79      |\n",
            "|    explained_variance   | 0.869      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.59       |\n",
            "|    n_updates            | 1270       |\n",
            "|    policy_gradient_loss | -0.0554    |\n",
            "|    std                  | 0.566      |\n",
            "|    value_loss           | 4.2        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=69296, episode_reward=1945.36 +/- 20.24\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.95e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 69296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.24714452 |\n",
            "|    clip_fraction        | 0.529      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.62      |\n",
            "|    explained_variance   | 0.864      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.46       |\n",
            "|    n_updates            | 1310       |\n",
            "|    policy_gradient_loss | -0.0467    |\n",
            "|    std                  | 0.554      |\n",
            "|    value_loss           | 3.82       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=79296, episode_reward=2006.54 +/- 50.76\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.01e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 79296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.097867504 |\n",
            "|    clip_fraction        | 0.51        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -6.46       |\n",
            "|    explained_variance   | 0.815       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.27        |\n",
            "|    n_updates            | 1360        |\n",
            "|    policy_gradient_loss | -0.0499     |\n",
            "|    std                  | 0.544       |\n",
            "|    value_loss           | 5.26        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 1.48e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 266        |\n",
            "|    iterations           | 40         |\n",
            "|    time_elapsed         | 307        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08929118 |\n",
            "|    clip_fraction        | 0.517      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.44      |\n",
            "|    explained_variance   | 0.757      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.3        |\n",
            "|    n_updates            | 1370       |\n",
            "|    policy_gradient_loss | -0.048     |\n",
            "|    std                  | 0.543      |\n",
            "|    value_loss           | 6.5        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=89296, episode_reward=2026.07 +/- 42.00\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.03e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 89296       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.097504646 |\n",
            "|    clip_fraction        | 0.567       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -6.3        |\n",
            "|    explained_variance   | 0.814       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.52        |\n",
            "|    n_updates            | 1410        |\n",
            "|    policy_gradient_loss | -0.0365     |\n",
            "|    std                  | 0.533       |\n",
            "|    value_loss           | 4.84        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=99296, episode_reward=1580.82 +/- 694.46\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.58e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 99296      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.08517647 |\n",
            "|    clip_fraction        | 0.484      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -6.05      |\n",
            "|    explained_variance   | 0.933      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.48       |\n",
            "|    n_updates            | 1460       |\n",
            "|    policy_gradient_loss | -0.018     |\n",
            "|    std                  | 0.517      |\n",
            "|    value_loss           | 6.61       |\n",
            "----------------------------------------\n",
            "mean_reward  1537.4006133999999\n",
            "Eval num_timesteps=8944, episode_reward=2206.34 +/- 32.23\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.21e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 8944      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1085398 |\n",
            "|    clip_fraction        | 0.568     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -5.88     |\n",
            "|    explained_variance   | 0.908     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.63      |\n",
            "|    n_updates            | 1510      |\n",
            "|    policy_gradient_loss | -0.0527   |\n",
            "|    std                  | 0.507     |\n",
            "|    value_loss           | 5.72      |\n",
            "---------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=18944, episode_reward=2248.06 +/- 21.64\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.25e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 18944       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.120109186 |\n",
            "|    clip_fraction        | 0.548       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.76       |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.5         |\n",
            "|    n_updates            | 1560        |\n",
            "|    policy_gradient_loss | -0.0521     |\n",
            "|    std                  | 0.498       |\n",
            "|    value_loss           | 5.46        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.05e+03 |\n",
            "|    ep_rew_mean     | 2.09e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 273      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 74       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=28944, episode_reward=2251.79 +/- 84.68\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.25e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 28944      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12971503 |\n",
            "|    clip_fraction        | 0.615      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.63      |\n",
            "|    explained_variance   | 0.933      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.17       |\n",
            "|    n_updates            | 1610       |\n",
            "|    policy_gradient_loss | -0.0382    |\n",
            "|    std                  | 0.491      |\n",
            "|    value_loss           | 4.2        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=38944, episode_reward=2352.72 +/- 23.91\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.35e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 38944       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.105099544 |\n",
            "|    clip_fraction        | 0.58        |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.57       |\n",
            "|    explained_variance   | 0.939       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.84        |\n",
            "|    n_updates            | 1660        |\n",
            "|    policy_gradient_loss | -0.0491     |\n",
            "|    std                  | 0.487       |\n",
            "|    value_loss           | 5.03        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.02e+03 |\n",
            "|    ep_rew_mean     | 2.13e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 20       |\n",
            "|    time_elapsed    | 151      |\n",
            "|    total_timesteps | 40960    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=48944, episode_reward=2382.00 +/- 51.83\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.38e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 48944       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.091343924 |\n",
            "|    clip_fraction        | 0.517       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -5.53       |\n",
            "|    explained_variance   | 0.905       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.6         |\n",
            "|    n_updates            | 1700        |\n",
            "|    policy_gradient_loss | -0.0487     |\n",
            "|    std                  | 0.486       |\n",
            "|    value_loss           | 8.64        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=58944, episode_reward=2385.45 +/- 33.13\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.39e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 58944      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13986245 |\n",
            "|    clip_fraction        | 0.598      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.38      |\n",
            "|    explained_variance   | 0.93       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.13       |\n",
            "|    n_updates            | 1750       |\n",
            "|    policy_gradient_loss | -0.0397    |\n",
            "|    std                  | 0.476      |\n",
            "|    value_loss           | 6.3        |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.02e+03   |\n",
            "|    ep_rew_mean          | 2.15e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 269        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 227        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13037461 |\n",
            "|    clip_fraction        | 0.579      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.33      |\n",
            "|    explained_variance   | 0.916      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.82       |\n",
            "|    n_updates            | 1760       |\n",
            "|    policy_gradient_loss | -0.0344    |\n",
            "|    std                  | 0.474      |\n",
            "|    value_loss           | 7.35       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=68944, episode_reward=2514.84 +/- 44.02\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.51e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 68944      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12462538 |\n",
            "|    clip_fraction        | 0.584      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.18      |\n",
            "|    explained_variance   | 0.89       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.2        |\n",
            "|    n_updates            | 1800       |\n",
            "|    policy_gradient_loss | -0.0386    |\n",
            "|    std                  | 0.465      |\n",
            "|    value_loss           | 9.07       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=78944, episode_reward=2538.35 +/- 57.75\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.54e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 78944      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14528818 |\n",
            "|    clip_fraction        | 0.608      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.07      |\n",
            "|    explained_variance   | 0.948      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.49       |\n",
            "|    n_updates            | 1850       |\n",
            "|    policy_gradient_loss | -0.041     |\n",
            "|    std                  | 0.459      |\n",
            "|    value_loss           | 5.59       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.21e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 269        |\n",
            "|    iterations           | 40         |\n",
            "|    time_elapsed         | 304        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.20969725 |\n",
            "|    clip_fraction        | 0.654      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -5.05      |\n",
            "|    explained_variance   | 0.955      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.66       |\n",
            "|    n_updates            | 1860       |\n",
            "|    policy_gradient_loss | -0.0192    |\n",
            "|    std                  | 0.456      |\n",
            "|    value_loss           | 4.03       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=88944, episode_reward=2591.39 +/- 35.12\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.59e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 88944      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.15966299 |\n",
            "|    clip_fraction        | 0.643      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.97      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.9        |\n",
            "|    n_updates            | 1900       |\n",
            "|    policy_gradient_loss | -0.0247    |\n",
            "|    std                  | 0.452      |\n",
            "|    value_loss           | 5.84       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=98944, episode_reward=2659.05 +/- 34.24\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.66e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 98944       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.082513995 |\n",
            "|    clip_fraction        | 0.495       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.88       |\n",
            "|    explained_variance   | 0.9         |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.97        |\n",
            "|    n_updates            | 1950        |\n",
            "|    policy_gradient_loss | -0.0416     |\n",
            "|    std                  | 0.446       |\n",
            "|    value_loss           | 22.1        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  2680.6823864000003\n",
            "Eval num_timesteps=8592, episode_reward=2564.61 +/- 67.73\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.56e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 8592        |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.119624935 |\n",
            "|    clip_fraction        | 0.602       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -4.78       |\n",
            "|    explained_variance   | 0.943       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 2.79        |\n",
            "|    n_updates            | 2000        |\n",
            "|    policy_gradient_loss | -0.0463     |\n",
            "|    std                  | 0.44        |\n",
            "|    value_loss           | 8.68        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=18592, episode_reward=2655.58 +/- 30.57\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.66e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 18592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.25724134 |\n",
            "|    clip_fraction        | 0.668      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.65      |\n",
            "|    explained_variance   | 0.97       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.4        |\n",
            "|    n_updates            | 2050       |\n",
            "|    policy_gradient_loss | -0.0334    |\n",
            "|    std                  | 0.433      |\n",
            "|    value_loss           | 5.48       |\n",
            "----------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1.03e+03 |\n",
            "|    ep_rew_mean     | 2.53e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 270      |\n",
            "|    iterations      | 10       |\n",
            "|    time_elapsed    | 75       |\n",
            "|    total_timesteps | 20480    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=28592, episode_reward=2752.56 +/- 11.31\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.75e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 28592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.38230422 |\n",
            "|    clip_fraction        | 0.713      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.64      |\n",
            "|    explained_variance   | 0.962      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.39       |\n",
            "|    n_updates            | 2090       |\n",
            "|    policy_gradient_loss | 0.00762    |\n",
            "|    std                  | 0.434      |\n",
            "|    value_loss           | 6.54       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=38592, episode_reward=2678.25 +/- 45.61\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.68e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 38592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14926165 |\n",
            "|    clip_fraction        | 0.597      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.5       |\n",
            "|    explained_variance   | 0.908      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.96       |\n",
            "|    n_updates            | 2140       |\n",
            "|    policy_gradient_loss | -0.0402    |\n",
            "|    std                  | 0.426      |\n",
            "|    value_loss           | 11.9       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.52e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 268       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 152       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1252606 |\n",
            "|    clip_fraction        | 0.594     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.48     |\n",
            "|    explained_variance   | 0.939     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.42      |\n",
            "|    n_updates            | 2150      |\n",
            "|    policy_gradient_loss | -0.0424   |\n",
            "|    std                  | 0.424     |\n",
            "|    value_loss           | 7.73      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=48592, episode_reward=1971.26 +/- 890.49\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.97e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 48592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14894825 |\n",
            "|    clip_fraction        | 0.611      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.31      |\n",
            "|    explained_variance   | 0.954      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.61       |\n",
            "|    n_updates            | 2190       |\n",
            "|    policy_gradient_loss | -0.0406    |\n",
            "|    std                  | 0.416      |\n",
            "|    value_loss           | 9.01       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=58592, episode_reward=2749.87 +/- 65.07\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.75e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 58592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14414817 |\n",
            "|    clip_fraction        | 0.671      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.24      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.04       |\n",
            "|    n_updates            | 2240       |\n",
            "|    policy_gradient_loss | -0.0229    |\n",
            "|    std                  | 0.413      |\n",
            "|    value_loss           | 9.15       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.54e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 268        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 229        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09553684 |\n",
            "|    clip_fraction        | 0.534      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.22      |\n",
            "|    explained_variance   | 0.925      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.64       |\n",
            "|    n_updates            | 2250       |\n",
            "|    policy_gradient_loss | -0.0465    |\n",
            "|    std                  | 0.411      |\n",
            "|    value_loss           | 21.1       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=68592, episode_reward=2857.79 +/- 21.78\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.86e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 68592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09291061 |\n",
            "|    clip_fraction        | 0.568      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.09      |\n",
            "|    explained_variance   | 0.936      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 12.2       |\n",
            "|    n_updates            | 2290       |\n",
            "|    policy_gradient_loss | -0.046     |\n",
            "|    std                  | 0.405      |\n",
            "|    value_loss           | 15.6       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=78592, episode_reward=2841.14 +/- 52.29\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.84e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 78592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18795513 |\n",
            "|    clip_fraction        | 0.633      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -4.07      |\n",
            "|    explained_variance   | 0.965      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.21       |\n",
            "|    n_updates            | 2340       |\n",
            "|    policy_gradient_loss | -0.0333    |\n",
            "|    std                  | 0.405      |\n",
            "|    value_loss           | 7.27       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.57e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 266       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 306       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1264148 |\n",
            "|    clip_fraction        | 0.588     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -4.05     |\n",
            "|    explained_variance   | 0.951     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.57      |\n",
            "|    n_updates            | 2350      |\n",
            "|    policy_gradient_loss | -0.0384   |\n",
            "|    std                  | 0.404     |\n",
            "|    value_loss           | 12.4      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=88592, episode_reward=2858.03 +/- 141.90\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.86e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 88592       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.120171055 |\n",
            "|    clip_fraction        | 0.583       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.88       |\n",
            "|    explained_variance   | 0.861       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 17.6        |\n",
            "|    n_updates            | 2390        |\n",
            "|    policy_gradient_loss | -0.0237     |\n",
            "|    std                  | 0.395       |\n",
            "|    value_loss           | 40.9        |\n",
            "-----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=98592, episode_reward=2965.06 +/- 83.80\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.97e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 98592      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.15365744 |\n",
            "|    clip_fraction        | 0.63       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.79      |\n",
            "|    explained_variance   | 0.916      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.74       |\n",
            "|    n_updates            | 2440       |\n",
            "|    policy_gradient_loss | -0.0448    |\n",
            "|    std                  | 0.391      |\n",
            "|    value_loss           | 13.9       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  2988.0241832\n",
            "Eval num_timesteps=8240, episode_reward=3000.05 +/- 19.65\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 3e+03      |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 8240       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.15063778 |\n",
            "|    clip_fraction        | 0.684      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.75      |\n",
            "|    explained_variance   | 0.942      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.07       |\n",
            "|    n_updates            | 2490       |\n",
            "|    policy_gradient_loss | -0.0217    |\n",
            "|    std                  | 0.389      |\n",
            "|    value_loss           | 8.21       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=18240, episode_reward=2727.93 +/- 391.77\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.73e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 18240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16584334 |\n",
            "|    clip_fraction        | 0.664      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.67      |\n",
            "|    explained_variance   | 0.931      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.13       |\n",
            "|    n_updates            | 2530       |\n",
            "|    policy_gradient_loss | -0.0297    |\n",
            "|    std                  | 0.385      |\n",
            "|    value_loss           | 11.4       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.74e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 267        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 76         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11564369 |\n",
            "|    clip_fraction        | 0.567      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.66      |\n",
            "|    explained_variance   | 0.945      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.76       |\n",
            "|    n_updates            | 2540       |\n",
            "|    policy_gradient_loss | -0.046     |\n",
            "|    std                  | 0.384      |\n",
            "|    value_loss           | 22.5       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=28240, episode_reward=2982.08 +/- 27.18\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.98e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 28240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.25838324 |\n",
            "|    clip_fraction        | 0.694      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.62      |\n",
            "|    explained_variance   | 0.955      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.95       |\n",
            "|    n_updates            | 2580       |\n",
            "|    policy_gradient_loss | -0.0162    |\n",
            "|    std                  | 0.383      |\n",
            "|    value_loss           | 9.3        |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=38240, episode_reward=3015.96 +/- 69.56\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 3.02e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 38240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14792791 |\n",
            "|    clip_fraction        | 0.689      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.54      |\n",
            "|    explained_variance   | 0.935      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.12       |\n",
            "|    n_updates            | 2630       |\n",
            "|    policy_gradient_loss | -0.0186    |\n",
            "|    std                  | 0.379      |\n",
            "|    value_loss           | 9.74       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.77e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 265        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 154        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.36748698 |\n",
            "|    clip_fraction        | 0.731      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.53      |\n",
            "|    explained_variance   | 0.934      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.68       |\n",
            "|    n_updates            | 2640       |\n",
            "|    policy_gradient_loss | 0.0389     |\n",
            "|    std                  | 0.378      |\n",
            "|    value_loss           | 10.4       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=48240, episode_reward=3034.43 +/- 56.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 3.03e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 48240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09698665 |\n",
            "|    clip_fraction        | 0.57       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.54      |\n",
            "|    explained_variance   | 0.909      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.77       |\n",
            "|    n_updates            | 2680       |\n",
            "|    policy_gradient_loss | -0.0371    |\n",
            "|    std                  | 0.379      |\n",
            "|    value_loss           | 17.2       |\n",
            "----------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=58240, episode_reward=2973.33 +/- 42.49\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.97e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 58240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.05296351 |\n",
            "|    clip_fraction        | 0.487      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.47      |\n",
            "|    explained_variance   | 0.965      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.42       |\n",
            "|    n_updates            | 2730       |\n",
            "|    policy_gradient_loss | -0.054     |\n",
            "|    std                  | 0.375      |\n",
            "|    value_loss           | 39.7       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 2.76e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 264        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 232        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18792677 |\n",
            "|    clip_fraction        | 0.72       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.45      |\n",
            "|    explained_variance   | 0.939      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.84       |\n",
            "|    n_updates            | 2740       |\n",
            "|    policy_gradient_loss | 0.00193    |\n",
            "|    std                  | 0.375      |\n",
            "|    value_loss           | 11.3       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=68240, episode_reward=2770.90 +/- 107.86\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| eval/                   |          |\n",
            "|    mean_ep_length       | 1e+03    |\n",
            "|    mean_reward          | 2.77e+03 |\n",
            "| time/                   |          |\n",
            "|    total_timesteps      | 68240    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 2.112002 |\n",
            "|    clip_fraction        | 0.77     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -3.33    |\n",
            "|    explained_variance   | 0.952    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 6.67     |\n",
            "|    n_updates            | 2780     |\n",
            "|    policy_gradient_loss | 0.0109   |\n",
            "|    std                  | 0.369    |\n",
            "|    value_loss           | 11.9     |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=78240, episode_reward=2817.46 +/- 195.74\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.82e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 78240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13878097 |\n",
            "|    clip_fraction        | 0.444      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.23      |\n",
            "|    explained_variance   | 0.98       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13.6       |\n",
            "|    n_updates            | 2830       |\n",
            "|    policy_gradient_loss | -0.0332    |\n",
            "|    std                  | 0.365      |\n",
            "|    value_loss           | 21.8       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1e+03     |\n",
            "|    ep_rew_mean          | 2.68e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 263       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 310       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1288501 |\n",
            "|    clip_fraction        | 0.557     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.24     |\n",
            "|    explained_variance   | 0.976     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.83      |\n",
            "|    n_updates            | 2840      |\n",
            "|    policy_gradient_loss | -0.0331   |\n",
            "|    std                  | 0.366     |\n",
            "|    value_loss           | 19.9      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=88240, episode_reward=2821.54 +/- 90.87\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.82e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 88240       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.080660954 |\n",
            "|    clip_fraction        | 0.475       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -3.23       |\n",
            "|    explained_variance   | 0.942       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 32          |\n",
            "|    n_updates            | 2880        |\n",
            "|    policy_gradient_loss | -0.0509     |\n",
            "|    std                  | 0.365       |\n",
            "|    value_loss           | 64.2        |\n",
            "-----------------------------------------\n",
            "Eval num_timesteps=98240, episode_reward=2992.91 +/- 53.34\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.99e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 98240      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16777983 |\n",
            "|    clip_fraction        | 0.59       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.18      |\n",
            "|    explained_variance   | 0.881      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.38       |\n",
            "|    n_updates            | 2920       |\n",
            "|    policy_gradient_loss | -0.0395    |\n",
            "|    std                  | 0.362      |\n",
            "|    value_loss           | 27.6       |\n",
            "----------------------------------------\n",
            "mean_reward  3005.2935310000003\n",
            "Eval num_timesteps=7888, episode_reward=1600.69 +/- 876.50\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 1.6e+03    |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 7888       |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12021883 |\n",
            "|    clip_fraction        | 0.561      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.02      |\n",
            "|    explained_variance   | 0.971      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.45       |\n",
            "|    n_updates            | 2970       |\n",
            "|    policy_gradient_loss | -0.0436    |\n",
            "|    std                  | 0.356      |\n",
            "|    value_loss           | 11.8       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=17888, episode_reward=2338.72 +/- 695.48\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.34e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 17888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16299699 |\n",
            "|    clip_fraction        | 0.572      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.04      |\n",
            "|    explained_variance   | 0.986      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.14       |\n",
            "|    n_updates            | 3020       |\n",
            "|    policy_gradient_loss | -0.0439    |\n",
            "|    std                  | 0.357      |\n",
            "|    value_loss           | 10.2       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.05e+03   |\n",
            "|    ep_rew_mean          | 1.85e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 265        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 77         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.17068514 |\n",
            "|    clip_fraction        | 0.496      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.05      |\n",
            "|    explained_variance   | 0.995      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.51       |\n",
            "|    n_updates            | 3030       |\n",
            "|    policy_gradient_loss | -0.0371    |\n",
            "|    std                  | 0.357      |\n",
            "|    value_loss           | 6.27       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=27888, episode_reward=2806.06 +/- 77.66\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.81e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 27888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.18926655 |\n",
            "|    clip_fraction        | 0.664      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.03      |\n",
            "|    explained_variance   | 0.951      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.95       |\n",
            "|    n_updates            | 3070       |\n",
            "|    policy_gradient_loss | -0.0464    |\n",
            "|    std                  | 0.356      |\n",
            "|    value_loss           | 16.8       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=37888, episode_reward=2836.85 +/- 58.40\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.84e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 37888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.21061745 |\n",
            "|    clip_fraction        | 0.664      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -3.04      |\n",
            "|    explained_variance   | 0.904      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.33       |\n",
            "|    n_updates            | 3120       |\n",
            "|    policy_gradient_loss | -0.0365    |\n",
            "|    std                  | 0.357      |\n",
            "|    value_loss           | 11.8       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.02e+03  |\n",
            "|    ep_rew_mean          | 2.27e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 263       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 155       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2673147 |\n",
            "|    clip_fraction        | 0.707     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -3.05     |\n",
            "|    explained_variance   | 0.946     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.88      |\n",
            "|    n_updates            | 3130      |\n",
            "|    policy_gradient_loss | -0.0177   |\n",
            "|    std                  | 0.358     |\n",
            "|    value_loss           | 7.19      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=47888, episode_reward=2957.36 +/- 36.97\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.96e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 47888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.27145618 |\n",
            "|    clip_fraction        | 0.676      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.97      |\n",
            "|    explained_variance   | 0.972      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.22       |\n",
            "|    n_updates            | 3170       |\n",
            "|    policy_gradient_loss | -0.0278    |\n",
            "|    std                  | 0.353      |\n",
            "|    value_loss           | 6.84       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=57888, episode_reward=2463.00 +/- 850.11\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.46e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 57888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.58222914 |\n",
            "|    clip_fraction        | 0.711      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.87      |\n",
            "|    explained_variance   | 0.96       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.1        |\n",
            "|    n_updates            | 3220       |\n",
            "|    policy_gradient_loss | -0.00326   |\n",
            "|    std                  | 0.349      |\n",
            "|    value_loss           | 8.3        |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.44e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 263       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 233       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.7725046 |\n",
            "|    clip_fraction        | 0.726     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.87     |\n",
            "|    explained_variance   | 0.968     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.26      |\n",
            "|    n_updates            | 3230      |\n",
            "|    policy_gradient_loss | 0.0044    |\n",
            "|    std                  | 0.35      |\n",
            "|    value_loss           | 8.32      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=67888, episode_reward=2794.59 +/- 110.70\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.79e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 67888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.15753171 |\n",
            "|    clip_fraction        | 0.641      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.88      |\n",
            "|    explained_variance   | 0.95       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.68       |\n",
            "|    n_updates            | 3270       |\n",
            "|    policy_gradient_loss | -0.0313    |\n",
            "|    std                  | 0.35       |\n",
            "|    value_loss           | 14.2       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=77888, episode_reward=2844.69 +/- 38.78\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.84e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 77888     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1097507 |\n",
            "|    clip_fraction        | 0.627     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.83     |\n",
            "|    explained_variance   | 0.863     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.86      |\n",
            "|    n_updates            | 3320      |\n",
            "|    policy_gradient_loss | -0.0191   |\n",
            "|    std                  | 0.347     |\n",
            "|    value_loss           | 42.4      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.51e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 262       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 311       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2837364 |\n",
            "|    clip_fraction        | 0.678     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.81     |\n",
            "|    explained_variance   | 0.935     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.85      |\n",
            "|    n_updates            | 3330      |\n",
            "|    policy_gradient_loss | -0.0268   |\n",
            "|    std                  | 0.346     |\n",
            "|    value_loss           | 12.7      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=87888, episode_reward=2950.08 +/- 43.04\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.95e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 87888      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.24359551 |\n",
            "|    clip_fraction        | 0.671      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.81      |\n",
            "|    explained_variance   | 0.927      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.63       |\n",
            "|    n_updates            | 3360       |\n",
            "|    policy_gradient_loss | -0.0137    |\n",
            "|    std                  | 0.346      |\n",
            "|    value_loss           | 21.8       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=97888, episode_reward=2977.52 +/- 34.67\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.98e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 97888     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.0445917 |\n",
            "|    clip_fraction        | 0.681     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.79     |\n",
            "|    explained_variance   | 0.92      |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 9.75      |\n",
            "|    n_updates            | 3410      |\n",
            "|    policy_gradient_loss | -0.0115   |\n",
            "|    std                  | 0.346     |\n",
            "|    value_loss           | 20.1      |\n",
            "---------------------------------------\n",
            "mean_reward  2862.2352566\n",
            "Eval num_timesteps=7536, episode_reward=2995.14 +/- 28.67\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 3e+03     |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 7536      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1771237 |\n",
            "|    clip_fraction        | 0.668     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.76     |\n",
            "|    explained_variance   | 0.915     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.77      |\n",
            "|    n_updates            | 3460      |\n",
            "|    policy_gradient_loss | -0.0286   |\n",
            "|    std                  | 0.345     |\n",
            "|    value_loss           | 16.7      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=17536, episode_reward=2922.01 +/- 168.90\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.92e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 17536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 4.9913435 |\n",
            "|    clip_fraction        | 0.822     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.76     |\n",
            "|    explained_variance   | 0.948     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.85      |\n",
            "|    n_updates            | 3510      |\n",
            "|    policy_gradient_loss | 0.0457    |\n",
            "|    std                  | 0.345     |\n",
            "|    value_loss           | 5.56      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.03e+03  |\n",
            "|    ep_rew_mean          | 2.64e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 265       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 77        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.4157611 |\n",
            "|    clip_fraction        | 0.741     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.75     |\n",
            "|    explained_variance   | 0.907     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.21      |\n",
            "|    n_updates            | 3520      |\n",
            "|    policy_gradient_loss | 0.0323    |\n",
            "|    std                  | 0.345     |\n",
            "|    value_loss           | 15.3      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=27536, episode_reward=2663.25 +/- 66.24\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| eval/                   |          |\n",
            "|    mean_ep_length       | 1e+03    |\n",
            "|    mean_reward          | 2.66e+03 |\n",
            "| time/                   |          |\n",
            "|    total_timesteps      | 27536    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 4.881745 |\n",
            "|    clip_fraction        | 0.764    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -2.72    |\n",
            "|    explained_variance   | 0.869    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 4.6      |\n",
            "|    n_updates            | 3560     |\n",
            "|    policy_gradient_loss | 0.0395   |\n",
            "|    std                  | 0.343    |\n",
            "|    value_loss           | 15.3     |\n",
            "--------------------------------------\n",
            "Eval num_timesteps=37536, episode_reward=2621.32 +/- 60.45\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.62e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 37536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.0517762 |\n",
            "|    clip_fraction        | 0.783     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.72     |\n",
            "|    explained_variance   | 0.878     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.34      |\n",
            "|    n_updates            | 3610      |\n",
            "|    policy_gradient_loss | 0.0355    |\n",
            "|    std                  | 0.343     |\n",
            "|    value_loss           | 12.8      |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.62e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 264       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 155       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 3.2613413 |\n",
            "|    clip_fraction        | 0.762     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.71     |\n",
            "|    explained_variance   | 0.874     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.29      |\n",
            "|    n_updates            | 3620      |\n",
            "|    policy_gradient_loss | 0.0384    |\n",
            "|    std                  | 0.343     |\n",
            "|    value_loss           | 25.4      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=47536, episode_reward=2802.28 +/- 66.25\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.8e+03   |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 47536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 4.5470138 |\n",
            "|    clip_fraction        | 0.815     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.66     |\n",
            "|    explained_variance   | 0.955     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 0.77      |\n",
            "|    n_updates            | 3660      |\n",
            "|    policy_gradient_loss | 0.0434    |\n",
            "|    std                  | 0.341     |\n",
            "|    value_loss           | 4.81      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=57536, episode_reward=2899.36 +/- 95.94\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.9e+03    |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 57536      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.47828406 |\n",
            "|    clip_fraction        | 0.767      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.65      |\n",
            "|    explained_variance   | 0.95       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.45       |\n",
            "|    n_updates            | 3710       |\n",
            "|    policy_gradient_loss | 0.0207     |\n",
            "|    std                  | 0.341      |\n",
            "|    value_loss           | 6.41       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.66e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 263        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 232        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.22984648 |\n",
            "|    clip_fraction        | 0.704      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.67      |\n",
            "|    explained_variance   | 0.946      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.69       |\n",
            "|    n_updates            | 3720       |\n",
            "|    policy_gradient_loss | -0.0103    |\n",
            "|    std                  | 0.341      |\n",
            "|    value_loss           | 11.1       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=67536, episode_reward=2917.94 +/- 56.30\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.92e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 67536      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.17452568 |\n",
            "|    clip_fraction        | 0.653      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.69      |\n",
            "|    explained_variance   | 0.937      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.53       |\n",
            "|    n_updates            | 3750       |\n",
            "|    policy_gradient_loss | -0.0371    |\n",
            "|    std                  | 0.341      |\n",
            "|    value_loss           | 11.3       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=77536, episode_reward=2981.02 +/- 48.48\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.98e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 77536      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.16388455 |\n",
            "|    clip_fraction        | 0.612      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.58      |\n",
            "|    explained_variance   | 0.951      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.84       |\n",
            "|    n_updates            | 3800       |\n",
            "|    policy_gradient_loss | -0.0487    |\n",
            "|    std                  | 0.337      |\n",
            "|    value_loss           | 17.4       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.66e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 263        |\n",
            "|    iterations           | 40         |\n",
            "|    time_elapsed         | 311        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.12392966 |\n",
            "|    clip_fraction        | 0.562      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.53      |\n",
            "|    explained_variance   | 0.983      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.05       |\n",
            "|    n_updates            | 3820       |\n",
            "|    policy_gradient_loss | -0.00265   |\n",
            "|    std                  | 0.335      |\n",
            "|    value_loss           | 9.05       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=87536, episode_reward=2911.96 +/- 68.49\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.91e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 87536     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.1138415 |\n",
            "|    clip_fraction        | 0.765     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.54     |\n",
            "|    explained_variance   | 0.955     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 1.61      |\n",
            "|    n_updates            | 3850      |\n",
            "|    policy_gradient_loss | 0.0246    |\n",
            "|    std                  | 0.336     |\n",
            "|    value_loss           | 7.38      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=97536, episode_reward=2955.29 +/- 58.68\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| eval/                   |          |\n",
            "|    mean_ep_length       | 1e+03    |\n",
            "|    mean_reward          | 2.96e+03 |\n",
            "| time/                   |          |\n",
            "|    total_timesteps      | 97536    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 1.134196 |\n",
            "|    clip_fraction        | 0.75     |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -2.52    |\n",
            "|    explained_variance   | 0.943    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 5.04     |\n",
            "|    n_updates            | 3900     |\n",
            "|    policy_gradient_loss | 0.016    |\n",
            "|    std                  | 0.334    |\n",
            "|    value_loss           | 8.6      |\n",
            "--------------------------------------\n",
            "mean_reward  2852.1533276\n",
            "Eval num_timesteps=7184, episode_reward=3042.43 +/- 41.97\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 3.04e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 7184      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2910521 |\n",
            "|    clip_fraction        | 0.637     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.51     |\n",
            "|    explained_variance   | 0.958     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 4.78      |\n",
            "|    n_updates            | 3950      |\n",
            "|    policy_gradient_loss | -0.038    |\n",
            "|    std                  | 0.333     |\n",
            "|    value_loss           | 10.9      |\n",
            "---------------------------------------\n",
            "New best mean reward!\n",
            "Eval num_timesteps=17184, episode_reward=2671.89 +/- 80.48\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.67e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 17184     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.7960935 |\n",
            "|    clip_fraction        | 0.637     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.41     |\n",
            "|    explained_variance   | 0.921     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 25.8      |\n",
            "|    n_updates            | 4000      |\n",
            "|    policy_gradient_loss | -0.0202   |\n",
            "|    std                  | 0.329     |\n",
            "|    value_loss           | 40.3      |\n",
            "---------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1.01e+03   |\n",
            "|    ep_rew_mean          | 2.54e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 272        |\n",
            "|    iterations           | 10         |\n",
            "|    time_elapsed         | 75         |\n",
            "|    total_timesteps      | 20480      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.15725671 |\n",
            "|    clip_fraction        | 0.634      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.39      |\n",
            "|    explained_variance   | 0.839      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.18       |\n",
            "|    n_updates            | 4010       |\n",
            "|    policy_gradient_loss | -0.0488    |\n",
            "|    std                  | 0.329      |\n",
            "|    value_loss           | 22.1       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=27184, episode_reward=2570.59 +/- 880.94\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.57e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 27184     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.4858377 |\n",
            "|    clip_fraction        | 0.757     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.35     |\n",
            "|    explained_variance   | 0.903     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.58      |\n",
            "|    n_updates            | 4050      |\n",
            "|    policy_gradient_loss | -0.00262  |\n",
            "|    std                  | 0.326     |\n",
            "|    value_loss           | 13.6      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=37184, episode_reward=2812.24 +/- 65.09\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.81e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 37184      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.24340555 |\n",
            "|    clip_fraction        | 0.689      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.4       |\n",
            "|    explained_variance   | 0.889      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 6.95       |\n",
            "|    n_updates            | 4100       |\n",
            "|    policy_gradient_loss | -0.00827   |\n",
            "|    std                  | 0.329      |\n",
            "|    value_loss           | 22.5       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 2.57e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 271        |\n",
            "|    iterations           | 20         |\n",
            "|    time_elapsed         | 151        |\n",
            "|    total_timesteps      | 40960      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.14571938 |\n",
            "|    clip_fraction        | 0.558      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.39      |\n",
            "|    explained_variance   | 0.958      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.01       |\n",
            "|    n_updates            | 4110       |\n",
            "|    policy_gradient_loss | -0.0177    |\n",
            "|    std                  | 0.329      |\n",
            "|    value_loss           | 17.3       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=47184, episode_reward=2821.08 +/- 101.63\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.82e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 47184     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.3452747 |\n",
            "|    clip_fraction        | 0.779     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.4      |\n",
            "|    explained_variance   | 0.976     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.53      |\n",
            "|    n_updates            | 4150      |\n",
            "|    policy_gradient_loss | 0.0235    |\n",
            "|    std                  | 0.33      |\n",
            "|    value_loss           | 6.4       |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=57184, episode_reward=3036.33 +/- 51.35\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 3.04e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 57184      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.17512459 |\n",
            "|    clip_fraction        | 0.622      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.43      |\n",
            "|    explained_variance   | 0.946      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.95       |\n",
            "|    n_updates            | 4190       |\n",
            "|    policy_gradient_loss | -0.0155    |\n",
            "|    std                  | 0.33       |\n",
            "|    value_loss           | 34.5       |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 2.62e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 269        |\n",
            "|    iterations           | 30         |\n",
            "|    time_elapsed         | 227        |\n",
            "|    total_timesteps      | 61440      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.17449173 |\n",
            "|    clip_fraction        | 0.55       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.4       |\n",
            "|    explained_variance   | 0.985      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 5.55       |\n",
            "|    n_updates            | 4210       |\n",
            "|    policy_gradient_loss | -0.0241    |\n",
            "|    std                  | 0.328      |\n",
            "|    value_loss           | 22.1       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=67184, episode_reward=2692.13 +/- 61.91\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.69e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 67184      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.46105248 |\n",
            "|    clip_fraction        | 0.78       |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.41      |\n",
            "|    explained_variance   | 0.956      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 3.11       |\n",
            "|    n_updates            | 4240       |\n",
            "|    policy_gradient_loss | 0.0226     |\n",
            "|    std                  | 0.33       |\n",
            "|    value_loss           | 6.05       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=77184, episode_reward=2905.48 +/- 54.63\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "-----------------------------------------\n",
            "| eval/                   |             |\n",
            "|    mean_ep_length       | 1e+03       |\n",
            "|    mean_reward          | 2.91e+03    |\n",
            "| time/                   |             |\n",
            "|    total_timesteps      | 77184       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.082495764 |\n",
            "|    clip_fraction        | 0.527       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -2.46       |\n",
            "|    explained_variance   | 0.923       |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 38.6        |\n",
            "|    n_updates            | 4290        |\n",
            "|    policy_gradient_loss | -0.0455     |\n",
            "|    std                  | 0.331       |\n",
            "|    value_loss           | 60.2        |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 1e+03      |\n",
            "|    ep_rew_mean          | 2.62e+03   |\n",
            "| time/                   |            |\n",
            "|    fps                  | 269        |\n",
            "|    iterations           | 40         |\n",
            "|    time_elapsed         | 304        |\n",
            "|    total_timesteps      | 81920      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.26909482 |\n",
            "|    clip_fraction        | 0.544      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.39      |\n",
            "|    explained_variance   | 0.99       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 2.49       |\n",
            "|    n_updates            | 4310       |\n",
            "|    policy_gradient_loss | -0.0257    |\n",
            "|    std                  | 0.328      |\n",
            "|    value_loss           | 16.6       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=87184, episode_reward=2783.60 +/- 179.32\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.78e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 87184      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.13300985 |\n",
            "|    clip_fraction        | 0.601      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.43      |\n",
            "|    explained_variance   | 0.875      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 29.1       |\n",
            "|    n_updates            | 4340       |\n",
            "|    policy_gradient_loss | -0.0445    |\n",
            "|    std                  | 0.33       |\n",
            "|    value_loss           | 52.9       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=97184, episode_reward=2161.79 +/- 768.11\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.16e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 97184     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.8334063 |\n",
            "|    clip_fraction        | 0.628     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.31     |\n",
            "|    explained_variance   | 0.87      |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 49.2      |\n",
            "|    n_updates            | 4390      |\n",
            "|    policy_gradient_loss | -0.0292   |\n",
            "|    std                  | 0.324     |\n",
            "|    value_loss           | 81.4      |\n",
            "---------------------------------------\n",
            "mean_reward  2419.6696018\n",
            "Eval num_timesteps=6832, episode_reward=2803.58 +/- 169.04\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.8e+03   |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 6832      |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.0842415 |\n",
            "|    clip_fraction        | 0.824     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.28     |\n",
            "|    explained_variance   | 0.919     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 6.83      |\n",
            "|    n_updates            | 4440      |\n",
            "|    policy_gradient_loss | 0.0236    |\n",
            "|    std                  | 0.324     |\n",
            "|    value_loss           | 16.3      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=16832, episode_reward=2823.73 +/- 140.85\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.82e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 16832      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.23393409 |\n",
            "|    clip_fraction        | 0.659      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.25      |\n",
            "|    explained_variance   | 0.943      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 23.6       |\n",
            "|    n_updates            | 4490       |\n",
            "|    policy_gradient_loss | -0.0359    |\n",
            "|    std                  | 0.323      |\n",
            "|    value_loss           | 46.4       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.04e+03  |\n",
            "|    ep_rew_mean          | 2.72e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 273       |\n",
            "|    iterations           | 10        |\n",
            "|    time_elapsed         | 75        |\n",
            "|    total_timesteps      | 20480     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 2.9588926 |\n",
            "|    clip_fraction        | 0.823     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.27     |\n",
            "|    explained_variance   | 0.873     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 10.5      |\n",
            "|    n_updates            | 4500      |\n",
            "|    policy_gradient_loss | 0.096     |\n",
            "|    std                  | 0.324     |\n",
            "|    value_loss           | 19.6      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=26832, episode_reward=2580.49 +/- 457.64\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.58e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 26832      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.09510924 |\n",
            "|    clip_fraction        | 0.567      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.22      |\n",
            "|    explained_variance   | 0.856      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 27         |\n",
            "|    n_updates            | 4540       |\n",
            "|    policy_gradient_loss | -0.0468    |\n",
            "|    std                  | 0.321      |\n",
            "|    value_loss           | 91.8       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=36832, episode_reward=2898.49 +/- 212.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.9e+03   |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 36832     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.1316791 |\n",
            "|    clip_fraction        | 0.58      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.19     |\n",
            "|    explained_variance   | 0.898     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 38.5      |\n",
            "|    n_updates            | 4580      |\n",
            "|    policy_gradient_loss | -0.046    |\n",
            "|    std                  | 0.32      |\n",
            "|    value_loss           | 108       |\n",
            "---------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.02e+03  |\n",
            "|    ep_rew_mean          | 2.63e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 271       |\n",
            "|    iterations           | 20        |\n",
            "|    time_elapsed         | 150       |\n",
            "|    total_timesteps      | 40960     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 1.6139758 |\n",
            "|    clip_fraction        | 0.727     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.19     |\n",
            "|    explained_variance   | 0.822     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 50.7      |\n",
            "|    n_updates            | 4600      |\n",
            "|    policy_gradient_loss | -0.00118  |\n",
            "|    std                  | 0.321     |\n",
            "|    value_loss           | 45.6      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=46832, episode_reward=2525.61 +/- 767.77\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 2.53e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 46832     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 5.3798237 |\n",
            "|    clip_fraction        | 0.824     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.24     |\n",
            "|    explained_variance   | 0.858     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 5.31      |\n",
            "|    n_updates            | 4630      |\n",
            "|    policy_gradient_loss | 0.028     |\n",
            "|    std                  | 0.321     |\n",
            "|    value_loss           | 19.5      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=56832, episode_reward=2973.54 +/- 29.99\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.97e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 56832      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.20556593 |\n",
            "|    clip_fraction        | 0.656      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.14      |\n",
            "|    explained_variance   | 0.915      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.47       |\n",
            "|    n_updates            | 4680       |\n",
            "|    policy_gradient_loss | -0.0342    |\n",
            "|    std                  | 0.318      |\n",
            "|    value_loss           | 17.4       |\n",
            "----------------------------------------\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.64e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 270       |\n",
            "|    iterations           | 30        |\n",
            "|    time_elapsed         | 227       |\n",
            "|    total_timesteps      | 61440     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.6317078 |\n",
            "|    clip_fraction        | 0.775     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -2.13     |\n",
            "|    explained_variance   | 0.942     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.19      |\n",
            "|    n_updates            | 4700      |\n",
            "|    policy_gradient_loss | 0.0372    |\n",
            "|    std                  | 0.318     |\n",
            "|    value_loss           | 8.92      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=66832, episode_reward=2957.55 +/- 48.60\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.96e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 66832      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.11754447 |\n",
            "|    clip_fraction        | 0.535      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -2.07      |\n",
            "|    explained_variance   | 0.92       |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 13.8       |\n",
            "|    n_updates            | 4730       |\n",
            "|    policy_gradient_loss | -0.0521    |\n",
            "|    std                  | 0.315      |\n",
            "|    value_loss           | 42.4       |\n",
            "----------------------------------------\n",
            "Eval num_timesteps=76832, episode_reward=3085.48 +/- 30.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "--------------------------------------\n",
            "| eval/                   |          |\n",
            "|    mean_ep_length       | 1e+03    |\n",
            "|    mean_reward          | 3.09e+03 |\n",
            "| time/                   |          |\n",
            "|    total_timesteps      | 76832    |\n",
            "| train/                  |          |\n",
            "|    approx_kl            | 2.079566 |\n",
            "|    clip_fraction        | 0.683    |\n",
            "|    clip_range           | 0.2      |\n",
            "|    entropy_loss         | -1.93    |\n",
            "|    explained_variance   | 0.928    |\n",
            "|    learning_rate        | 0.0003   |\n",
            "|    loss                 | 9.1      |\n",
            "|    n_updates            | 4780     |\n",
            "|    policy_gradient_loss | -0.00498 |\n",
            "|    std                  | 0.31     |\n",
            "|    value_loss           | 16.6     |\n",
            "--------------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------------\n",
            "| rollout/                |           |\n",
            "|    ep_len_mean          | 1.01e+03  |\n",
            "|    ep_rew_mean          | 2.65e+03  |\n",
            "| time/                   |           |\n",
            "|    fps                  | 269       |\n",
            "|    iterations           | 40        |\n",
            "|    time_elapsed         | 303       |\n",
            "|    total_timesteps      | 81920     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2575349 |\n",
            "|    clip_fraction        | 0.698     |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.91     |\n",
            "|    explained_variance   | 0.963     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 2.99      |\n",
            "|    n_updates            | 4800      |\n",
            "|    policy_gradient_loss | -0.0222   |\n",
            "|    std                  | 0.309     |\n",
            "|    value_loss           | 12.2      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=86832, episode_reward=3017.79 +/- 108.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------------\n",
            "| eval/                   |           |\n",
            "|    mean_ep_length       | 1e+03     |\n",
            "|    mean_reward          | 3.02e+03  |\n",
            "| time/                   |           |\n",
            "|    total_timesteps      | 86832     |\n",
            "| train/                  |           |\n",
            "|    approx_kl            | 0.2659723 |\n",
            "|    clip_fraction        | 0.61      |\n",
            "|    clip_range           | 0.2       |\n",
            "|    entropy_loss         | -1.86     |\n",
            "|    explained_variance   | 0.984     |\n",
            "|    learning_rate        | 0.0003    |\n",
            "|    loss                 | 3.58      |\n",
            "|    n_updates            | 4830      |\n",
            "|    policy_gradient_loss | -0.0351   |\n",
            "|    std                  | 0.307     |\n",
            "|    value_loss           | 26.3      |\n",
            "---------------------------------------\n",
            "Eval num_timesteps=96832, episode_reward=2941.78 +/- 79.82\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "----------------------------------------\n",
            "| eval/                   |            |\n",
            "|    mean_ep_length       | 1e+03      |\n",
            "|    mean_reward          | 2.94e+03   |\n",
            "| time/                   |            |\n",
            "|    total_timesteps      | 96832      |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.22995207 |\n",
            "|    clip_fraction        | 0.671      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -1.82      |\n",
            "|    explained_variance   | 0.961      |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 4.67       |\n",
            "|    n_updates            | 4880       |\n",
            "|    policy_gradient_loss | -0.0386    |\n",
            "|    std                  | 0.306      |\n",
            "|    value_loss           | 15.3       |\n",
            "----------------------------------------\n",
            "mean_reward  2808.48396\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=100000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"PPO_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "LDhxwvh9ibz0",
        "outputId": "eb78ce5d-381b-40a2-d17f-8714680d3c29"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 489
        },
        "id": "Ufh_xhalibz0",
        "outputId": "5670869b-3ca0-4b38-e54f-e9d8b726355e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['timesteps', 'results', 'ep_lengths']\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el archivo .npz\n",
        "eval_data = np.load('./logs/eval/evaluations.npz')\n",
        "\n",
        "# Listar las claves en el archivo .npz\n",
        "print(eval_data.files)\n",
        "\n",
        "# Supongamos que el archivo tiene las claves 'results' y 'timesteps'\n",
        "# Acceder a los datos\n",
        "results = eval_data['results']\n",
        "timesteps = eval_data['timesteps']\n",
        "\n",
        "# Calcular la recompensa promedio si es necesario (depende del formato de results)\n",
        "mean_rewards = results.mean(axis=1)  # Promedio de recompensas por evaluación\n",
        "\n",
        "# Graficar las recompensas promedio\n",
        "plt.plot(timesteps, mean_rewards)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqdWTUryibz1"
      },
      "source": [
        "#SAC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GsOaQ5jeibz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5ed1c46-b7d9-49da-ef92-4c3541a8655a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        }
      ],
      "source": [
        "model = SAC('MlpPolicy', env,learning_rate=0.0003,policy_kwargs=policy_kwargs, verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iN7-hcQKibz1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0812a6f6-f155-4ddc-e232-6dc593c06190"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 640      |\n",
            "|    ep_rew_mean     | 320      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 87       |\n",
            "|    total_timesteps | 6401     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -68.5    |\n",
            "|    critic_loss     | 1.08     |\n",
            "|    ent_coef        | 0.154    |\n",
            "|    ent_coef_loss   | -22.6    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 6300     |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=10000, episode_reward=371.10 +/- 118.75\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 371      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -82.7    |\n",
            "|    critic_loss     | 2.63     |\n",
            "|    ent_coef        | 0.0781   |\n",
            "|    ent_coef_loss   | -2.66    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 9899     |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 713      |\n",
            "|    ep_rew_mean     | 334      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 198      |\n",
            "|    total_timesteps | 14255    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95.4    |\n",
            "|    critic_loss     | 0.696    |\n",
            "|    ent_coef        | 0.0693   |\n",
            "|    ent_coef_loss   | -0.378   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 14154    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 617      |\n",
            "|    ep_rew_mean     | 292      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 252      |\n",
            "|    total_timesteps | 18504    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -110     |\n",
            "|    critic_loss     | 35.7     |\n",
            "|    ent_coef        | 0.0862   |\n",
            "|    ent_coef_loss   | 0.608    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 18403    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=544.76 +/- 26.37\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 545      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -113     |\n",
            "|    critic_loss     | 1.05     |\n",
            "|    ent_coef        | 0.0876   |\n",
            "|    ent_coef_loss   | 0.641    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 19899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 725      |\n",
            "|    ep_rew_mean     | 342      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 401      |\n",
            "|    total_timesteps | 29000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -132     |\n",
            "|    critic_loss     | 1.33     |\n",
            "|    ent_coef        | 0.0979   |\n",
            "|    ent_coef_loss   | 0.822    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 28899    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=639.78 +/- 87.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 640      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 0.814    |\n",
            "|    ent_coef        | 0.0939   |\n",
            "|    ent_coef_loss   | -1.27    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 29899    |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 741      |\n",
            "|    ep_rew_mean     | 359      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 516      |\n",
            "|    total_timesteps | 37040    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 0.942    |\n",
            "|    ent_coef        | 0.0654   |\n",
            "|    ent_coef_loss   | -1.3     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 36939    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=381.29 +/- 159.97\n",
            "Episode length: 846.80 +/- 306.40\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 847      |\n",
            "|    mean_reward     | 381      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -138     |\n",
            "|    critic_loss     | 1.07     |\n",
            "|    ent_coef        | 0.072    |\n",
            "|    ent_coef_loss   | 2.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 39899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 691      |\n",
            "|    ep_rew_mean     | 333      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 582      |\n",
            "|    total_timesteps | 41479    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -140     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.0692   |\n",
            "|    ent_coef_loss   | 0.205    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 41378    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 682      |\n",
            "|    ep_rew_mean     | 327      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 667      |\n",
            "|    total_timesteps | 47744    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 2.8      |\n",
            "|    ent_coef        | 0.0677   |\n",
            "|    ent_coef_loss   | 0.981    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 47643    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=593.80 +/- 69.61\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 594      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -135     |\n",
            "|    critic_loss     | 31.2     |\n",
            "|    ent_coef        | 0.068    |\n",
            "|    ent_coef_loss   | -1.52    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 49899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 725      |\n",
            "|    ep_rew_mean     | 354      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 814      |\n",
            "|    total_timesteps | 58000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -135     |\n",
            "|    critic_loss     | 0.991    |\n",
            "|    ent_coef        | 0.0638   |\n",
            "|    ent_coef_loss   | -0.107   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 57899    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=581.67 +/- 86.14\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 582      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -135     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.0645   |\n",
            "|    ent_coef_loss   | -0.484   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 59899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 756      |\n",
            "|    ep_rew_mean     | 362      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 953      |\n",
            "|    total_timesteps | 68000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -134     |\n",
            "|    critic_loss     | 0.864    |\n",
            "|    ent_coef        | 0.0672   |\n",
            "|    ent_coef_loss   | -0.284   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 67899    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=350.78 +/- 13.50\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 351      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -134     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.0635   |\n",
            "|    ent_coef_loss   | -0.212   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 69899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 767      |\n",
            "|    ep_rew_mean     | 361      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1078     |\n",
            "|    total_timesteps | 76739    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -130     |\n",
            "|    critic_loss     | 0.877    |\n",
            "|    ent_coef        | 0.0543   |\n",
            "|    ent_coef_loss   | -0.258   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 76638    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=449.73 +/- 163.25\n",
            "Episode length: 877.40 +/- 245.20\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 877      |\n",
            "|    mean_reward     | 450      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -127     |\n",
            "|    critic_loss     | 0.823    |\n",
            "|    ent_coef        | 0.0523   |\n",
            "|    ent_coef_loss   | -0.561   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 79899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 790      |\n",
            "|    ep_rew_mean     | 366      |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1199     |\n",
            "|    total_timesteps | 85410    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -124     |\n",
            "|    critic_loss     | 0.771    |\n",
            "|    ent_coef        | 0.0469   |\n",
            "|    ent_coef_loss   | -0.129   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 85309    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=444.21 +/- 70.72\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 444      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -121     |\n",
            "|    critic_loss     | 0.861    |\n",
            "|    ent_coef        | 0.0457   |\n",
            "|    ent_coef_loss   | -2.16    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 89899    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 786      |\n",
            "|    ep_rew_mean     | 367      |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 1310     |\n",
            "|    total_timesteps | 92872    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -121     |\n",
            "|    critic_loss     | 0.591    |\n",
            "|    ent_coef        | 0.0438   |\n",
            "|    ent_coef_loss   | 1.69     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 92771    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 811      |\n",
            "|    ep_rew_mean     | 377      |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1398     |\n",
            "|    total_timesteps | 99557    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -118     |\n",
            "|    critic_loss     | 0.573    |\n",
            "|    ent_coef        | 0.046    |\n",
            "|    ent_coef_loss   | -0.636   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 99456    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=518.22 +/- 59.08\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 518      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -118     |\n",
            "|    critic_loss     | 0.708    |\n",
            "|    ent_coef        | 0.0459   |\n",
            "|    ent_coef_loss   | 1.44     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 99899    |\n",
            "---------------------------------\n",
            "mean_reward  292.90356579999997\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 906      |\n",
            "|    ep_rew_mean     | 413      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 76       |\n",
            "|    time_elapsed    | 117      |\n",
            "|    total_timesteps | 9060     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -114     |\n",
            "|    critic_loss     | 0.53     |\n",
            "|    ent_coef        | 0.0424   |\n",
            "|    ent_coef_loss   | 0.336    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 108859   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=504.36 +/- 81.70\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 504      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -114     |\n",
            "|    critic_loss     | 0.523    |\n",
            "|    ent_coef        | 0.0409   |\n",
            "|    ent_coef_loss   | -2.23    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 109799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 851      |\n",
            "|    ep_rew_mean     | 404      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 232      |\n",
            "|    total_timesteps | 17021    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -109     |\n",
            "|    critic_loss     | 0.422    |\n",
            "|    ent_coef        | 0.0325   |\n",
            "|    ent_coef_loss   | 0.596    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 116820   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=454.31 +/- 190.42\n",
            "Episode length: 802.00 +/- 258.82\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 802      |\n",
            "|    mean_reward     | 454      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -108     |\n",
            "|    critic_loss     | 0.806    |\n",
            "|    ent_coef        | 0.0325   |\n",
            "|    ent_coef_loss   | 1.54     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 119799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 868      |\n",
            "|    ep_rew_mean     | 417      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 357      |\n",
            "|    total_timesteps | 26026    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -105     |\n",
            "|    critic_loss     | 0.423    |\n",
            "|    ent_coef        | 0.0311   |\n",
            "|    ent_coef_loss   | -1.56    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 125825   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=427.23 +/- 30.93\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 427      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -104     |\n",
            "|    critic_loss     | 0.52     |\n",
            "|    ent_coef        | 0.0304   |\n",
            "|    ent_coef_loss   | 0.248    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 129799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 862      |\n",
            "|    ep_rew_mean     | 416      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 476      |\n",
            "|    total_timesteps | 34465    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -102     |\n",
            "|    critic_loss     | 0.618    |\n",
            "|    ent_coef        | 0.0283   |\n",
            "|    ent_coef_loss   | 0.823    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 134264   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=493.27 +/- 139.21\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 493      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -101     |\n",
            "|    critic_loss     | 0.412    |\n",
            "|    ent_coef        | 0.0287   |\n",
            "|    ent_coef_loss   | -0.969   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 139799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 868      |\n",
            "|    ep_rew_mean     | 419      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 604      |\n",
            "|    total_timesteps | 43417    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -99.1    |\n",
            "|    critic_loss     | 0.434    |\n",
            "|    ent_coef        | 0.0283   |\n",
            "|    ent_coef_loss   | 1.04     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 143216   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=496.69 +/- 52.02\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 497      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -97.2    |\n",
            "|    critic_loss     | 0.403    |\n",
            "|    ent_coef        | 0.0261   |\n",
            "|    ent_coef_loss   | -0.422   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 149799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 900      |\n",
            "|    ep_rew_mean     | 450      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 756      |\n",
            "|    total_timesteps | 54000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95.8    |\n",
            "|    critic_loss     | 0.286    |\n",
            "|    ent_coef        | 0.0248   |\n",
            "|    ent_coef_loss   | -1.15    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 153799   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=506.38 +/- 179.25\n",
            "Episode length: 860.00 +/- 280.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 860      |\n",
            "|    mean_reward     | 506      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.8    |\n",
            "|    critic_loss     | 0.201    |\n",
            "|    ent_coef        | 0.0238   |\n",
            "|    ent_coef_loss   | 1.43     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 159799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 914      |\n",
            "|    ep_rew_mean     | 461      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 899      |\n",
            "|    total_timesteps | 64000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.6    |\n",
            "|    critic_loss     | 0.286    |\n",
            "|    ent_coef        | 0.0237   |\n",
            "|    ent_coef_loss   | -1.4     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 163799   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=613.46 +/- 63.45\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 613      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92.5    |\n",
            "|    critic_loss     | 0.323    |\n",
            "|    ent_coef        | 0.0241   |\n",
            "|    ent_coef_loss   | 1.11     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 169799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 925      |\n",
            "|    ep_rew_mean     | 474      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1037     |\n",
            "|    total_timesteps | 74000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92.4    |\n",
            "|    critic_loss     | 0.382    |\n",
            "|    ent_coef        | 0.0242   |\n",
            "|    ent_coef_loss   | -0.0845  |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 173799   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=440.78 +/- 211.27\n",
            "Episode length: 815.60 +/- 368.80\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 816      |\n",
            "|    mean_reward     | 441      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92      |\n",
            "|    critic_loss     | 0.216    |\n",
            "|    ent_coef        | 0.0227   |\n",
            "|    ent_coef_loss   | 0.785    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 179799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 933      |\n",
            "|    ep_rew_mean     | 491      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1174     |\n",
            "|    total_timesteps | 84000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91.8    |\n",
            "|    critic_loss     | 0.266    |\n",
            "|    ent_coef        | 0.0228   |\n",
            "|    ent_coef_loss   | -2.05    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 183799   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=602.72 +/- 208.66\n",
            "Episode length: 859.20 +/- 281.60\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 859      |\n",
            "|    mean_reward     | 603      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91      |\n",
            "|    critic_loss     | 0.211    |\n",
            "|    ent_coef        | 0.0216   |\n",
            "|    ent_coef_loss   | 0.486    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 189799   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 940      |\n",
            "|    ep_rew_mean     | 503      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1312     |\n",
            "|    total_timesteps | 94000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.9    |\n",
            "|    critic_loss     | 0.261    |\n",
            "|    ent_coef        | 0.0214   |\n",
            "|    ent_coef_loss   | -0.184   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 193799   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=526.21 +/- 45.63\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 526      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -89.9    |\n",
            "|    critic_loss     | 0.235    |\n",
            "|    ent_coef        | 0.0212   |\n",
            "|    ent_coef_loss   | -0.432   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 199799   |\n",
            "---------------------------------\n",
            "mean_reward  540.2879704\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 922      |\n",
            "|    ep_rew_mean     | 515      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 76       |\n",
            "|    time_elapsed    | 120      |\n",
            "|    total_timesteps | 9217     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -88.8    |\n",
            "|    critic_loss     | 0.467    |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | 0.0419   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 208916   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=609.15 +/- 91.69\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 609      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -88.5    |\n",
            "|    critic_loss     | 0.223    |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | 0.704    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 209699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 984      |\n",
            "|    ep_rew_mean     | 570      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 271      |\n",
            "|    total_timesteps | 19679    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.8    |\n",
            "|    critic_loss     | 0.185    |\n",
            "|    ent_coef        | 0.019    |\n",
            "|    ent_coef_loss   | -1.56    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 219378   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=450.62 +/- 201.41\n",
            "Episode length: 830.40 +/- 339.20\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 830      |\n",
            "|    mean_reward     | 451      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.2    |\n",
            "|    critic_loss     | 0.321    |\n",
            "|    ent_coef        | 0.0189   |\n",
            "|    ent_coef_loss   | -0.823   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 219699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 946      |\n",
            "|    ep_rew_mean     | 541      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 397      |\n",
            "|    total_timesteps | 28366    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -85.9    |\n",
            "|    critic_loss     | 0.463    |\n",
            "|    ent_coef        | 0.0186   |\n",
            "|    ent_coef_loss   | -1.45    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 228065   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=443.22 +/- 86.70\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 443      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -85.7    |\n",
            "|    critic_loss     | 0.268    |\n",
            "|    ent_coef        | 0.0181   |\n",
            "|    ent_coef_loss   | 1.19     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 229699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 975      |\n",
            "|    ep_rew_mean     | 548      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 550      |\n",
            "|    total_timesteps | 39000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -84.6    |\n",
            "|    critic_loss     | 0.192    |\n",
            "|    ent_coef        | 0.018    |\n",
            "|    ent_coef_loss   | 0.825    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 238699   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=170.06 +/- 139.62\n",
            "Episode length: 342.00 +/- 242.31\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 342      |\n",
            "|    mean_reward     | 170      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -84.7    |\n",
            "|    critic_loss     | 0.418    |\n",
            "|    ent_coef        | 0.0183   |\n",
            "|    ent_coef_loss   | 1.51     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 239699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 961      |\n",
            "|    ep_rew_mean     | 543      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 674      |\n",
            "|    total_timesteps | 48034    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -85.4    |\n",
            "|    critic_loss     | 0.363    |\n",
            "|    ent_coef        | 0.0199   |\n",
            "|    ent_coef_loss   | -0.245   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 247733   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=564.00 +/- 61.56\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 564      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -86      |\n",
            "|    critic_loss     | 0.65     |\n",
            "|    ent_coef        | 0.0219   |\n",
            "|    ent_coef_loss   | -0.00607 |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 249699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 957      |\n",
            "|    ep_rew_mean     | 538      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 807      |\n",
            "|    total_timesteps | 57403    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -88.1    |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    ent_coef        | 0.0215   |\n",
            "|    ent_coef_loss   | 0.0936   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 257102   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=459.94 +/- 157.92\n",
            "Episode length: 846.20 +/- 307.60\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 846      |\n",
            "|    mean_reward     | 460      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -89.5    |\n",
            "|    critic_loss     | 0.895    |\n",
            "|    ent_coef        | 0.021    |\n",
            "|    ent_coef_loss   | 1.29     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 259699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 923      |\n",
            "|    ep_rew_mean     | 515      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 912      |\n",
            "|    total_timesteps | 64601    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.6    |\n",
            "|    critic_loss     | 0.549    |\n",
            "|    ent_coef        | 0.0205   |\n",
            "|    ent_coef_loss   | 0.639    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 264300   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=215.98 +/- 169.32\n",
            "Episode length: 453.20 +/- 446.62\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 453      |\n",
            "|    mean_reward     | 216      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92.3    |\n",
            "|    critic_loss     | 0.628    |\n",
            "|    ent_coef        | 0.0215   |\n",
            "|    ent_coef_loss   | 2.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 269699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 913      |\n",
            "|    ep_rew_mean     | 496      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1027     |\n",
            "|    total_timesteps | 73071    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91      |\n",
            "|    critic_loss     | 0.351    |\n",
            "|    ent_coef        | 0.0209   |\n",
            "|    ent_coef_loss   | -3.22    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 272770   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=661.06 +/- 85.16\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 661      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91.3    |\n",
            "|    critic_loss     | 0.843    |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | 2.12     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 279699   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 922      |\n",
            "|    ep_rew_mean     | 497      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1163     |\n",
            "|    total_timesteps | 83000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91.3    |\n",
            "|    critic_loss     | 0.251    |\n",
            "|    ent_coef        | 0.019    |\n",
            "|    ent_coef_loss   | 1.57     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 282699   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=581.38 +/- 105.97\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 581      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91.4    |\n",
            "|    critic_loss     | 0.323    |\n",
            "|    ent_coef        | 0.0191   |\n",
            "|    ent_coef_loss   | 1.07     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 289699   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 930      |\n",
            "|    ep_rew_mean     | 503      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1297     |\n",
            "|    total_timesteps | 93000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.9    |\n",
            "|    critic_loss     | 0.219    |\n",
            "|    ent_coef        | 0.018    |\n",
            "|    ent_coef_loss   | 1.03     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 292699   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=692.90 +/- 59.49\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 693      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -91.5    |\n",
            "|    critic_loss     | 0.315    |\n",
            "|    ent_coef        | 0.0178   |\n",
            "|    ent_coef_loss   | -1.15    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 299699   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  638.219658\n",
            "Eval num_timesteps=10000, episode_reward=632.73 +/- 171.03\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 633      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.1    |\n",
            "|    critic_loss     | 0.218    |\n",
            "|    ent_coef        | 0.0162   |\n",
            "|    ent_coef_loss   | 0.534    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 309599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 653      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 134      |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=681.76 +/- 109.18\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 682      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -89.3    |\n",
            "|    critic_loss     | 0.383    |\n",
            "|    ent_coef        | 0.0154   |\n",
            "|    ent_coef_loss   | 1.74     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 319599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 671      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 268      |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=743.40 +/- 74.18\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 743      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.8    |\n",
            "|    critic_loss     | 0.182    |\n",
            "|    ent_coef        | 0.0151   |\n",
            "|    ent_coef_loss   | -2.67    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 329599   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 684      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 74       |\n",
            "|    time_elapsed    | 405      |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=807.26 +/- 95.67\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 807      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.2    |\n",
            "|    critic_loss     | 0.274    |\n",
            "|    ent_coef        | 0.0156   |\n",
            "|    ent_coef_loss   | -0.499   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 339599   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 697      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 541      |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=741.21 +/- 67.21\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 741      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.3    |\n",
            "|    critic_loss     | 0.216    |\n",
            "|    ent_coef        | 0.0162   |\n",
            "|    ent_coef_loss   | -0.561   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 349599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 698      |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 679      |\n",
            "|    total_timesteps | 50000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=784.35 +/- 195.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 784      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -87.2    |\n",
            "|    critic_loss     | 0.259    |\n",
            "|    ent_coef        | 0.0167   |\n",
            "|    ent_coef_loss   | 0.406    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 359599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 721      |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 816      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=789.73 +/- 71.42\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 790      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -88.5    |\n",
            "|    critic_loss     | 0.204    |\n",
            "|    ent_coef        | 0.0171   |\n",
            "|    ent_coef_loss   | -0.895   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 369599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 726      |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 956      |\n",
            "|    total_timesteps | 70000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=911.73 +/- 136.43\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 912      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -90.1    |\n",
            "|    critic_loss     | 1.13     |\n",
            "|    ent_coef        | 0.0176   |\n",
            "|    ent_coef_loss   | 1.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 379599   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 747      |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1097     |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=892.22 +/- 162.19\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 892      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -92      |\n",
            "|    critic_loss     | 0.274    |\n",
            "|    ent_coef        | 0.0187   |\n",
            "|    ent_coef_loss   | 2.42     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 389599   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 774      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1238     |\n",
            "|    total_timesteps | 90000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 964      |\n",
            "|    ep_rew_mean     | 760      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1321     |\n",
            "|    total_timesteps | 96440    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.3    |\n",
            "|    critic_loss     | 0.481    |\n",
            "|    ent_coef        | 0.0179   |\n",
            "|    ent_coef_loss   | 0.604    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 396039   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=901.97 +/- 267.69\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 902      |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.2    |\n",
            "|    critic_loss     | 0.585    |\n",
            "|    ent_coef        | 0.0175   |\n",
            "|    ent_coef_loss   | 1.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 399599   |\n",
            "---------------------------------\n",
            "mean_reward  434.5832454\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 434      |\n",
            "|    ep_rew_mean     | 301      |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 77       |\n",
            "|    time_elapsed    | 55       |\n",
            "|    total_timesteps | 4339     |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93      |\n",
            "|    critic_loss     | 1.05     |\n",
            "|    ent_coef        | 0.0173   |\n",
            "|    ent_coef_loss   | -0.734   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 403838   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=10000, episode_reward=1112.76 +/- 292.15\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.11e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -94.4    |\n",
            "|    critic_loss     | 0.392    |\n",
            "|    ent_coef        | 0.0179   |\n",
            "|    ent_coef_loss   | 0.366    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 409499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 650      |\n",
            "|    ep_rew_mean     | 563      |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 179      |\n",
            "|    total_timesteps | 13000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -93.6    |\n",
            "|    critic_loss     | 0.379    |\n",
            "|    ent_coef        | 0.0171   |\n",
            "|    ent_coef_loss   | 0.982    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 412499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=1167.77 +/- 269.09\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.17e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95.5    |\n",
            "|    critic_loss     | 0.405    |\n",
            "|    ent_coef        | 0.0176   |\n",
            "|    ent_coef_loss   | -1.65    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 419499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 767      |\n",
            "|    ep_rew_mean     | 785      |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 321      |\n",
            "|    total_timesteps | 23000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -95.6    |\n",
            "|    critic_loss     | 0.388    |\n",
            "|    ent_coef        | 0.0183   |\n",
            "|    ent_coef_loss   | -0.24    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 422499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=1294.09 +/- 77.62\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.29e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -97.6    |\n",
            "|    critic_loss     | 0.592    |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | -1.28    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 429499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 825      |\n",
            "|    ep_rew_mean     | 949      |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 461      |\n",
            "|    total_timesteps | 33000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -99      |\n",
            "|    critic_loss     | 0.638    |\n",
            "|    ent_coef        | 0.0198   |\n",
            "|    ent_coef_loss   | 1.8      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 432499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=1745.84 +/- 52.40\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.75e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -101     |\n",
            "|    critic_loss     | 0.445    |\n",
            "|    ent_coef        | 0.0202   |\n",
            "|    ent_coef_loss   | 1.01     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 439499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 860      |\n",
            "|    ep_rew_mean     | 1.04e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 601      |\n",
            "|    total_timesteps | 43000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -103     |\n",
            "|    critic_loss     | 0.507    |\n",
            "|    ent_coef        | 0.0214   |\n",
            "|    ent_coef_loss   | -0.65    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 442499   |\n",
            "---------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/stable_baselines3/common/evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eval num_timesteps=50000, episode_reward=1737.68 +/- 402.92\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.74e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -105     |\n",
            "|    critic_loss     | 0.513    |\n",
            "|    ent_coef        | 0.0212   |\n",
            "|    ent_coef_loss   | -1.2     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 449499   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 883      |\n",
            "|    ep_rew_mean     | 1.14e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 743      |\n",
            "|    total_timesteps | 53000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -107     |\n",
            "|    critic_loss     | 0.495    |\n",
            "|    ent_coef        | 0.0221   |\n",
            "|    ent_coef_loss   | 0.891    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 452499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=1646.25 +/- 373.36\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.65e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -109     |\n",
            "|    critic_loss     | 0.586    |\n",
            "|    ent_coef        | 0.0233   |\n",
            "|    ent_coef_loss   | 0.593    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 459499   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 900      |\n",
            "|    ep_rew_mean     | 1.21e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 881      |\n",
            "|    total_timesteps | 63000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -109     |\n",
            "|    critic_loss     | 0.724    |\n",
            "|    ent_coef        | 0.0244   |\n",
            "|    ent_coef_loss   | -1.15    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 462499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=1976.30 +/- 13.20\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.98e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -112     |\n",
            "|    critic_loss     | 0.516    |\n",
            "|    ent_coef        | 0.0254   |\n",
            "|    ent_coef_loss   | -0.563   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 469499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 912      |\n",
            "|    ep_rew_mean     | 1.3e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1022     |\n",
            "|    total_timesteps | 73000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -115     |\n",
            "|    critic_loss     | 0.532    |\n",
            "|    ent_coef        | 0.0257   |\n",
            "|    ent_coef_loss   | 0.384    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 472499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=1928.83 +/- 171.10\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.93e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -119     |\n",
            "|    critic_loss     | 0.651    |\n",
            "|    ent_coef        | 0.0259   |\n",
            "|    ent_coef_loss   | -0.856   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 479499   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 922      |\n",
            "|    ep_rew_mean     | 1.37e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1159     |\n",
            "|    total_timesteps | 83000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -117     |\n",
            "|    critic_loss     | 0.529    |\n",
            "|    ent_coef        | 0.0261   |\n",
            "|    ent_coef_loss   | 0.315    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 482499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=1937.24 +/- 15.80\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 1.94e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -122     |\n",
            "|    critic_loss     | 0.591    |\n",
            "|    ent_coef        | 0.0265   |\n",
            "|    ent_coef_loss   | -0.522   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 489499   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 930      |\n",
            "|    ep_rew_mean     | 1.43e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1298     |\n",
            "|    total_timesteps | 93000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -122     |\n",
            "|    critic_loss     | 0.919    |\n",
            "|    ent_coef        | 0.0278   |\n",
            "|    ent_coef_loss   | -1.18    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 492499   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=2080.19 +/- 14.84\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.08e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -128     |\n",
            "|    critic_loss     | 0.722    |\n",
            "|    ent_coef        | 0.029    |\n",
            "|    ent_coef_loss   | -1.71    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 499499   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  2041.075988\n",
            "Eval num_timesteps=10000, episode_reward=2163.37 +/- 11.89\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.16e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -130     |\n",
            "|    critic_loss     | 0.651    |\n",
            "|    ent_coef        | 0.0284   |\n",
            "|    ent_coef_loss   | -1.47    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 509399   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 1.88e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 138      |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=2025.35 +/- 14.54\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.03e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -133     |\n",
            "|    critic_loss     | 0.72     |\n",
            "|    ent_coef        | 0.029    |\n",
            "|    ent_coef_loss   | -1.5     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 519399   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 1.97e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 278      |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=2259.08 +/- 32.91\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.26e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -134     |\n",
            "|    critic_loss     | 0.516    |\n",
            "|    ent_coef        | 0.029    |\n",
            "|    ent_coef_loss   | -0.118   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 529399   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.02e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 416      |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 978      |\n",
            "|    ep_rew_mean     | 2.01e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 536      |\n",
            "|    total_timesteps | 39112    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -138     |\n",
            "|    critic_loss     | 1.17     |\n",
            "|    ent_coef        | 0.0309   |\n",
            "|    ent_coef_loss   | -0.605   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 538511   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=75.74 +/- 3.57\n",
            "Episode length: 93.00 +/- 1.67\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 93       |\n",
            "|    mean_reward     | 75.7     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 0.784    |\n",
            "|    ent_coef        | 0.0308   |\n",
            "|    ent_coef_loss   | -0.579   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 539399   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 802      |\n",
            "|    ep_rew_mean     | 1.62e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 551      |\n",
            "|    total_timesteps | 40105    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -135     |\n",
            "|    critic_loss     | 1.02     |\n",
            "|    ent_coef        | 0.0308   |\n",
            "|    ent_coef_loss   | 1.15     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 539504   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 684      |\n",
            "|    ep_rew_mean     | 1.37e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 563      |\n",
            "|    total_timesteps | 41040    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 3.74     |\n",
            "|    ent_coef        | 0.0301   |\n",
            "|    ent_coef_loss   | 1.84     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 540439   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 626      |\n",
            "|    ep_rew_mean     | 1.19e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 601      |\n",
            "|    total_timesteps | 43845    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 1.3      |\n",
            "|    ent_coef        | 0.0294   |\n",
            "|    ent_coef_loss   | -1.4     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 543244   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 559      |\n",
            "|    ep_rew_mean     | 1.05e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 612      |\n",
            "|    total_timesteps | 44711    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -139     |\n",
            "|    critic_loss     | 1.19     |\n",
            "|    ent_coef        | 0.0305   |\n",
            "|    ent_coef_loss   | -0.593   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 544110   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 507      |\n",
            "|    ep_rew_mean     | 942      |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 625      |\n",
            "|    total_timesteps | 45624    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 1.25     |\n",
            "|    ent_coef        | 0.03     |\n",
            "|    ent_coef_loss   | -1.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 545023   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 474      |\n",
            "|    ep_rew_mean     | 857      |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 648      |\n",
            "|    total_timesteps | 47431    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 1.45     |\n",
            "|    ent_coef        | 0.0287   |\n",
            "|    ent_coef_loss   | -1.69    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 546830   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 384      |\n",
            "|    ep_rew_mean     | 678      |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 660      |\n",
            "|    total_timesteps | 48362    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 1.21     |\n",
            "|    ent_coef        | 0.0297   |\n",
            "|    ent_coef_loss   | -0.342   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 547761   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 293      |\n",
            "|    ep_rew_mean     | 482      |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 673      |\n",
            "|    total_timesteps | 49328    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 2.13     |\n",
            "|    ent_coef        | 0.0292   |\n",
            "|    ent_coef_loss   | 0.359    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 548727   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=77.28 +/- 4.05\n",
            "Episode length: 97.60 +/- 20.55\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 97.6     |\n",
            "|    mean_reward     | 77.3     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 1.01     |\n",
            "|    ent_coef        | 0.0291   |\n",
            "|    ent_coef_loss   | 1.06     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 549399   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 208      |\n",
            "|    ep_rew_mean     | 279      |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 691      |\n",
            "|    total_timesteps | 50757    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -133     |\n",
            "|    critic_loss     | 1.1      |\n",
            "|    ent_coef        | 0.0291   |\n",
            "|    ent_coef_loss   | -0.254   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 550156   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 198      |\n",
            "|    ep_rew_mean     | 226      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 73       |\n",
            "|    time_elapsed    | 801      |\n",
            "|    total_timesteps | 58939    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -137     |\n",
            "|    critic_loss     | 0.747    |\n",
            "|    ent_coef        | 0.0284   |\n",
            "|    ent_coef_loss   | 1.33     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 558338   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=2292.50 +/- 58.91\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.29e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -136     |\n",
            "|    critic_loss     | 0.827    |\n",
            "|    ent_coef        | 0.0283   |\n",
            "|    ent_coef_loss   | -0.237   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 559399   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 289      |\n",
            "|    ep_rew_mean     | 449      |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 946      |\n",
            "|    total_timesteps | 69000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -134     |\n",
            "|    critic_loss     | 1.28     |\n",
            "|    ent_coef        | 0.0293   |\n",
            "|    ent_coef_loss   | 0.459    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 568399   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=2181.40 +/- 35.76\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.18e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -140     |\n",
            "|    critic_loss     | 1.04     |\n",
            "|    ent_coef        | 0.0288   |\n",
            "|    ent_coef_loss   | -1.38    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 569399   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 380      |\n",
            "|    ep_rew_mean     | 674      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1087     |\n",
            "|    total_timesteps | 79000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -141     |\n",
            "|    critic_loss     | 0.718    |\n",
            "|    ent_coef        | 0.0311   |\n",
            "|    ent_coef_loss   | -1.34    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 578399   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=2443.90 +/- 19.24\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.44e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -143     |\n",
            "|    critic_loss     | 0.794    |\n",
            "|    ent_coef        | 0.0311   |\n",
            "|    ent_coef_loss   | 1.08     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 579399   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 452      |\n",
            "|    ep_rew_mean     | 896      |\n",
            "| time/              |          |\n",
            "|    episodes        | 170      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1227     |\n",
            "|    total_timesteps | 89000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -139     |\n",
            "|    critic_loss     | 1.4      |\n",
            "|    ent_coef        | 0.0312   |\n",
            "|    ent_coef_loss   | -0.575   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 588399   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=2349.45 +/- 15.28\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.35e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -143     |\n",
            "|    critic_loss     | 0.736    |\n",
            "|    ent_coef        | 0.0315   |\n",
            "|    ent_coef_loss   | 0.711    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 589399   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 543      |\n",
            "|    ep_rew_mean     | 1.13e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 180      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1368     |\n",
            "|    total_timesteps | 99000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -148     |\n",
            "|    critic_loss     | 0.783    |\n",
            "|    ent_coef        | 0.0323   |\n",
            "|    ent_coef_loss   | -1.57    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 598399   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=2503.10 +/- 29.51\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.5e+03  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -145     |\n",
            "|    critic_loss     | 0.656    |\n",
            "|    ent_coef        | 0.0323   |\n",
            "|    ent_coef_loss   | -1.85    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 599399   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  2482.8315362000003\n",
            "Eval num_timesteps=10000, episode_reward=2257.66 +/- 100.09\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.26e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -149     |\n",
            "|    critic_loss     | 1.32     |\n",
            "|    ent_coef        | 0.0319   |\n",
            "|    ent_coef_loss   | 1.5      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 609299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.32e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 139      |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=2430.02 +/- 12.39\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.43e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -150     |\n",
            "|    critic_loss     | 0.723    |\n",
            "|    ent_coef        | 0.0323   |\n",
            "|    ent_coef_loss   | 0.0595   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 619299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.34e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 280      |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=2497.89 +/- 13.14\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.5e+03  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -155     |\n",
            "|    critic_loss     | 0.601    |\n",
            "|    ent_coef        | 0.0327   |\n",
            "|    ent_coef_loss   | -0.416   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 629299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.38e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 422      |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=2538.87 +/- 15.47\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.54e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -155     |\n",
            "|    critic_loss     | 0.93     |\n",
            "|    ent_coef        | 0.0328   |\n",
            "|    ent_coef_loss   | -0.486   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 639299   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.41e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 559      |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=2626.80 +/- 27.65\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.63e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -160     |\n",
            "|    critic_loss     | 0.762    |\n",
            "|    ent_coef        | 0.0338   |\n",
            "|    ent_coef_loss   | 0.231    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 649299   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.43e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 699      |\n",
            "|    total_timesteps | 50000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=2561.09 +/- 37.95\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.56e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -160     |\n",
            "|    critic_loss     | 0.791    |\n",
            "|    ent_coef        | 0.0346   |\n",
            "|    ent_coef_loss   | -0.838   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 659299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.45e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 836      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=2541.89 +/- 17.43\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.54e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -164     |\n",
            "|    critic_loss     | 0.966    |\n",
            "|    ent_coef        | 0.0355   |\n",
            "|    ent_coef_loss   | -0.484   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 669299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.46e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 976      |\n",
            "|    total_timesteps | 70000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=2574.14 +/- 5.42\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.57e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -166     |\n",
            "|    critic_loss     | 0.937    |\n",
            "|    ent_coef        | 0.0342   |\n",
            "|    ent_coef_loss   | 0.847    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 679299   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.47e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1113     |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=2633.51 +/- 10.04\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.63e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -164     |\n",
            "|    critic_loss     | 1.02     |\n",
            "|    ent_coef        | 0.035    |\n",
            "|    ent_coef_loss   | 1.59     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 689299   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.48e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1255     |\n",
            "|    total_timesteps | 90000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=2669.50 +/- 13.33\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.67e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -170     |\n",
            "|    critic_loss     | 0.781    |\n",
            "|    ent_coef        | 0.0355   |\n",
            "|    ent_coef_loss   | -0.585   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 699299   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.49e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1397     |\n",
            "|    total_timesteps | 100000   |\n",
            "---------------------------------\n",
            "mean_reward  2681.2634582\n",
            "Eval num_timesteps=10000, episode_reward=2660.41 +/- 15.44\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.66e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -167     |\n",
            "|    critic_loss     | 2.07     |\n",
            "|    ent_coef        | 0.0369   |\n",
            "|    ent_coef_loss   | -0.763   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 709199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.57e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 138      |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=2658.52 +/- 20.96\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.66e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -172     |\n",
            "|    critic_loss     | 0.792    |\n",
            "|    ent_coef        | 0.0362   |\n",
            "|    ent_coef_loss   | 1.14     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 719199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.59e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 278      |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=2729.55 +/- 13.36\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.73e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -173     |\n",
            "|    critic_loss     | 0.977    |\n",
            "|    ent_coef        | 0.0372   |\n",
            "|    ent_coef_loss   | -1.06    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 729199   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.6e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 422      |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=2684.32 +/- 33.36\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.68e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -176     |\n",
            "|    critic_loss     | 0.783    |\n",
            "|    ent_coef        | 0.0371   |\n",
            "|    ent_coef_loss   | -1.6     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 739199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.6e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 561      |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=2712.77 +/- 13.13\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.71e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -175     |\n",
            "|    critic_loss     | 0.825    |\n",
            "|    ent_coef        | 0.0363   |\n",
            "|    ent_coef_loss   | 0.741    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 749199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.61e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 703      |\n",
            "|    total_timesteps | 50000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=2688.54 +/- 8.35\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.69e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -180     |\n",
            "|    critic_loss     | 1.54     |\n",
            "|    ent_coef        | 0.0373   |\n",
            "|    ent_coef_loss   | 0.541    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 759199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.61e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 844      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=91.33 +/- 32.73\n",
            "Episode length: 134.60 +/- 82.45\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 135      |\n",
            "|    mean_reward     | 91.3     |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -180     |\n",
            "|    critic_loss     | 1.4      |\n",
            "|    ent_coef        | 0.0367   |\n",
            "|    ent_coef_loss   | 0.952    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 769199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.61e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 973      |\n",
            "|    total_timesteps | 70000    |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 887      |\n",
            "|    ep_rew_mean     | 2.3e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 985      |\n",
            "|    total_timesteps | 70962    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -181     |\n",
            "|    critic_loss     | 0.661    |\n",
            "|    ent_coef        | 0.0367   |\n",
            "|    ent_coef_loss   | 1.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 770161   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 809      |\n",
            "|    ep_rew_mean     | 2.05e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 90       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1011     |\n",
            "|    total_timesteps | 72829    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -181     |\n",
            "|    critic_loss     | 1.13     |\n",
            "|    ent_coef        | 0.0363   |\n",
            "|    ent_coef_loss   | 0.224    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 772028   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 746      |\n",
            "|    ep_rew_mean     | 1.86e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 100      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1035     |\n",
            "|    total_timesteps | 74570    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -180     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    ent_coef        | 0.0367   |\n",
            "|    ent_coef_loss   | 1.21     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 773769   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 654      |\n",
            "|    ep_rew_mean     | 1.61e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 110      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1047     |\n",
            "|    total_timesteps | 75426    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -179     |\n",
            "|    critic_loss     | 0.947    |\n",
            "|    ent_coef        | 0.0351   |\n",
            "|    ent_coef_loss   | 0.221    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 774625   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 563      |\n",
            "|    ep_rew_mean     | 1.36e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 120      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1059     |\n",
            "|    total_timesteps | 76305    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -177     |\n",
            "|    critic_loss     | 1.75     |\n",
            "|    ent_coef        | 0.0365   |\n",
            "|    ent_coef_loss   | 1.62     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 775504   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 473      |\n",
            "|    ep_rew_mean     | 1.1e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 130      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1072     |\n",
            "|    total_timesteps | 77284    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -177     |\n",
            "|    critic_loss     | 1.47     |\n",
            "|    ent_coef        | 0.0354   |\n",
            "|    ent_coef_loss   | 1.2      |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 776483   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 392      |\n",
            "|    ep_rew_mean     | 874      |\n",
            "| time/              |          |\n",
            "|    episodes        | 140      |\n",
            "|    fps             | 72       |\n",
            "|    time_elapsed    | 1097     |\n",
            "|    total_timesteps | 79192    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -178     |\n",
            "|    critic_loss     | 1.16     |\n",
            "|    ent_coef        | 0.0356   |\n",
            "|    ent_coef_loss   | 0.245    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 778391   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=2649.47 +/- 25.92\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.65e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -180     |\n",
            "|    critic_loss     | 1.07     |\n",
            "|    ent_coef        | 0.0339   |\n",
            "|    ent_coef_loss   | 0.448    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 779199   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 360      |\n",
            "|    ep_rew_mean     | 784      |\n",
            "| time/              |          |\n",
            "|    episodes        | 150      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1196     |\n",
            "|    total_timesteps | 86000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -176     |\n",
            "|    critic_loss     | 1        |\n",
            "|    ent_coef        | 0.0329   |\n",
            "|    ent_coef_loss   | 1.23     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 785199   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=90000, episode_reward=2742.48 +/- 13.43\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.74e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 90000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -175     |\n",
            "|    critic_loss     | 1.09     |\n",
            "|    ent_coef        | 0.0333   |\n",
            "|    ent_coef_loss   | 0.973    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 789199   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 360      |\n",
            "|    ep_rew_mean     | 787      |\n",
            "| time/              |          |\n",
            "|    episodes        | 160      |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 1338     |\n",
            "|    total_timesteps | 96000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -173     |\n",
            "|    critic_loss     | 1.44     |\n",
            "|    ent_coef        | 0.0343   |\n",
            "|    ent_coef_loss   | 0.108    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 795199   |\n",
            "---------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=2780.22 +/- 9.06\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.78e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 100000   |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -178     |\n",
            "|    critic_loss     | 1.02     |\n",
            "|    ent_coef        | 0.0349   |\n",
            "|    ent_coef_loss   | 0.625    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 799199   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "mean_reward  2767.9101786\n",
            "Eval num_timesteps=10000, episode_reward=2801.83 +/- 10.46\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.8e+03  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 10000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -176     |\n",
            "|    critic_loss     | 1.32     |\n",
            "|    ent_coef        | 0.0343   |\n",
            "|    ent_coef_loss   | 1.18     |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 809099   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.64e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 10       |\n",
            "|    fps             | 71       |\n",
            "|    time_elapsed    | 140      |\n",
            "|    total_timesteps | 10000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=20000, episode_reward=2746.78 +/- 10.39\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.75e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 20000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -180     |\n",
            "|    critic_loss     | 0.836    |\n",
            "|    ent_coef        | 0.0343   |\n",
            "|    ent_coef_loss   | -1.26    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 819099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.66e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 20       |\n",
            "|    fps             | 70       |\n",
            "|    time_elapsed    | 283      |\n",
            "|    total_timesteps | 20000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=30000, episode_reward=2797.99 +/- 23.45\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.8e+03  |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 30000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -188     |\n",
            "|    critic_loss     | 0.843    |\n",
            "|    ent_coef        | 0.0353   |\n",
            "|    ent_coef_loss   | 0.996    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 829099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.68e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 30       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 431      |\n",
            "|    total_timesteps | 30000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=40000, episode_reward=2764.29 +/- 5.91\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.76e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 40000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -185     |\n",
            "|    critic_loss     | 0.6      |\n",
            "|    ent_coef        | 0.0341   |\n",
            "|    ent_coef_loss   | 0.276    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 839099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.69e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 40       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 576      |\n",
            "|    total_timesteps | 40000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=2737.99 +/- 5.93\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.74e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 50000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -183     |\n",
            "|    critic_loss     | 0.588    |\n",
            "|    ent_coef        | 0.0348   |\n",
            "|    ent_coef_loss   | 0.782    |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 849099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.7e+03  |\n",
            "| time/              |          |\n",
            "|    episodes        | 50       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 718      |\n",
            "|    total_timesteps | 50000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=60000, episode_reward=2817.78 +/- 6.48\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.82e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 60000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -184     |\n",
            "|    critic_loss     | 1.05     |\n",
            "|    ent_coef        | 0.0349   |\n",
            "|    ent_coef_loss   | -0.567   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 859099   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.71e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 60       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 864      |\n",
            "|    total_timesteps | 60000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=70000, episode_reward=2832.29 +/- 4.94\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.83e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 70000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -189     |\n",
            "|    critic_loss     | 0.604    |\n",
            "|    ent_coef        | 0.0349   |\n",
            "|    ent_coef_loss   | -0.225   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 869099   |\n",
            "---------------------------------\n",
            "New best mean reward!\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.71e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 70       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 1007     |\n",
            "|    total_timesteps | 70000    |\n",
            "---------------------------------\n",
            "Eval num_timesteps=80000, episode_reward=2793.36 +/- 10.48\n",
            "Episode length: 1000.00 +/- 0.00\n",
            "---------------------------------\n",
            "| eval/              |          |\n",
            "|    mean_ep_length  | 1e+03    |\n",
            "|    mean_reward     | 2.79e+03 |\n",
            "| time/              |          |\n",
            "|    total_timesteps | 80000    |\n",
            "| train/             |          |\n",
            "|    actor_loss      | -190     |\n",
            "|    critic_loss     | 0.689    |\n",
            "|    ent_coef        | 0.0347   |\n",
            "|    ent_coef_loss   | -0.862   |\n",
            "|    learning_rate   | 0.0003   |\n",
            "|    n_updates       | 879099   |\n",
            "---------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 1e+03    |\n",
            "|    ep_rew_mean     | 2.72e+03 |\n",
            "| time/              |          |\n",
            "|    episodes        | 80       |\n",
            "|    fps             | 69       |\n",
            "|    time_elapsed    | 1154     |\n",
            "|    total_timesteps | 80000    |\n",
            "---------------------------------\n"
          ]
        }
      ],
      "source": [
        "mean_rewards = []\n",
        "for _ in range(10):\n",
        "  model.learn(total_timesteps=100000,log_interval = 10,callback=eval_callback)\n",
        "  # Save the agent\n",
        "  model.save(\"SAC_Ant\")\n",
        "  mean_reward, std_reward = evaluate_policy(model, model.get_env(), n_eval_episodes=5)\n",
        "  mean_rewards.append(mean_reward)\n",
        "  print(\"mean_reward \", mean_reward)\n",
        "del model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Tzr51OOibz2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "7992dd24-cdd2-40a7-98ce-e1f978756272"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'mean_rewards' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-a5123db67c4e>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_rewards\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Iteration'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Mean Reward'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mean_rewards' is not defined"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(mean_rewards)\n",
        "plt.xlabel('Iteration')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UOqxBY5Wibz2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Cargar el archivo .npz\n",
        "eval_data = np.load('./logs/eval/evaluations.npz')\n",
        "\n",
        "# Listar las claves en el archivo .npz\n",
        "print(eval_data.files)\n",
        "\n",
        "# Supongamos que el archivo tiene las claves 'results' y 'timesteps'\n",
        "# Acceder a los datos\n",
        "results = eval_data['results']\n",
        "timesteps = eval_data['timesteps']\n",
        "\n",
        "# Calcular la recompensa promedio si es necesario (depende del formato de results)\n",
        "mean_rewards = results.mean(axis=1)  # Promedio de recompensas por evaluación\n",
        "\n",
        "# Graficar las recompensas promedio\n",
        "plt.plot(timesteps, mean_rewards)\n",
        "plt.xlabel('Timestep')\n",
        "plt.ylabel('Mean Reward')\n",
        "plt.title('Mean Reward over Time')\n",
        "plt.grid()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN7DM3ROXc0mZiLwoLxcmvK",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}